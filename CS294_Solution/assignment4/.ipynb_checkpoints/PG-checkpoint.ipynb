{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Policy Gradients for CartPole and Pong\n",
    "\n",
    "In this notebook, you will implement a Vanilla Policy Gradient algorithm to train an agent to play CartPole (and Pong later, if desired). This uses the OpenAI gym library. Make sure you can install and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some setup.\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from agents.policy_gradients import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0,8.0)\n",
    "plt.rcParams['image.interpolation'] = 'linear'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x,y):\n",
    "    \"\"\" Returns relative error. \"\"\"\n",
    "    return np.max( np.abs(x-y) / np.maximum(1e-8,np.abs(x)+np.abs(y)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discounted Rewards\n",
    "\n",
    "With policy gradients, we need rewards to scale the gradient terms appropriately. Implement the method `discount_rewards` and test your implementation using the following cell. For some games, such as CartPole, we can sum the rewards by considering all of the subsequent rewards for a given episode. For Pong, however, the rewards should be reset to 0 after any player scores.\n",
    "\n",
    "You will need to take care of both cases (set by the `do_reset` parameter). Do this even if you do not plan to test with Pong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32314280378e-09\n",
      "2.75945079139e-09\n"
     ]
    }
   ],
   "source": [
    "test = np.array([0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,-1], np.float)\n",
    "output_1 = [-0.70017483, -0.70724731, -0.71439122, -0.72160729, -0.72889625, -0.73625884,\n",
    "            -0.7436958,  -0.75120788, -0.75879584, -0.76646044, -0.77420247, -1.7921237,\n",
    "            -1.81022596, -1.82851107, -1.84698088, -1.86563725, -1.88448208, -1.90351725,\n",
    "            -1.92274469, -0.93206535, -0.94148015, -0.95099005, -0.96059601, -0.970299,\n",
    "            -0.9801,     -0.99,       -1.        ]\n",
    "output_2 = [ 0.90438208,  0.91351725,  0.92274469,  0.93206535,  0.94148015,  0.95099005,\n",
    "             0.96059601,  0.970299,    0.9801,      0.99,        1.,         -0.93206535,\n",
    "            -0.94148015, -0.95099005, -0.96059601, -0.970299,   -0.9801,    -0.99,     -1.,\n",
    "            -0.93206535, -0.94148015, -0.95099005, -0.96059601, -0.970299,  -0.9801, -0.99, -1.]\n",
    "\n",
    "PG = PolicyGradient()\n",
    "rewards_1 = PG.discount_rewards(test, do_reset=False)\n",
    "rewards_2 = PG.discount_rewards(test, do_reset=True)\n",
    "\n",
    "# Should be around 1e-9\n",
    "print(rel_error(output_1, rewards_1))\n",
    "print(rel_error(output_2, rewards_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradients for CartPole\n",
    "\n",
    "There are three places in the code to fill:\n",
    "\n",
    "1. The method `policy_backward`, which will compute the gradients.\n",
    "2. In the `train` method, you need to write the gradient for the final output layer (i.e., the last gradient in the overall computational graph) and store that in a list to be used at the end of the episode.\n",
    "3. Also in the `train` method, you need to utilize the discounted rewards you wrote and integrate it into the computation of the gradient. In addition, you need to keep the overall `grad_buffer` up to date.\n",
    "\n",
    "After you complete these, you should be able to train your agent on CartPole (and Pong, if desired).\n",
    "\n",
    "To get full credit for this portion run CartPole with `max_episodes=400`, and report the final running reward, as well as a plot of all the running reward values. (The cell after the training call should do these two automatically.) You should aim to get a final running_reward of **at least 200.00**, and the plot for the running_rewards should show a clear upward trend, though it may sometimes decrease if there are games that last abnormally long. For reference, our implementation usually achieves running rewards of 500-5000 after 400 episodes. From our experience, the performance varies a lot with CartPole; we have gotten scores as high as a million, so save any output that meets the 200-score requirement.\n",
    "\n",
    "Some additional comments:\n",
    "\n",
    "1. You do not need to change the default hyperparameters provided, such as `learning_rate`. If you need to change one of them to get the minimum performance -- or if you think there's a compelling reason to do so -- explain your changes in a new text/Markdown cell.\n",
    "\n",
    "2. Please keep `print_every=2` (or some other reasonable value) so that we can spot-check the rewards and running rewards per episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-18 20:01:38,280] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 10 done, reward: 15.0, running_reward: 28.7208, time (sec): 0.0232\n",
      "Ep. 20 done, reward: 11.0, running_reward: 27.7047, time (sec): 0.0419\n",
      "Ep. 30 done, reward: 49.0, running_reward: 27.7510, time (sec): 0.0726\n",
      "Ep. 40 done, reward: 15.0, running_reward: 27.8340, time (sec): 0.0875\n",
      "Ep. 50 done, reward: 62.0, running_reward: 29.1790, time (sec): 0.1066\n",
      "Ep. 60 done, reward: 95.0, running_reward: 30.4940, time (sec): 0.1243\n",
      "Ep. 70 done, reward: 33.0, running_reward: 31.4567, time (sec): 0.1401\n",
      "Ep. 80 done, reward: 53.0, running_reward: 33.4554, time (sec): 0.1609\n",
      "Ep. 90 done, reward: 77.0, running_reward: 36.1012, time (sec): 0.1885\n",
      "Ep. 100 done, reward: 75.0, running_reward: 40.1257, time (sec): 0.2201\n",
      "Ep. 110 done, reward: 180.0, running_reward: 53.7436, time (sec): 0.2977\n",
      "Ep. 120 done, reward: 158.0, running_reward: 60.8863, time (sec): 0.3488\n",
      "Ep. 130 done, reward: 144.0, running_reward: 73.6780, time (sec): 0.4264\n",
      "Ep. 140 done, reward: 263.0, running_reward: 98.2052, time (sec): 0.5725\n",
      "Ep. 150 done, reward: 59.0, running_reward: 112.2448, time (sec): 0.6784\n",
      "Ep. 160 done, reward: 168.0, running_reward: 115.8397, time (sec): 0.7488\n",
      "Ep. 170 done, reward: 133.0, running_reward: 125.5684, time (sec): 0.8427\n",
      "Ep. 180 done, reward: 267.0, running_reward: 136.9677, time (sec): 0.9419\n",
      "Ep. 190 done, reward: 345.0, running_reward: 147.2905, time (sec): 1.0743\n",
      "Ep. 200 done, reward: 184.0, running_reward: 149.9699, time (sec): 1.1597\n",
      "Ep. 210 done, reward: 722.0, running_reward: 174.1991, time (sec): 1.3379\n",
      "Ep. 220 done, reward: 405.0, running_reward: 199.5810, time (sec): 1.5077\n",
      "Ep. 230 done, reward: 102.0, running_reward: 226.3129, time (sec): 1.7018\n",
      "Ep. 240 done, reward: 184.0, running_reward: 224.7089, time (sec): 1.7878\n",
      "Ep. 250 done, reward: 304.0, running_reward: 233.3232, time (sec): 1.9158\n",
      "Ep. 260 done, reward: 216.0, running_reward: 238.2328, time (sec): 2.0486\n",
      "Ep. 270 done, reward: 245.0, running_reward: 270.6318, time (sec): 2.2674\n",
      "Ep. 280 done, reward: 466.0, running_reward: 287.7880, time (sec): 2.4553\n",
      "Ep. 290 done, reward: 201.0, running_reward: 289.8791, time (sec): 2.5876\n",
      "Ep. 300 done, reward: 279.0, running_reward: 294.8508, time (sec): 2.7225\n",
      "Ep. 310 done, reward: 920.0, running_reward: 330.2104, time (sec): 2.9968\n",
      "Ep. 320 done, reward: 3279.0, running_reward: 512.4191, time (sec): 3.8909\n",
      "Ep. 330 done, reward: 2252.0, running_reward: 558.5649, time (sec): 4.2804\n",
      "Ep. 340 done, reward: 269.0, running_reward: 558.5704, time (sec): 4.4963\n",
      "Ep. 350 done, reward: 252.0, running_reward: 537.4406, time (sec): 4.6356\n",
      "Ep. 360 done, reward: 200.0, running_reward: 532.9720, time (sec): 4.8313\n",
      "Ep. 370 done, reward: 290.0, running_reward: 549.2698, time (sec): 5.1119\n",
      "Ep. 380 done, reward: 169.0, running_reward: 547.7793, time (sec): 5.3223\n",
      "Ep. 390 done, reward: 549.0, running_reward: 528.1272, time (sec): 5.4608\n",
      "Ep. 400 done, reward: 140.0, running_reward: 505.3916, time (sec): 5.5830\n",
      "Whew! All done with 400 episodes!\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to play CartPole.\n",
    "PG = PolicyGradient(D=4, H=30, learning_rate=0.01)\n",
    "PG.train(environment=\"CartPole-v0\", max_episodes=400, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CartPole running reward: 505.391577955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1062951d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGHCAYAAABrpPKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBcwnt0cgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105f8fdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print final running_reward and plot the results.\n",
    "print(\"Final CartPole running reward: {}\".format(PG.running_rewards[-1]))\n",
    "plt.figure()\n",
    "plt.plot(PG.running_rewards)\n",
    "plt.title(\"Running Rewards for CartPole\")\n",
    "plt.xlabel(\"Training Episodes\")\n",
    "plt.ylabel(\"Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most computers should be able to run larger, image-based environments like Pong. Although it will take much longer, especially on older machines, so this step is optional. To run Pong, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-18 20:06:17,416] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 done, reward: -21.0, running_reward: -21.0000, time (sec): 4.2392\n",
      "Ep. 4 done, reward: -20.0, running_reward: -20.9900, time (sec): 9.1926\n",
      "Ep. 6 done, reward: -21.0, running_reward: -20.9902, time (sec): 13.2447\n",
      "Ep. 8 done, reward: -20.0, running_reward: -20.9804, time (sec): 18.0817\n",
      "Ep. 10 done, reward: -21.0, running_reward: -20.9610, time (sec): 23.3640\n",
      "Ep. 12 done, reward: -21.0, running_reward: -20.9420, time (sec): 28.3489\n",
      "Ep. 14 done, reward: -21.0, running_reward: -20.9332, time (sec): 32.5287\n",
      "Ep. 16 done, reward: -20.0, running_reward: -20.9146, time (sec): 37.9364\n",
      "Ep. 18 done, reward: -20.0, running_reward: -20.8964, time (sec): 42.9231\n",
      "Ep. 20 done, reward: -21.0, running_reward: -20.8985, time (sec): 47.9806\n",
      "Ep. 22 done, reward: -18.0, running_reward: -20.8507, time (sec): 54.7351\n",
      "Ep. 24 done, reward: -20.0, running_reward: -20.8437, time (sec): 60.5124\n",
      "Ep. 26 done, reward: -20.0, running_reward: -20.8368, time (sec): 65.0339\n",
      "Ep. 28 done, reward: -21.0, running_reward: -20.8401, time (sec): 70.2894\n",
      "Ep. 30 done, reward: -21.0, running_reward: -20.8432, time (sec): 75.5356\n",
      "Ep. 32 done, reward: -19.0, running_reward: -20.8264, time (sec): 80.8980\n",
      "Ep. 34 done, reward: -21.0, running_reward: -20.8199, time (sec): 85.8828\n",
      "Ep. 36 done, reward: -21.0, running_reward: -20.8235, time (sec): 90.3270\n",
      "Ep. 38 done, reward: -21.0, running_reward: -20.8270, time (sec): 95.5191\n",
      "Ep. 40 done, reward: -20.0, running_reward: -20.8006, time (sec): 100.7529\n",
      "Ep. 42 done, reward: -21.0, running_reward: -20.7848, time (sec): 106.5344\n",
      "Ep. 44 done, reward: -21.0, running_reward: -20.7693, time (sec): 111.2267\n",
      "Ep. 46 done, reward: -21.0, running_reward: -20.7739, time (sec): 115.1715\n",
      "Ep. 48 done, reward: -21.0, running_reward: -20.7784, time (sec): 119.8909\n",
      "Ep. 50 done, reward: -21.0, running_reward: -20.7828, time (sec): 124.6310\n",
      "Ep. 52 done, reward: -21.0, running_reward: -20.7772, time (sec): 129.4931\n",
      "Ep. 54 done, reward: -21.0, running_reward: -20.7718, time (sec): 134.8587\n",
      "Ep. 56 done, reward: -21.0, running_reward: -20.7763, time (sec): 139.6418\n",
      "Ep. 58 done, reward: -20.0, running_reward: -20.7707, time (sec): 143.9785\n",
      "Ep. 60 done, reward: -20.0, running_reward: -20.7653, time (sec): 148.7718\n",
      "Ep. 62 done, reward: -18.0, running_reward: -20.7301, time (sec): 153.9780\n",
      "Ep. 64 done, reward: -21.0, running_reward: -20.7355, time (sec): 157.9662\n",
      "Ep. 66 done, reward: -19.0, running_reward: -20.7009, time (sec): 163.8958\n",
      "Ep. 68 done, reward: -18.0, running_reward: -20.6670, time (sec): 169.4670\n",
      "Ep. 70 done, reward: -21.0, running_reward: -20.6736, time (sec): 174.2977\n",
      "Ep. 72 done, reward: -21.0, running_reward: -20.6801, time (sec): 178.7102\n",
      "Ep. 74 done, reward: -20.0, running_reward: -20.6765, time (sec): 183.3715\n",
      "Ep. 76 done, reward: -20.0, running_reward: -20.6531, time (sec): 190.3076\n",
      "Ep. 78 done, reward: -21.0, running_reward: -20.6600, time (sec): 195.5147\n",
      "Ep. 80 done, reward: -20.0, running_reward: -20.6469, time (sec): 199.8856\n",
      "Ep. 82 done, reward: -21.0, running_reward: -20.6440, time (sec): 205.4735\n",
      "Ep. 84 done, reward: -21.0, running_reward: -20.6511, time (sec): 210.0436\n",
      "Ep. 86 done, reward: -19.0, running_reward: -20.6380, time (sec): 214.4542\n",
      "Ep. 88 done, reward: -21.0, running_reward: -20.6353, time (sec): 218.5687\n",
      "Ep. 90 done, reward: -20.0, running_reward: -20.6128, time (sec): 223.3302\n",
      "Ep. 92 done, reward: -20.0, running_reward: -20.6105, time (sec): 228.7682\n",
      "Ep. 94 done, reward: -20.0, running_reward: -20.5983, time (sec): 233.4770\n",
      "Ep. 96 done, reward: -20.0, running_reward: -20.5765, time (sec): 238.4736\n",
      "Ep. 98 done, reward: -20.0, running_reward: -20.5651, time (sec): 243.1123\n",
      "Ep. 100 done, reward: -21.0, running_reward: -20.5737, time (sec): 248.8996\n",
      "Ep. 102 done, reward: -21.0, running_reward: -20.5822, time (sec): 252.8532\n",
      "Ep. 104 done, reward: -21.0, running_reward: -20.5905, time (sec): 258.0402\n",
      "Ep. 106 done, reward: -20.0, running_reward: -20.5788, time (sec): 262.5961\n",
      "Ep. 108 done, reward: -21.0, running_reward: -20.5772, time (sec): 267.6257\n",
      "Ep. 110 done, reward: -20.0, running_reward: -20.5559, time (sec): 273.5980\n",
      "Ep. 112 done, reward: -20.0, running_reward: -20.5547, time (sec): 278.0879\n",
      "Ep. 114 done, reward: -21.0, running_reward: -20.5636, time (sec): 282.1821\n",
      "Ep. 116 done, reward: -21.0, running_reward: -20.5722, time (sec): 287.0268\n",
      "Ep. 118 done, reward: -21.0, running_reward: -20.5709, time (sec): 291.6533\n",
      "Ep. 120 done, reward: -21.0, running_reward: -20.5794, time (sec): 296.5948\n",
      "Ep. 122 done, reward: -20.0, running_reward: -20.5580, time (sec): 303.8260\n",
      "Ep. 124 done, reward: -21.0, running_reward: -20.5569, time (sec): 308.1760\n",
      "Ep. 126 done, reward: -20.0, running_reward: -20.5557, time (sec): 312.4121\n",
      "Ep. 128 done, reward: -21.0, running_reward: -20.5645, time (sec): 317.1501\n",
      "Ep. 130 done, reward: -21.0, running_reward: -20.5732, time (sec): 323.1515\n",
      "Ep. 132 done, reward: -20.0, running_reward: -20.5717, time (sec): 328.3361\n",
      "Ep. 134 done, reward: -21.0, running_reward: -20.5604, time (sec): 333.6731\n",
      "Ep. 136 done, reward: -21.0, running_reward: -20.5593, time (sec): 338.4787\n",
      "Ep. 138 done, reward: -21.0, running_reward: -20.5680, time (sec): 342.9134\n",
      "Ep. 140 done, reward: -21.0, running_reward: -20.5667, time (sec): 347.7160\n",
      "Ep. 142 done, reward: -20.0, running_reward: -20.5554, time (sec): 353.1362\n",
      "Ep. 144 done, reward: -21.0, running_reward: -20.5643, time (sec): 357.5533\n",
      "Ep. 146 done, reward: -21.0, running_reward: -20.5631, time (sec): 363.0866\n",
      "Ep. 148 done, reward: -19.0, running_reward: -20.5419, time (sec): 368.0869\n",
      "Ep. 150 done, reward: -18.0, running_reward: -20.5210, time (sec): 374.1700\n",
      "Ep. 152 done, reward: -21.0, running_reward: -20.5206, time (sec): 378.6594\n",
      "Ep. 154 done, reward: -21.0, running_reward: -20.5202, time (sec): 384.4660\n",
      "Ep. 156 done, reward: -19.0, running_reward: -20.5098, time (sec): 390.0022\n",
      "Ep. 158 done, reward: -19.0, running_reward: -20.4896, time (sec): 395.9394\n",
      "Ep. 160 done, reward: -21.0, running_reward: -20.4998, time (sec): 400.4037\n",
      "Ep. 162 done, reward: -21.0, running_reward: -20.4999, time (sec): 406.4180\n",
      "Ep. 164 done, reward: -21.0, running_reward: -20.4900, time (sec): 411.4041\n",
      "Ep. 166 done, reward: -20.0, running_reward: -20.4803, time (sec): 416.1490\n",
      "Ep. 168 done, reward: -21.0, running_reward: -20.4807, time (sec): 421.4906\n",
      "Ep. 170 done, reward: -20.0, running_reward: -20.4612, time (sec): 426.7835\n",
      "Ep. 172 done, reward: -19.0, running_reward: -20.4421, time (sec): 432.3183\n",
      "Ep. 174 done, reward: -21.0, running_reward: -20.4235, time (sec): 438.3214\n",
      "Ep. 176 done, reward: -20.0, running_reward: -20.4249, time (sec): 443.8384\n",
      "Ep. 178 done, reward: -20.0, running_reward: -20.4264, time (sec): 448.3665\n",
      "Ep. 180 done, reward: -20.0, running_reward: -20.4179, time (sec): 453.5874\n",
      "Ep. 182 done, reward: -21.0, running_reward: -20.4295, time (sec): 459.1741\n",
      "Ep. 184 done, reward: -21.0, running_reward: -20.4309, time (sec): 463.9330\n",
      "Ep. 186 done, reward: -21.0, running_reward: -20.4225, time (sec): 468.8973\n",
      "Ep. 188 done, reward: -20.0, running_reward: -20.4239, time (sec): 474.0862\n",
      "Ep. 190 done, reward: -18.0, running_reward: -20.4054, time (sec): 479.4600\n",
      "Ep. 192 done, reward: -20.0, running_reward: -20.3973, time (sec): 484.7964\n",
      "Ep. 194 done, reward: -21.0, running_reward: -20.4093, time (sec): 490.5004\n",
      "Ep. 196 done, reward: -21.0, running_reward: -20.4013, time (sec): 496.7631\n",
      "Ep. 198 done, reward: -19.0, running_reward: -20.3833, time (sec): 501.4961\n",
      "Ep. 200 done, reward: -21.0, running_reward: -20.3956, time (sec): 506.2113\n",
      "Ep. 202 done, reward: -21.0, running_reward: -20.4076, time (sec): 510.9743\n",
      "Ep. 204 done, reward: -19.0, running_reward: -20.3994, time (sec): 516.5849\n",
      "Ep. 206 done, reward: -20.0, running_reward: -20.3914, time (sec): 521.9836\n",
      "Ep. 208 done, reward: -19.0, running_reward: -20.3737, time (sec): 527.0490\n",
      "Ep. 210 done, reward: -18.0, running_reward: -20.3462, time (sec): 532.9166\n",
      "Ep. 212 done, reward: -21.0, running_reward: -20.3493, time (sec): 537.6034\n",
      "Ep. 214 done, reward: -20.0, running_reward: -20.3325, time (sec): 544.0004\n",
      "Ep. 216 done, reward: -20.0, running_reward: -20.3259, time (sec): 549.8594\n",
      "Ep. 218 done, reward: -19.0, running_reward: -20.3193, time (sec): 555.6293\n",
      "Ep. 220 done, reward: -20.0, running_reward: -20.2931, time (sec): 561.6251\n",
      "Ep. 222 done, reward: -20.0, running_reward: -20.2972, time (sec): 566.5820\n",
      "Ep. 224 done, reward: -21.0, running_reward: -20.3112, time (sec): 571.3388\n",
      "Ep. 226 done, reward: -21.0, running_reward: -20.3249, time (sec): 575.4796\n",
      "Ep. 228 done, reward: -21.0, running_reward: -20.3185, time (sec): 580.9542\n",
      "Ep. 230 done, reward: -19.0, running_reward: -20.2923, time (sec): 586.7374\n",
      "Ep. 232 done, reward: -19.0, running_reward: -20.2765, time (sec): 592.3784\n",
      "Ep. 234 done, reward: -21.0, running_reward: -20.2711, time (sec): 597.5254\n",
      "Ep. 236 done, reward: -21.0, running_reward: -20.2757, time (sec): 603.0086\n",
      "Ep. 238 done, reward: -20.0, running_reward: -20.2801, time (sec): 607.6885\n",
      "Ep. 240 done, reward: -20.0, running_reward: -20.2745, time (sec): 612.5830\n",
      "Ep. 242 done, reward: -20.0, running_reward: -20.2492, time (sec): 619.1763\n",
      "Ep. 244 done, reward: -17.0, running_reward: -20.2044, time (sec): 624.9938\n",
      "Ep. 246 done, reward: -21.0, running_reward: -20.2004, time (sec): 630.0149\n",
      "Ep. 248 done, reward: -19.0, running_reward: -20.1864, time (sec): 635.1871\n",
      "Ep. 250 done, reward: -21.0, running_reward: -20.2026, time (sec): 640.0634\n",
      "Ep. 252 done, reward: -19.0, running_reward: -20.1985, time (sec): 645.8076\n",
      "Ep. 254 done, reward: -21.0, running_reward: -20.2144, time (sec): 650.5224\n",
      "Ep. 256 done, reward: -21.0, running_reward: -20.2202, time (sec): 657.7243\n",
      "Ep. 258 done, reward: -19.0, running_reward: -20.2157, time (sec): 663.5865\n",
      "Ep. 260 done, reward: -18.0, running_reward: -20.1716, time (sec): 669.1787\n",
      "Ep. 262 done, reward: -19.0, running_reward: -20.1384, time (sec): 675.9072\n",
      "Ep. 264 done, reward: -21.0, running_reward: -20.1456, time (sec): 682.5271\n",
      "Ep. 266 done, reward: -20.0, running_reward: -20.1526, time (sec): 688.2445\n",
      "Ep. 268 done, reward: -18.0, running_reward: -20.1296, time (sec): 695.2393\n",
      "Ep. 270 done, reward: -20.0, running_reward: -20.1072, time (sec): 702.2048\n",
      "Ep. 272 done, reward: -19.0, running_reward: -20.1050, time (sec): 707.6467\n",
      "Ep. 274 done, reward: -20.0, running_reward: -20.1128, time (sec): 713.1062\n",
      "Ep. 276 done, reward: -20.0, running_reward: -20.0808, time (sec): 719.2846\n",
      "Ep. 278 done, reward: -21.0, running_reward: -20.0991, time (sec): 724.4098\n",
      "Ep. 280 done, reward: -21.0, running_reward: -20.1072, time (sec): 729.5699\n",
      "Ep. 282 done, reward: -19.0, running_reward: -20.0950, time (sec): 734.8899\n",
      "Ep. 284 done, reward: -19.0, running_reward: -20.0732, time (sec): 741.6244\n",
      "Ep. 286 done, reward: -20.0, running_reward: -20.0619, time (sec): 747.9569\n",
      "Ep. 288 done, reward: -20.0, running_reward: -20.0508, time (sec): 753.4379\n",
      "Ep. 290 done, reward: -21.0, running_reward: -20.0696, time (sec): 759.4738\n",
      "Ep. 292 done, reward: -21.0, running_reward: -20.0882, time (sec): 764.3858\n",
      "Ep. 294 done, reward: -21.0, running_reward: -20.0766, time (sec): 769.9039\n",
      "Ep. 296 done, reward: -21.0, running_reward: -20.0950, time (sec): 774.8298\n",
      "Ep. 298 done, reward: -20.0, running_reward: -20.1030, time (sec): 779.4464\n",
      "Ep. 300 done, reward: -20.0, running_reward: -20.0910, time (sec): 785.3082\n",
      "Ep. 302 done, reward: -21.0, running_reward: -20.0992, time (sec): 791.0749\n",
      "Ep. 304 done, reward: -19.0, running_reward: -20.0873, time (sec): 797.5585\n",
      "Ep. 306 done, reward: -21.0, running_reward: -20.1054, time (sec): 802.9665\n",
      "Ep. 308 done, reward: -21.0, running_reward: -20.1232, time (sec): 808.6239\n",
      "Ep. 310 done, reward: -21.0, running_reward: -20.1011, time (sec): 815.7710\n",
      "Ep. 312 done, reward: -21.0, running_reward: -20.0893, time (sec): 821.8641\n",
      "Ep. 314 done, reward: -21.0, running_reward: -20.1074, time (sec): 827.7258\n",
      "Ep. 316 done, reward: -20.0, running_reward: -20.1151, time (sec): 833.0751\n",
      "Ep. 318 done, reward: -21.0, running_reward: -20.1130, time (sec): 839.1900\n",
      "Ep. 320 done, reward: -21.0, running_reward: -20.1306, time (sec): 845.1911\n",
      "Ep. 322 done, reward: -21.0, running_reward: -20.1281, time (sec): 851.6167\n",
      "Ep. 324 done, reward: -21.0, running_reward: -20.1455, time (sec): 856.8987\n",
      "Ep. 326 done, reward: -18.0, running_reward: -20.1226, time (sec): 863.2633\n",
      "Ep. 328 done, reward: -18.0, running_reward: -20.1100, time (sec): 870.2399\n",
      "Ep. 330 done, reward: -21.0, running_reward: -20.1277, time (sec): 876.0405\n",
      "Ep. 332 done, reward: -21.0, running_reward: -20.1451, time (sec): 881.8222\n",
      "Ep. 334 done, reward: -21.0, running_reward: -20.1522, time (sec): 887.2877\n",
      "Ep. 336 done, reward: -18.0, running_reward: -20.1391, time (sec): 894.1669\n",
      "Ep. 338 done, reward: -21.0, running_reward: -20.1265, time (sec): 900.8539\n",
      "Ep. 340 done, reward: -21.0, running_reward: -20.1142, time (sec): 906.9747\n",
      "Ep. 342 done, reward: -21.0, running_reward: -20.1120, time (sec): 913.7350\n",
      "Ep. 344 done, reward: -18.0, running_reward: -20.0997, time (sec): 920.5207\n",
      "Ep. 346 done, reward: -20.0, running_reward: -20.0977, time (sec): 926.8143\n",
      "Ep. 348 done, reward: -19.0, running_reward: -20.0759, time (sec): 933.2884\n",
      "Ep. 350 done, reward: -21.0, running_reward: -20.0942, time (sec): 938.6995\n",
      "Ep. 352 done, reward: -20.0, running_reward: -20.1023, time (sec): 944.5981\n",
      "Ep. 354 done, reward: -21.0, running_reward: -20.1201, time (sec): 950.6279\n",
      "Ep. 356 done, reward: -20.0, running_reward: -20.1078, time (sec): 957.0322\n",
      "Ep. 358 done, reward: -20.0, running_reward: -20.1156, time (sec): 964.0857\n",
      "Ep. 360 done, reward: -18.0, running_reward: -20.1032, time (sec): 971.0379\n",
      "Ep. 362 done, reward: -19.0, running_reward: -20.0812, time (sec): 977.4849\n",
      "Ep. 364 done, reward: -20.0, running_reward: -20.0697, time (sec): 985.7710\n",
      "Ep. 366 done, reward: -21.0, running_reward: -20.0783, time (sec): 991.3819\n",
      "Ep. 368 done, reward: -20.0, running_reward: -20.0867, time (sec): 997.2848\n",
      "Ep. 370 done, reward: -20.0, running_reward: -20.0751, time (sec): 1003.4760\n",
      "Ep. 372 done, reward: -20.0, running_reward: -20.0538, time (sec): 1010.5694\n",
      "Ep. 374 done, reward: -20.0, running_reward: -20.0527, time (sec): 1016.9895\n",
      "Ep. 376 done, reward: -19.0, running_reward: -20.0317, time (sec): 1024.1884\n",
      "Ep. 378 done, reward: -21.0, running_reward: -20.0312, time (sec): 1031.2786\n",
      "Ep. 380 done, reward: -20.0, running_reward: -20.0405, time (sec): 1036.8805\n",
      "Ep. 382 done, reward: -19.0, running_reward: -20.0099, time (sec): 1043.6535\n",
      "Ep. 384 done, reward: -19.0, running_reward: -19.9898, time (sec): 1050.0900\n",
      "Ep. 386 done, reward: -19.0, running_reward: -19.9701, time (sec): 1056.9121\n",
      "Ep. 388 done, reward: -21.0, running_reward: -19.9807, time (sec): 1062.0477\n",
      "Ep. 390 done, reward: -21.0, running_reward: -19.9812, time (sec): 1069.3168\n",
      "Ep. 392 done, reward: -19.0, running_reward: -19.9517, time (sec): 1075.6972\n",
      "Ep. 394 done, reward: -21.0, running_reward: -19.9330, time (sec): 1082.1019\n",
      "Ep. 396 done, reward: -19.0, running_reward: -19.9342, time (sec): 1088.3060\n",
      "Ep. 398 done, reward: -21.0, running_reward: -19.9258, time (sec): 1094.0608\n",
      "Ep. 400 done, reward: -19.0, running_reward: -19.9271, time (sec): 1100.4238\n",
      "Ep. 402 done, reward: -20.0, running_reward: -19.9187, time (sec): 1107.4288\n",
      "Ep. 404 done, reward: -19.0, running_reward: -19.9103, time (sec): 1114.0711\n",
      "Ep. 406 done, reward: -16.0, running_reward: -19.8820, time (sec): 1122.2128\n",
      "Ep. 408 done, reward: -18.0, running_reward: -19.8742, time (sec): 1128.6323\n",
      "Ep. 410 done, reward: -17.0, running_reward: -19.8566, time (sec): 1135.6837\n",
      "Ep. 412 done, reward: -19.0, running_reward: -19.8594, time (sec): 1142.0557\n",
      "Ep. 414 done, reward: -19.0, running_reward: -19.8621, time (sec): 1148.1194\n",
      "Ep. 416 done, reward: -18.0, running_reward: -19.8547, time (sec): 1155.6107\n",
      "Ep. 418 done, reward: -20.0, running_reward: -19.8576, time (sec): 1162.2393\n",
      "Ep. 420 done, reward: -19.0, running_reward: -19.8505, time (sec): 1168.3464\n",
      "Ep. 422 done, reward: -17.0, running_reward: -19.8333, time (sec): 1174.5532\n",
      "Ep. 424 done, reward: -21.0, running_reward: -19.8169, time (sec): 1182.5041\n",
      "Ep. 426 done, reward: -19.0, running_reward: -19.7809, time (sec): 1189.4384\n",
      "Ep. 428 done, reward: -18.0, running_reward: -19.7454, time (sec): 1196.9708\n",
      "Ep. 430 done, reward: -19.0, running_reward: -19.7207, time (sec): 1204.4735\n",
      "Ep. 432 done, reward: -20.0, running_reward: -19.7065, time (sec): 1212.1474\n",
      "Ep. 434 done, reward: -20.0, running_reward: -19.7123, time (sec): 1218.4740\n",
      "Ep. 436 done, reward: -21.0, running_reward: -19.7379, time (sec): 1225.4062\n",
      "Ep. 438 done, reward: -18.0, running_reward: -19.6836, time (sec): 1232.6310\n",
      "Ep. 440 done, reward: -21.0, running_reward: -19.6999, time (sec): 1239.7577\n",
      "Ep. 442 done, reward: -17.0, running_reward: -19.6857, time (sec): 1247.5348\n",
      "Ep. 444 done, reward: -19.0, running_reward: -19.6820, time (sec): 1254.8621\n",
      "Ep. 446 done, reward: -16.0, running_reward: -19.6384, time (sec): 1262.6566\n",
      "Ep. 448 done, reward: -19.0, running_reward: -19.6356, time (sec): 1270.3549\n",
      "Ep. 450 done, reward: -15.0, running_reward: -19.6028, time (sec): 1277.4354\n",
      "Ep. 452 done, reward: -21.0, running_reward: -19.6306, time (sec): 1283.7036\n",
      "Ep. 454 done, reward: -21.0, running_reward: -19.6578, time (sec): 1291.2285\n",
      "Ep. 456 done, reward: -20.0, running_reward: -19.6547, time (sec): 1299.2455\n",
      "Ep. 458 done, reward: -18.0, running_reward: -19.6317, time (sec): 1306.9972\n",
      "Ep. 460 done, reward: -18.0, running_reward: -19.6091, time (sec): 1314.1330\n",
      "Ep. 462 done, reward: -19.0, running_reward: -19.5970, time (sec): 1322.5408\n",
      "Ep. 464 done, reward: -19.0, running_reward: -19.6049, time (sec): 1329.6889\n",
      "Ep. 466 done, reward: -19.0, running_reward: -19.5731, time (sec): 1336.6305\n",
      "Ep. 468 done, reward: -19.0, running_reward: -19.5815, time (sec): 1341.7637\n",
      "Ep. 470 done, reward: -21.0, running_reward: -19.5899, time (sec): 1347.9588\n",
      "Ep. 472 done, reward: -19.0, running_reward: -19.5386, time (sec): 1354.7302\n",
      "Ep. 474 done, reward: -19.0, running_reward: -19.5278, time (sec): 1362.0106\n",
      "Ep. 476 done, reward: -19.0, running_reward: -19.5272, time (sec): 1368.5546\n",
      "Ep. 478 done, reward: -18.0, running_reward: -19.5266, time (sec): 1375.7920\n",
      "Ep. 480 done, reward: -19.0, running_reward: -19.5062, time (sec): 1384.1807\n",
      "Ep. 482 done, reward: -20.0, running_reward: -19.5259, time (sec): 1390.7256\n",
      "Ep. 484 done, reward: -21.0, running_reward: -19.5552, time (sec): 1397.2185\n",
      "Ep. 486 done, reward: -19.0, running_reward: -19.5244, time (sec): 1405.0756\n",
      "Ep. 488 done, reward: -19.0, running_reward: -19.5338, time (sec): 1411.7404\n",
      "Ep. 490 done, reward: -21.0, running_reward: -19.5530, time (sec): 1417.9557\n",
      "Ep. 492 done, reward: -19.0, running_reward: -19.5222, time (sec): 1425.7267\n",
      "Ep. 494 done, reward: -18.0, running_reward: -19.4919, time (sec): 1433.3667\n",
      "Ep. 496 done, reward: -20.0, running_reward: -19.4921, time (sec): 1439.5885\n",
      "Ep. 498 done, reward: -20.0, running_reward: -19.5121, time (sec): 1447.1732\n",
      "Ep. 500 done, reward: -19.0, running_reward: -19.5020, time (sec): 1454.1048\n",
      "Whew! All done with 500 episodes!\n"
     ]
    }
   ],
   "source": [
    "PG = PolicyGradient(D=80*80, H=200, learning_rate=0.001)\n",
    "PG.train(environment=\"Pong-v0\", max_episodes=500, print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Pong running reward: -19.5019571061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10624acd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGHCAYAAABMCnNGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTm7MzMysrPw/6dM7tSEXzTwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10626b6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results.\n",
    "print(\"Final Pong running reward: {}\".format(PG.running_rewards[-1]))\n",
    "plt.figure()\n",
    "plt.plot(PG.running_rewards)\n",
    "plt.title(\"Running Rewards for Pong\")\n",
    "plt.xlabel(\"Training Episodes\")\n",
    "plt.ylabel(\"Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional\n",
    "\n",
    "Congratulations on implementing Policy Gradients! \n",
    "\n",
    "Consider doing the following extensions:\n",
    "\n",
    "1. Run the Pong code from the cells above and tune for best performance. Summarize your results. \n",
    "2. Introduce a baseline function for the rewards. This will also require refitting the baseline; we recommend using a linear function and Numpy's linear algebra solver. \n",
    "3. Try a neural network architecture which is substantially different from the current one we are using. Try using two hidden layers (instead of one) and/or using sigmoid non-linearity.\n",
    "4. Extend the model to control more than two actions. You should use a softmax output. Try it, e.g. on Pong with the default action (actions [0,2,3]). \n",
    "5. Try an environment other than CartPole or Pong and see how the same architecture works (you need to look up the documentation for OpenAI gym, and run get_action_meanings on the environment). You will need to check the following: (1) that the game can be reduced to two controls, or that you implemented part 4 above, (2) that the preprocessing procedure makes sense, and (3) that your reward discounting is appropriate - some environments restart each time a reward is returned. \n",
    "\n",
    "State which one of these you are doing in the following cell(s). Describe results/statistics, show at least one plot, and provide at least one conclusion in the following cell.\n",
    "\n",
    "These experiments will generally require you to write code outside of the areas you wrote earlier, so make sure you at least put in a code comment somewhere to explain what is new.\n",
    "\n",
    "If you do an extension, modify the names of the log files e.g. `PG.running_rewards` to keep them distinct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-18 22:11:05,494] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 done, reward: -21.0, running_reward: -21.0000, time (sec): 4.2748\n",
      "Ep. 4 done, reward: -21.0, running_reward: -20.9901, time (sec): 9.7702\n",
      "Ep. 6 done, reward: -21.0, running_reward: -20.9804, time (sec): 14.1163\n",
      "Ep. 8 done, reward: -20.0, running_reward: -20.9708, time (sec): 19.7963\n",
      "Ep. 10 done, reward: -21.0, running_reward: -20.9714, time (sec): 24.5350\n",
      "Ep. 12 done, reward: -20.0, running_reward: -20.9322, time (sec): 31.7211\n",
      "Ep. 14 done, reward: -21.0, running_reward: -20.9336, time (sec): 36.6427\n",
      "Ep. 16 done, reward: -21.0, running_reward: -20.9349, time (sec): 41.8180\n",
      "Ep. 18 done, reward: -20.0, running_reward: -20.9262, time (sec): 47.3191\n",
      "Ep. 20 done, reward: -21.0, running_reward: -20.9277, time (sec): 52.8338\n",
      "Ep. 22 done, reward: -21.0, running_reward: -20.9291, time (sec): 58.2691\n",
      "Ep. 24 done, reward: -21.0, running_reward: -20.9305, time (sec): 62.5723\n",
      "Ep. 26 done, reward: -21.0, running_reward: -20.9319, time (sec): 67.9691\n",
      "Ep. 28 done, reward: -21.0, running_reward: -20.9234, time (sec): 73.7985\n",
      "Ep. 30 done, reward: -20.0, running_reward: -20.9149, time (sec): 81.1970\n",
      "Ep. 32 done, reward: -19.0, running_reward: -20.8966, time (sec): 85.9476\n",
      "Ep. 34 done, reward: -17.0, running_reward: -20.8586, time (sec): 92.4164\n",
      "Ep. 36 done, reward: -21.0, running_reward: -20.8615, time (sec): 96.6880\n",
      "Ep. 38 done, reward: -21.0, running_reward: -20.8642, time (sec): 104.7774\n",
      "Ep. 40 done, reward: -21.0, running_reward: -20.8669, time (sec): 110.8915\n",
      "Ep. 42 done, reward: -21.0, running_reward: -20.8696, time (sec): 116.5110\n",
      "Ep. 44 done, reward: -21.0, running_reward: -20.8722, time (sec): 124.3890\n",
      "Ep. 46 done, reward: -20.0, running_reward: -20.8449, time (sec): 132.1539\n",
      "Ep. 48 done, reward: -20.0, running_reward: -20.8281, time (sec): 137.6926\n",
      "Ep. 50 done, reward: -20.0, running_reward: -20.8215, time (sec): 142.9339\n",
      "Ep. 52 done, reward: -20.0, running_reward: -20.7953, time (sec): 150.1263\n",
      "Ep. 54 done, reward: -21.0, running_reward: -20.7993, time (sec): 155.1299\n",
      "Ep. 56 done, reward: -21.0, running_reward: -20.8033, time (sec): 160.0543\n",
      "Ep. 58 done, reward: -19.0, running_reward: -20.7872, time (sec): 166.8415\n",
      "Ep. 60 done, reward: -20.0, running_reward: -20.7716, time (sec): 173.3180\n",
      "Ep. 62 done, reward: -21.0, running_reward: -20.7662, time (sec): 178.8189\n",
      "Ep. 64 done, reward: -21.0, running_reward: -20.7511, time (sec): 183.7843\n",
      "Ep. 66 done, reward: -21.0, running_reward: -20.7461, time (sec): 191.8999\n",
      "Ep. 68 done, reward: -21.0, running_reward: -20.7512, time (sec): 198.9616\n",
      "Ep. 70 done, reward: -21.0, running_reward: -20.7561, time (sec): 204.3647\n",
      "Ep. 72 done, reward: -21.0, running_reward: -20.7610, time (sec): 209.0481\n",
      "Ep. 74 done, reward: -21.0, running_reward: -20.7657, time (sec): 215.9269\n",
      "Ep. 76 done, reward: -19.0, running_reward: -20.7504, time (sec): 221.5510\n",
      "Ep. 78 done, reward: -21.0, running_reward: -20.7554, time (sec): 225.7015\n",
      "Ep. 80 done, reward: -20.0, running_reward: -20.7502, time (sec): 230.5846\n",
      "Ep. 82 done, reward: -19.0, running_reward: -20.7253, time (sec): 235.5042\n",
      "Ep. 84 done, reward: -21.0, running_reward: -20.7209, time (sec): 240.7300\n",
      "Ep. 86 done, reward: -21.0, running_reward: -20.7264, time (sec): 246.9004\n",
      "Ep. 88 done, reward: -21.0, running_reward: -20.7319, time (sec): 252.4081\n",
      "Ep. 90 done, reward: -21.0, running_reward: -20.7273, time (sec): 258.5774\n",
      "Ep. 92 done, reward: -20.0, running_reward: -20.7029, time (sec): 264.9780\n",
      "Ep. 94 done, reward: -20.0, running_reward: -20.6889, time (sec): 271.8165\n",
      "Ep. 96 done, reward: -21.0, running_reward: -20.6951, time (sec): 279.2583\n",
      "Ep. 98 done, reward: -21.0, running_reward: -20.7012, time (sec): 284.4871\n",
      "Ep. 100 done, reward: -21.0, running_reward: -20.7071, time (sec): 292.1414\n",
      "Ep. 102 done, reward: -18.0, running_reward: -20.6731, time (sec): 298.9709\n",
      "Ep. 104 done, reward: -21.0, running_reward: -20.6796, time (sec): 304.1319\n",
      "Ep. 106 done, reward: -19.0, running_reward: -20.6561, time (sec): 309.3310\n",
      "Ep. 108 done, reward: -21.0, running_reward: -20.6431, time (sec): 314.5828\n",
      "Ep. 110 done, reward: -20.0, running_reward: -20.6204, time (sec): 320.0893\n",
      "Ep. 112 done, reward: -19.0, running_reward: -20.5981, time (sec): 326.4484\n",
      "Ep. 114 done, reward: -20.0, running_reward: -20.5961, time (sec): 333.1851\n",
      "Ep. 116 done, reward: -17.0, running_reward: -20.5641, time (sec): 338.6048\n",
      "Ep. 118 done, reward: -21.0, running_reward: -20.5629, time (sec): 343.7875\n",
      "Ep. 120 done, reward: -19.0, running_reward: -20.5516, time (sec): 351.0377\n",
      "Ep. 122 done, reward: -21.0, running_reward: -20.5506, time (sec): 357.6764\n",
      "Ep. 124 done, reward: -21.0, running_reward: -20.5496, time (sec): 362.7517\n",
      "Ep. 126 done, reward: -19.0, running_reward: -20.5188, time (sec): 369.9221\n",
      "Ep. 128 done, reward: -19.0, running_reward: -20.5084, time (sec): 375.9633\n",
      "Ep. 130 done, reward: -21.0, running_reward: -20.4885, time (sec): 383.9067\n",
      "Ep. 132 done, reward: -20.0, running_reward: -20.4886, time (sec): 389.2983\n",
      "Ep. 134 done, reward: -21.0, running_reward: -20.4988, time (sec): 394.3667\n",
      "Ep. 136 done, reward: -20.0, running_reward: -20.4889, time (sec): 401.8709\n",
      "Ep. 138 done, reward: -21.0, running_reward: -20.4892, time (sec): 407.1202\n",
      "Ep. 140 done, reward: -21.0, running_reward: -20.4894, time (sec): 412.3127\n",
      "Ep. 142 done, reward: -19.0, running_reward: -20.4499, time (sec): 417.9587\n",
      "Ep. 144 done, reward: -21.0, running_reward: -20.4608, time (sec): 423.4844\n",
      "Ep. 146 done, reward: -21.0, running_reward: -20.4518, time (sec): 429.6350\n",
      "Ep. 148 done, reward: -20.0, running_reward: -20.4428, time (sec): 435.4743\n",
      "Ep. 150 done, reward: -21.0, running_reward: -20.4539, time (sec): 440.3343\n",
      "Ep. 152 done, reward: -19.0, running_reward: -20.4447, time (sec): 445.8084\n",
      "Ep. 154 done, reward: -20.0, running_reward: -20.4458, time (sec): 451.7248\n",
      "Ep. 156 done, reward: -19.0, running_reward: -20.4269, time (sec): 458.5049\n",
      "Ep. 158 done, reward: -18.0, running_reward: -20.4083, time (sec): 464.2686\n",
      "Ep. 160 done, reward: -19.0, running_reward: -20.4001, time (sec): 469.3259\n",
      "Ep. 162 done, reward: -20.0, running_reward: -20.4020, time (sec): 474.5751\n",
      "Ep. 164 done, reward: -21.0, running_reward: -20.4040, time (sec): 479.9624\n",
      "Ep. 166 done, reward: -20.0, running_reward: -20.4059, time (sec): 484.9356\n",
      "Ep. 168 done, reward: -20.0, running_reward: -20.3879, time (sec): 490.2405\n",
      "Ep. 170 done, reward: -19.0, running_reward: -20.3702, time (sec): 496.1788\n",
      "Ep. 172 done, reward: -21.0, running_reward: -20.3827, time (sec): 502.0406\n",
      "Ep. 174 done, reward: -20.0, running_reward: -20.3751, time (sec): 508.1854\n",
      "Ep. 176 done, reward: -21.0, running_reward: -20.3776, time (sec): 514.4689\n",
      "Ep. 178 done, reward: -20.0, running_reward: -20.3701, time (sec): 519.7720\n",
      "Ep. 180 done, reward: -20.0, running_reward: -20.3628, time (sec): 526.0546\n",
      "Ep. 182 done, reward: -21.0, running_reward: -20.3754, time (sec): 532.2185\n",
      "Ep. 184 done, reward: -21.0, running_reward: -20.3879, time (sec): 538.0161\n",
      "Ep. 186 done, reward: -21.0, running_reward: -20.3902, time (sec): 542.6208\n",
      "Ep. 188 done, reward: -21.0, running_reward: -20.4023, time (sec): 547.0296\n",
      "Ep. 190 done, reward: -21.0, running_reward: -20.4043, time (sec): 553.1182\n",
      "Ep. 192 done, reward: -20.0, running_reward: -20.4061, time (sec): 559.1794\n",
      "Ep. 194 done, reward: -19.0, running_reward: -20.3881, time (sec): 567.9669\n",
      "Ep. 196 done, reward: -21.0, running_reward: -20.3903, time (sec): 573.6507\n",
      "Ep. 198 done, reward: -21.0, running_reward: -20.4025, time (sec): 579.7605\n",
      "Ep. 200 done, reward: -21.0, running_reward: -20.3649, time (sec): 587.3460\n",
      "Ep. 202 done, reward: -21.0, running_reward: -20.3577, time (sec): 592.1154\n",
      "Ep. 204 done, reward: -19.0, running_reward: -20.3307, time (sec): 599.7591\n",
      "Ep. 206 done, reward: -21.0, running_reward: -20.3044, time (sec): 606.5519\n",
      "Ep. 208 done, reward: -18.0, running_reward: -20.2882, time (sec): 613.2850\n",
      "Ep. 210 done, reward: -21.0, running_reward: -20.2925, time (sec): 620.3161\n",
      "Ep. 212 done, reward: -19.0, running_reward: -20.2767, time (sec): 627.5382\n",
      "Ep. 214 done, reward: -20.0, running_reward: -20.2712, time (sec): 634.5734\n",
      "Ep. 216 done, reward: -21.0, running_reward: -20.2560, time (sec): 642.6982\n",
      "Ep. 218 done, reward: -19.0, running_reward: -20.2508, time (sec): 649.1309\n",
      "Ep. 220 done, reward: -21.0, running_reward: -20.2657, time (sec): 654.7993\n",
      "Ep. 222 done, reward: -20.0, running_reward: -20.2604, time (sec): 660.6301\n",
      "Ep. 224 done, reward: -20.0, running_reward: -20.2651, time (sec): 666.6768\n",
      "Ep. 226 done, reward: -19.0, running_reward: -20.2498, time (sec): 671.9917\n",
      "Ep. 228 done, reward: -18.0, running_reward: -20.2249, time (sec): 678.6297\n",
      "Ep. 230 done, reward: -20.0, running_reward: -20.2303, time (sec): 684.3593\n",
      "Ep. 232 done, reward: -20.0, running_reward: -20.2356, time (sec): 689.8239\n",
      "Ep. 234 done, reward: -21.0, running_reward: -20.2508, time (sec): 695.8392\n",
      "Ep. 236 done, reward: -21.0, running_reward: -20.2459, time (sec): 701.1951\n",
      "Ep. 238 done, reward: -21.0, running_reward: -20.2114, time (sec): 706.7732\n",
      "Ep. 240 done, reward: -20.0, running_reward: -20.2171, time (sec): 711.9179\n",
      "Ep. 242 done, reward: -20.0, running_reward: -20.2029, time (sec): 717.3588\n",
      "Ep. 244 done, reward: -18.0, running_reward: -20.1789, time (sec): 723.0014\n",
      "Ep. 246 done, reward: -18.0, running_reward: -20.1652, time (sec): 728.7654\n",
      "Ep. 248 done, reward: -18.0, running_reward: -20.1518, time (sec): 735.0517\n",
      "Ep. 250 done, reward: -21.0, running_reward: -20.1489, time (sec): 742.3076\n",
      "Ep. 252 done, reward: -21.0, running_reward: -20.1559, time (sec): 750.9682\n",
      "Ep. 254 done, reward: -21.0, running_reward: -20.1628, time (sec): 757.1785\n",
      "Ep. 256 done, reward: -19.0, running_reward: -20.1397, time (sec): 764.3117\n",
      "Ep. 258 done, reward: -20.0, running_reward: -20.1270, time (sec): 770.5427\n",
      "Ep. 260 done, reward: -18.0, running_reward: -20.0847, time (sec): 780.0048\n",
      "Ep. 262 done, reward: -18.0, running_reward: -20.0729, time (sec): 786.6393\n",
      "Ep. 264 done, reward: -21.0, running_reward: -20.0914, time (sec): 792.5149\n",
      "Ep. 266 done, reward: -20.0, running_reward: -20.0994, time (sec): 800.0955\n",
      "Ep. 268 done, reward: -20.0, running_reward: -20.0876, time (sec): 809.4146\n",
      "Ep. 270 done, reward: -19.0, running_reward: -20.0659, time (sec): 815.8156\n",
      "Ep. 272 done, reward: -21.0, running_reward: -20.0647, time (sec): 823.6858\n",
      "Ep. 274 done, reward: -20.0, running_reward: -20.0634, time (sec): 831.1408\n",
      "Ep. 276 done, reward: -19.0, running_reward: -20.0522, time (sec): 837.7275\n",
      "Ep. 278 done, reward: -21.0, running_reward: -20.0413, time (sec): 844.8325\n",
      "Ep. 280 done, reward: -21.0, running_reward: -20.0505, time (sec): 851.5710\n",
      "Ep. 282 done, reward: -20.0, running_reward: -20.0495, time (sec): 858.0889\n",
      "Ep. 284 done, reward: -21.0, running_reward: -20.0585, time (sec): 865.5599\n",
      "Ep. 286 done, reward: -21.0, running_reward: -20.0574, time (sec): 872.7990\n",
      "Ep. 288 done, reward: -21.0, running_reward: -20.0762, time (sec): 881.5696\n",
      "Ep. 290 done, reward: -21.0, running_reward: -20.0847, time (sec): 888.5971\n",
      "Ep. 292 done, reward: -19.0, running_reward: -20.0829, time (sec): 894.6988\n",
      "Ep. 294 done, reward: -19.0, running_reward: -20.0811, time (sec): 902.4086\n",
      "Ep. 296 done, reward: -20.0, running_reward: -20.0894, time (sec): 909.7826\n",
      "Ep. 298 done, reward: -21.0, running_reward: -20.0977, time (sec): 916.5068\n",
      "Ep. 300 done, reward: -20.0, running_reward: -20.0957, time (sec): 922.1359\n",
      "Ep. 302 done, reward: -20.0, running_reward: -20.1037, time (sec): 927.3121\n",
      "Ep. 304 done, reward: -20.0, running_reward: -20.0917, time (sec): 938.2519\n",
      "Ep. 306 done, reward: -20.0, running_reward: -20.0899, time (sec): 945.4420\n",
      "Ep. 308 done, reward: -21.0, running_reward: -20.0882, time (sec): 954.5250\n",
      "Ep. 310 done, reward: -21.0, running_reward: -20.0965, time (sec): 962.3925\n",
      "Ep. 312 done, reward: -21.0, running_reward: -20.0947, time (sec): 970.3634\n",
      "Ep. 314 done, reward: -20.0, running_reward: -20.1027, time (sec): 977.2196\n",
      "Ep. 316 done, reward: -21.0, running_reward: -20.1007, time (sec): 985.4676\n",
      "Ep. 318 done, reward: -20.0, running_reward: -20.0888, time (sec): 993.7659\n",
      "Ep. 320 done, reward: -18.0, running_reward: -20.0770, time (sec): 1002.5459\n",
      "Ep. 322 done, reward: -19.0, running_reward: -20.0456, time (sec): 1010.1686\n",
      "Ep. 324 done, reward: -19.0, running_reward: -20.0050, time (sec): 1017.9706\n",
      "Ep. 326 done, reward: -21.0, running_reward: -19.9951, time (sec): 1025.3002\n",
      "Ep. 328 done, reward: -21.0, running_reward: -19.9656, time (sec): 1033.8515\n",
      "Ep. 330 done, reward: -19.0, running_reward: -19.9563, time (sec): 1041.9849\n",
      "Ep. 332 done, reward: -18.0, running_reward: -19.9273, time (sec): 1052.9257\n",
      "Ep. 334 done, reward: -20.0, running_reward: -19.9287, time (sec): 1060.6750\n",
      "Ep. 336 done, reward: -21.0, running_reward: -19.9203, time (sec): 1067.8787\n",
      "Ep. 338 done, reward: -20.0, running_reward: -19.9318, time (sec): 1073.9202\n",
      "Ep. 340 done, reward: -19.0, running_reward: -19.9232, time (sec): 1081.1306\n",
      "Ep. 342 done, reward: -21.0, running_reward: -19.9446, time (sec): 1087.2544\n",
      "Ep. 344 done, reward: -21.0, running_reward: -19.9458, time (sec): 1094.3247\n",
      "Ep. 346 done, reward: -19.0, running_reward: -19.9369, time (sec): 1103.4361\n",
      "Ep. 348 done, reward: -21.0, running_reward: -19.9481, time (sec): 1110.4141\n",
      "Ep. 350 done, reward: -16.0, running_reward: -19.8993, time (sec): 1119.2478\n",
      "Ep. 352 done, reward: -21.0, running_reward: -19.9113, time (sec): 1124.6167\n",
      "Ep. 354 done, reward: -20.0, running_reward: -19.9130, time (sec): 1131.3872\n",
      "Ep. 356 done, reward: -20.0, running_reward: -19.9049, time (sec): 1138.7417\n",
      "Ep. 358 done, reward: -21.0, running_reward: -19.9069, time (sec): 1145.6838\n",
      "Ep. 360 done, reward: -21.0, running_reward: -19.9187, time (sec): 1152.2895\n",
      "Ep. 362 done, reward: -20.0, running_reward: -19.9302, time (sec): 1160.5356\n",
      "Ep. 364 done, reward: -20.0, running_reward: -19.9316, time (sec): 1165.7632\n",
      "Ep. 366 done, reward: -21.0, running_reward: -19.9529, time (sec): 1171.5373\n",
      "Ep. 368 done, reward: -19.0, running_reward: -19.9240, time (sec): 1178.1064\n",
      "Ep. 370 done, reward: -18.0, running_reward: -19.8956, time (sec): 1186.5382\n",
      "Ep. 372 done, reward: -21.0, running_reward: -19.9176, time (sec): 1191.8703\n",
      "Ep. 374 done, reward: -20.0, running_reward: -19.9193, time (sec): 1198.0484\n",
      "Ep. 376 done, reward: -21.0, running_reward: -19.9309, time (sec): 1204.4524\n",
      "Ep. 378 done, reward: -21.0, running_reward: -19.9521, time (sec): 1210.4792\n",
      "Ep. 380 done, reward: -19.0, running_reward: -19.9332, time (sec): 1217.9032\n",
      "Ep. 382 done, reward: -20.0, running_reward: -19.9345, time (sec): 1224.5625\n",
      "Ep. 384 done, reward: -19.0, running_reward: -19.8961, time (sec): 1230.9025\n",
      "Ep. 386 done, reward: -19.0, running_reward: -19.8981, time (sec): 1237.2618\n",
      "Ep. 388 done, reward: -17.0, running_reward: -19.8602, time (sec): 1243.6415\n",
      "Ep. 390 done, reward: -21.0, running_reward: -19.8829, time (sec): 1248.9407\n",
      "Ep. 392 done, reward: -19.0, running_reward: -19.8851, time (sec): 1253.9969\n",
      "Ep. 394 done, reward: -19.0, running_reward: -19.8675, time (sec): 1259.6417\n",
      "Ep. 396 done, reward: -19.0, running_reward: -19.8502, time (sec): 1266.0458\n",
      "Ep. 398 done, reward: -21.0, running_reward: -19.8731, time (sec): 1271.7005\n",
      "Ep. 400 done, reward: -20.0, running_reward: -19.8856, time (sec): 1277.2255\n",
      "Ep. 402 done, reward: -21.0, running_reward: -19.8978, time (sec): 1282.4935\n",
      "Ep. 404 done, reward: -21.0, running_reward: -19.9099, time (sec): 1288.6665\n",
      "Ep. 406 done, reward: -19.0, running_reward: -19.9116, time (sec): 1294.8774\n",
      "Ep. 408 done, reward: -20.0, running_reward: -19.8935, time (sec): 1300.2558\n",
      "Ep. 410 done, reward: -19.0, running_reward: -19.8856, time (sec): 1306.8271\n",
      "Ep. 412 done, reward: -19.0, running_reward: -19.8878, time (sec): 1313.2407\n",
      "Ep. 414 done, reward: -21.0, running_reward: -19.9000, time (sec): 1319.1251\n",
      "Ep. 416 done, reward: -21.0, running_reward: -19.9219, time (sec): 1324.1518\n",
      "Ep. 418 done, reward: -17.0, running_reward: -19.9034, time (sec): 1330.7394\n",
      "Ep. 420 done, reward: -21.0, running_reward: -19.9252, time (sec): 1336.4691\n",
      "Ep. 422 done, reward: -21.0, running_reward: -19.9367, time (sec): 1342.2022\n",
      "Ep. 424 done, reward: -19.0, running_reward: -19.9181, time (sec): 1352.5520\n",
      "Ep. 426 done, reward: -19.0, running_reward: -19.8800, time (sec): 1358.6722\n",
      "Ep. 428 done, reward: -20.0, running_reward: -19.8824, time (sec): 1365.7386\n",
      "Ep. 430 done, reward: -20.0, running_reward: -19.8946, time (sec): 1372.3618\n",
      "Ep. 432 done, reward: -20.0, running_reward: -19.9066, time (sec): 1378.9905\n",
      "Ep. 434 done, reward: -21.0, running_reward: -19.9185, time (sec): 1384.6907\n",
      "Ep. 436 done, reward: -19.0, running_reward: -19.9101, time (sec): 1393.3182\n",
      "Ep. 438 done, reward: -20.0, running_reward: -19.9020, time (sec): 1402.5670\n",
      "Ep. 440 done, reward: -19.0, running_reward: -19.8840, time (sec): 1410.1322\n",
      "Ep. 442 done, reward: -20.0, running_reward: -19.8962, time (sec): 1416.7543\n",
      "Ep. 444 done, reward: -19.0, running_reward: -19.8982, time (sec): 1422.8799\n",
      "Ep. 446 done, reward: -20.0, running_reward: -19.9002, time (sec): 1429.7018\n",
      "Ep. 448 done, reward: -18.0, running_reward: -19.8822, time (sec): 1439.4343\n",
      "Ep. 450 done, reward: -21.0, running_reward: -19.9045, time (sec): 1447.4921\n",
      "Ep. 452 done, reward: -19.0, running_reward: -19.8964, time (sec): 1455.9999\n",
      "Ep. 454 done, reward: -19.0, running_reward: -19.8884, time (sec): 1464.3372\n",
      "Ep. 456 done, reward: -20.0, running_reward: -19.9005, time (sec): 1473.9575\n",
      "Ep. 458 done, reward: -20.0, running_reward: -19.9124, time (sec): 1483.3423\n",
      "Ep. 460 done, reward: -21.0, running_reward: -19.9341, time (sec): 1490.9365\n",
      "Ep. 462 done, reward: -21.0, running_reward: -19.9553, time (sec): 1497.5155\n",
      "Ep. 464 done, reward: -18.0, running_reward: -19.9263, time (sec): 1504.6094\n",
      "Ep. 466 done, reward: -20.0, running_reward: -19.9079, time (sec): 1514.2734\n",
      "Ep. 468 done, reward: -20.0, running_reward: -19.9197, time (sec): 1520.8931\n",
      "Ep. 470 done, reward: -21.0, running_reward: -19.9214, time (sec): 1527.1429\n",
      "Ep. 472 done, reward: -21.0, running_reward: -19.9428, time (sec): 1534.0564\n",
      "Ep. 474 done, reward: -21.0, running_reward: -19.9342, time (sec): 1540.8264\n",
      "Ep. 476 done, reward: -20.0, running_reward: -19.9256, time (sec): 1547.0045\n",
      "Ep. 478 done, reward: -21.0, running_reward: -19.9371, time (sec): 1552.7901\n",
      "Ep. 480 done, reward: -19.0, running_reward: -19.9184, time (sec): 1559.9945\n",
      "Ep. 482 done, reward: -20.0, running_reward: -19.9101, time (sec): 1566.8249\n",
      "Ep. 484 done, reward: -19.0, running_reward: -19.9118, time (sec): 1571.8774\n",
      "Ep. 486 done, reward: -21.0, running_reward: -19.9236, time (sec): 1578.8253\n",
      "Ep. 488 done, reward: -18.0, running_reward: -19.9051, time (sec): 1588.7552\n",
      "Ep. 490 done, reward: -21.0, running_reward: -19.8972, time (sec): 1596.9875\n",
      "Ep. 492 done, reward: -21.0, running_reward: -19.8993, time (sec): 1603.9569\n",
      "Ep. 494 done, reward: -20.0, running_reward: -19.8815, time (sec): 1612.2059\n",
      "Ep. 496 done, reward: -21.0, running_reward: -19.8642, time (sec): 1619.2804\n",
      "Ep. 498 done, reward: -20.0, running_reward: -19.8471, time (sec): 1625.9582\n",
      "Ep. 500 done, reward: -19.0, running_reward: -19.8401, time (sec): 1634.3407\n",
      "Ep. 502 done, reward: -18.0, running_reward: -19.8332, time (sec): 1640.7353\n",
      "Ep. 504 done, reward: -18.0, running_reward: -19.8264, time (sec): 1647.3851\n",
      "Ep. 506 done, reward: -20.0, running_reward: -19.8002, time (sec): 1653.8803\n",
      "Ep. 508 done, reward: -19.0, running_reward: -19.7744, time (sec): 1664.2166\n",
      "Ep. 510 done, reward: -20.0, running_reward: -19.7789, time (sec): 1672.0392\n",
      "Ep. 512 done, reward: -19.0, running_reward: -19.7733, time (sec): 1681.6714\n",
      "Ep. 514 done, reward: -21.0, running_reward: -19.7581, time (sec): 1691.3762\n",
      "Ep. 516 done, reward: -19.0, running_reward: -19.7529, time (sec): 1699.2937\n",
      "Ep. 518 done, reward: -21.0, running_reward: -19.7678, time (sec): 1706.8653\n",
      "Ep. 520 done, reward: -21.0, running_reward: -19.7725, time (sec): 1713.9638\n",
      "Ep. 522 done, reward: -19.0, running_reward: -19.7473, time (sec): 1722.4682\n",
      "Ep. 524 done, reward: -20.0, running_reward: -19.7424, time (sec): 1730.8944\n",
      "Ep. 526 done, reward: -17.0, running_reward: -19.7076, time (sec): 1739.9505\n",
      "Ep. 528 done, reward: -19.0, running_reward: -19.6935, time (sec): 1746.6572\n",
      "Ep. 530 done, reward: -20.0, running_reward: -19.6996, time (sec): 1754.7703\n",
      "Ep. 532 done, reward: -21.0, running_reward: -19.7255, time (sec): 1761.8365\n",
      "Ep. 534 done, reward: -18.0, running_reward: -19.7209, time (sec): 1769.2624\n",
      "Ep. 536 done, reward: -20.0, running_reward: -19.7165, time (sec): 1776.3121\n",
      "Ep. 538 done, reward: -19.0, running_reward: -19.7221, time (sec): 1783.3807\n",
      "Ep. 540 done, reward: -19.0, running_reward: -19.7176, time (sec): 1790.0655\n",
      "Ep. 542 done, reward: -18.0, running_reward: -19.6537, time (sec): 1798.0013\n",
      "Ep. 544 done, reward: -20.0, running_reward: -19.6507, time (sec): 1804.8164\n",
      "Ep. 546 done, reward: -21.0, running_reward: -19.6479, time (sec): 1810.6463\n",
      "Ep. 548 done, reward: -19.0, running_reward: -19.6548, time (sec): 1818.5633\n",
      "Ep. 550 done, reward: -19.0, running_reward: -19.6615, time (sec): 1825.4859\n",
      "Ep. 552 done, reward: -18.0, running_reward: -19.6186, time (sec): 1833.9294\n",
      "Ep. 554 done, reward: -19.0, running_reward: -19.5964, time (sec): 1842.3007\n",
      "Ep. 556 done, reward: -21.0, running_reward: -19.6045, time (sec): 1850.3798\n",
      "Ep. 558 done, reward: -17.0, running_reward: -19.5626, time (sec): 1858.6161\n",
      "Ep. 560 done, reward: -19.0, running_reward: -19.5613, time (sec): 1865.1080\n",
      "Ep. 562 done, reward: -21.0, running_reward: -19.5800, time (sec): 1871.1845\n",
      "Ep. 564 done, reward: -20.0, running_reward: -19.5983, time (sec): 1881.0041\n",
      "Ep. 566 done, reward: -19.0, running_reward: -19.6062, time (sec): 1888.5269\n",
      "Ep. 568 done, reward: -21.0, running_reward: -19.5943, time (sec): 1896.4810\n",
      "Ep. 570 done, reward: -21.0, running_reward: -19.6223, time (sec): 1904.1580\n",
      "Ep. 572 done, reward: -20.0, running_reward: -19.6199, time (sec): 1912.5012\n",
      "Ep. 574 done, reward: -20.0, running_reward: -19.6373, time (sec): 1919.7301\n",
      "Ep. 576 done, reward: -19.0, running_reward: -19.6445, time (sec): 1930.9898\n",
      "Ep. 578 done, reward: -20.0, running_reward: -19.6218, time (sec): 1939.8348\n",
      "Ep. 580 done, reward: -21.0, running_reward: -19.6394, time (sec): 1946.3786\n",
      "Ep. 582 done, reward: -21.0, running_reward: -19.6664, time (sec): 1953.1960\n",
      "Ep. 584 done, reward: -21.0, running_reward: -19.6831, time (sec): 1960.0660\n",
      "Ep. 586 done, reward: -21.0, running_reward: -19.7093, time (sec): 1966.8966\n",
      "Ep. 588 done, reward: -20.0, running_reward: -19.7250, time (sec): 1973.7621\n",
      "Ep. 590 done, reward: -21.0, running_reward: -19.7404, time (sec): 1983.3458\n",
      "Ep. 592 done, reward: -20.0, running_reward: -19.7555, time (sec): 1993.5825\n",
      "Ep. 594 done, reward: -21.0, running_reward: -19.7704, time (sec): 2001.4371\n",
      "Ep. 596 done, reward: -20.0, running_reward: -19.7848, time (sec): 2007.2751\n",
      "Ep. 598 done, reward: -21.0, running_reward: -19.7793, time (sec): 2014.9024\n",
      "Ep. 600 done, reward: -19.0, running_reward: -19.7638, time (sec): 2023.6130\n",
      "Ep. 602 done, reward: -20.0, running_reward: -19.7487, time (sec): 2031.4812\n",
      "Ep. 604 done, reward: -18.0, running_reward: -19.6743, time (sec): 2041.5105\n",
      "Ep. 606 done, reward: -21.0, running_reward: -19.6809, time (sec): 2047.5232\n",
      "Ep. 608 done, reward: -19.0, running_reward: -19.6772, time (sec): 2055.4915\n",
      "Ep. 610 done, reward: -19.0, running_reward: -19.6539, time (sec): 2068.0127\n",
      "Ep. 612 done, reward: -21.0, running_reward: -19.6411, time (sec): 2076.7574\n",
      "Ep. 614 done, reward: -19.0, running_reward: -19.6481, time (sec): 2085.7319\n",
      "Ep. 616 done, reward: -21.0, running_reward: -19.6651, time (sec): 2093.6908\n",
      "Ep. 618 done, reward: -21.0, running_reward: -19.6719, time (sec): 2102.1965\n",
      "Ep. 620 done, reward: -15.0, running_reward: -19.6185, time (sec): 2114.3546\n",
      "Ep. 622 done, reward: -20.0, running_reward: -19.6063, time (sec): 2125.4336\n",
      "Ep. 624 done, reward: -20.0, running_reward: -19.6240, time (sec): 2134.5113\n",
      "Ep. 626 done, reward: -21.0, running_reward: -19.6118, time (sec): 2143.9036\n",
      "Ep. 628 done, reward: -20.0, running_reward: -19.6096, time (sec): 2151.8615\n",
      "Ep. 630 done, reward: -19.0, running_reward: -19.6074, time (sec): 2159.9797\n",
      "Ep. 632 done, reward: -20.0, running_reward: -19.6251, time (sec): 2167.3704\n",
      "Ep. 634 done, reward: -21.0, running_reward: -19.6030, time (sec): 2176.0400\n",
      "Ep. 636 done, reward: -19.0, running_reward: -19.6108, time (sec): 2183.4769\n",
      "Ep. 638 done, reward: -19.0, running_reward: -19.6085, time (sec): 2191.9063\n",
      "Ep. 640 done, reward: -16.0, running_reward: -19.5862, time (sec): 2200.9304\n",
      "Ep. 642 done, reward: -19.0, running_reward: -19.5745, time (sec): 2207.7314\n",
      "Ep. 644 done, reward: -18.0, running_reward: -19.5333, time (sec): 2215.0631\n",
      "Ep. 646 done, reward: -21.0, running_reward: -19.5328, time (sec): 2222.2935\n",
      "Ep. 648 done, reward: -20.0, running_reward: -19.5520, time (sec): 2228.9518\n",
      "Ep. 650 done, reward: -19.0, running_reward: -19.5311, time (sec): 2236.5289\n",
      "Ep. 652 done, reward: -20.0, running_reward: -19.5305, time (sec): 2245.2655\n",
      "Ep. 654 done, reward: -19.0, running_reward: -19.5200, time (sec): 2253.6748\n",
      "Ep. 656 done, reward: -16.0, running_reward: -19.4895, time (sec): 2260.9559\n",
      "Ep. 658 done, reward: -20.0, running_reward: -19.4898, time (sec): 2269.4681\n",
      "Ep. 660 done, reward: -18.0, running_reward: -19.4403, time (sec): 2279.1704\n",
      "Ep. 662 done, reward: -20.0, running_reward: -19.4416, time (sec): 2286.8537\n",
      "Ep. 664 done, reward: -19.0, running_reward: -19.4427, time (sec): 2295.8702\n",
      "Ep. 666 done, reward: -16.0, running_reward: -19.4138, time (sec): 2304.9923\n",
      "Ep. 668 done, reward: -19.0, running_reward: -19.4056, time (sec): 2313.1985\n",
      "Ep. 670 done, reward: -13.0, running_reward: -19.3375, time (sec): 2323.0036\n",
      "Ep. 672 done, reward: -17.0, running_reward: -19.2910, time (sec): 2332.4134\n",
      "Ep. 674 done, reward: -21.0, running_reward: -19.3052, time (sec): 2342.7623\n",
      "Ep. 676 done, reward: -15.0, running_reward: -19.2393, time (sec): 2351.9641\n",
      "Ep. 678 done, reward: -20.0, running_reward: -19.2643, time (sec): 2358.8422\n",
      "Ep. 680 done, reward: -21.0, running_reward: -19.2890, time (sec): 2366.0040\n",
      "Ep. 682 done, reward: -19.0, running_reward: -19.2535, time (sec): 2375.8802\n",
      "Ep. 684 done, reward: -19.0, running_reward: -19.2386, time (sec): 2384.9492\n",
      "Ep. 686 done, reward: -17.0, running_reward: -19.1940, time (sec): 2394.5712\n",
      "Ep. 688 done, reward: -17.0, running_reward: -19.1702, time (sec): 2403.7158\n",
      "Ep. 690 done, reward: -18.0, running_reward: -19.1370, time (sec): 2413.0623\n",
      "Ep. 692 done, reward: -16.0, running_reward: -19.0944, time (sec): 2424.1291\n",
      "Ep. 694 done, reward: -16.0, running_reward: -19.0823, time (sec): 2433.3739\n",
      "Ep. 696 done, reward: -17.0, running_reward: -19.0606, time (sec): 2442.8792\n",
      "Ep. 698 done, reward: -19.0, running_reward: -19.0594, time (sec): 2453.3705\n",
      "Ep. 700 done, reward: -19.0, running_reward: -19.0385, time (sec): 2463.7289\n",
      "Ep. 702 done, reward: -19.0, running_reward: -19.0278, time (sec): 2472.2710\n",
      "Ep. 704 done, reward: -20.0, running_reward: -19.0372, time (sec): 2482.4156\n",
      "Ep. 706 done, reward: -18.0, running_reward: -19.0166, time (sec): 2491.8231\n",
      "Ep. 708 done, reward: -19.0, running_reward: -19.0163, time (sec): 2502.5027\n",
      "Ep. 710 done, reward: -19.0, running_reward: -19.0060, time (sec): 2513.0365\n",
      "Ep. 712 done, reward: -19.0, running_reward: -19.0059, time (sec): 2525.7350\n",
      "Ep. 714 done, reward: -21.0, running_reward: -19.0060, time (sec): 2535.0341\n",
      "Ep. 716 done, reward: -18.0, running_reward: -18.9959, time (sec): 2546.4920\n",
      "Ep. 718 done, reward: -17.0, running_reward: -18.9958, time (sec): 2556.2858\n",
      "Ep. 720 done, reward: -21.0, running_reward: -19.0060, time (sec): 2565.0370\n",
      "Ep. 722 done, reward: -20.0, running_reward: -19.0158, time (sec): 2574.0248\n",
      "Ep. 724 done, reward: -19.0, running_reward: -19.0254, time (sec): 2586.3789\n",
      "Ep. 726 done, reward: -20.0, running_reward: -18.9854, time (sec): 2597.2345\n",
      "Ep. 728 done, reward: -20.0, running_reward: -18.9858, time (sec): 2606.1687\n",
      "Ep. 730 done, reward: -20.0, running_reward: -18.9961, time (sec): 2615.9472\n",
      "Ep. 732 done, reward: -14.0, running_reward: -18.9660, time (sec): 2626.2066\n",
      "Ep. 734 done, reward: -20.0, running_reward: -18.9766, time (sec): 2635.6838\n",
      "Ep. 736 done, reward: -21.0, running_reward: -19.0169, time (sec): 2648.1606\n",
      "Ep. 738 done, reward: -19.0, running_reward: -19.0166, time (sec): 2658.7429\n",
      "Ep. 740 done, reward: -20.0, running_reward: -19.0361, time (sec): 2669.8730\n",
      "Ep. 742 done, reward: -19.0, running_reward: -19.0354, time (sec): 2684.3133\n",
      "Ep. 744 done, reward: -21.0, running_reward: -19.0448, time (sec): 2694.8748\n",
      "Ep. 746 done, reward: -20.0, running_reward: -19.0539, time (sec): 2705.7369\n",
      "Ep. 748 done, reward: -21.0, running_reward: -19.0630, time (sec): 2714.5731\n",
      "Ep. 750 done, reward: -20.0, running_reward: -19.0717, time (sec): 2723.0135\n",
      "Ep. 752 done, reward: -18.0, running_reward: -19.0801, time (sec): 2732.0937\n",
      "Ep. 754 done, reward: -16.0, running_reward: -19.0584, time (sec): 2742.6043\n",
      "Ep. 756 done, reward: -19.0, running_reward: -19.0671, time (sec): 2753.6076\n",
      "Ep. 758 done, reward: -17.0, running_reward: -19.0260, time (sec): 2763.1986\n",
      "Ep. 760 done, reward: -19.0, running_reward: -19.0255, time (sec): 2774.4377\n",
      "Ep. 762 done, reward: -17.0, running_reward: -19.0248, time (sec): 2782.8378\n",
      "Ep. 764 done, reward: -21.0, running_reward: -19.0641, time (sec): 2799.2150\n",
      "Ep. 766 done, reward: -20.0, running_reward: -19.0827, time (sec): 2811.0160\n",
      "Ep. 768 done, reward: -19.0, running_reward: -19.0909, time (sec): 2822.6494\n",
      "Ep. 770 done, reward: -21.0, running_reward: -19.1289, time (sec): 2831.4499\n",
      "Ep. 772 done, reward: -19.0, running_reward: -19.1264, time (sec): 2841.2700\n",
      "Ep. 774 done, reward: -21.0, running_reward: -19.1241, time (sec): 2852.2808\n",
      "Ep. 776 done, reward: -19.0, running_reward: -19.1018, time (sec): 2868.5125\n",
      "Ep. 778 done, reward: -17.0, running_reward: -19.0897, time (sec): 2879.7892\n",
      "Ep. 780 done, reward: -21.0, running_reward: -19.1178, time (sec): 2889.7506\n",
      "Ep. 782 done, reward: -17.0, running_reward: -19.0756, time (sec): 2900.5417\n",
      "Ep. 784 done, reward: -20.0, running_reward: -19.0841, time (sec): 2909.4417\n",
      "Ep. 786 done, reward: -17.0, running_reward: -19.0724, time (sec): 2917.4630\n",
      "Ep. 788 done, reward: -18.0, running_reward: -19.0807, time (sec): 2926.2238\n",
      "Ep. 790 done, reward: -10.0, running_reward: -18.9792, time (sec): 2937.9823\n",
      "Ep. 792 done, reward: -21.0, running_reward: -19.0194, time (sec): 2945.0626\n",
      "Ep. 794 done, reward: -20.0, running_reward: -19.0389, time (sec): 2954.5081\n",
      "Ep. 796 done, reward: -19.0, running_reward: -19.0481, time (sec): 2962.0007\n",
      "Ep. 798 done, reward: -21.0, running_reward: -19.0869, time (sec): 2969.8492\n",
      "Ep. 800 done, reward: -19.0, running_reward: -19.0753, time (sec): 2978.8249\n",
      "Ep. 802 done, reward: -17.0, running_reward: -19.0637, time (sec): 2988.6350\n",
      "Ep. 804 done, reward: -19.0, running_reward: -19.0426, time (sec): 2998.8750\n",
      "Ep. 806 done, reward: -18.0, running_reward: -19.0516, time (sec): 3009.3460\n",
      "Ep. 808 done, reward: -17.0, running_reward: -19.0206, time (sec): 3019.6947\n",
      "Ep. 810 done, reward: -20.0, running_reward: -19.0401, time (sec): 3028.2122\n",
      "Ep. 812 done, reward: -19.0, running_reward: -19.0393, time (sec): 3036.7431\n",
      "Ep. 814 done, reward: -19.0, running_reward: -18.9791, time (sec): 3046.9084\n",
      "Ep. 816 done, reward: -20.0, running_reward: -19.0094, time (sec): 3056.2371\n",
      "Ep. 818 done, reward: -18.0, running_reward: -18.9398, time (sec): 3066.9878\n",
      "Ep. 820 done, reward: -16.0, running_reward: -18.9308, time (sec): 3078.0620\n",
      "Ep. 822 done, reward: -19.0, running_reward: -18.9519, time (sec): 3089.4207\n",
      "Ep. 824 done, reward: -20.0, running_reward: -18.9827, time (sec): 3099.0000\n",
      "Ep. 826 done, reward: -17.0, running_reward: -18.9729, time (sec): 3109.5040\n",
      "Ep. 828 done, reward: -18.0, running_reward: -18.9734, time (sec): 3120.9338\n",
      "Ep. 830 done, reward: -20.0, running_reward: -18.9641, time (sec): 3130.7823\n",
      "Ep. 832 done, reward: -20.0, running_reward: -18.9550, time (sec): 3140.3835\n",
      "Ep. 834 done, reward: -18.0, running_reward: -18.9558, time (sec): 3152.5448\n",
      "Ep. 836 done, reward: -14.0, running_reward: -18.9067, time (sec): 3166.2253\n",
      "Ep. 838 done, reward: -19.0, running_reward: -18.9086, time (sec): 3178.1489\n",
      "Ep. 840 done, reward: -19.0, running_reward: -18.8807, time (sec): 3190.5858\n",
      "Ep. 842 done, reward: -19.0, running_reward: -18.8930, time (sec): 3202.8927\n",
      "Ep. 844 done, reward: -19.0, running_reward: -18.9050, time (sec): 3212.2155\n",
      "Ep. 846 done, reward: -17.0, running_reward: -18.8869, time (sec): 3222.0898\n",
      "Ep. 848 done, reward: -21.0, running_reward: -18.8794, time (sec): 3233.3782\n",
      "Ep. 850 done, reward: -19.0, running_reward: -18.8917, time (sec): 3241.5393\n",
      "Ep. 852 done, reward: -21.0, running_reward: -18.8743, time (sec): 3253.3909\n",
      "Ep. 854 done, reward: -21.0, running_reward: -18.8968, time (sec): 3265.8861\n",
      "Ep. 856 done, reward: -19.0, running_reward: -18.8988, time (sec): 3274.4119\n",
      "Ep. 858 done, reward: -19.0, running_reward: -18.8810, time (sec): 3286.2847\n",
      "Ep. 860 done, reward: -17.0, running_reward: -18.8832, time (sec): 3298.1253\n",
      "Ep. 862 done, reward: -19.0, running_reward: -18.8954, time (sec): 3306.8639\n",
      "Ep. 864 done, reward: -20.0, running_reward: -18.8778, time (sec): 3318.9173\n",
      "Ep. 866 done, reward: -19.0, running_reward: -18.9001, time (sec): 3328.1949\n",
      "Ep. 868 done, reward: -17.0, running_reward: -18.8919, time (sec): 3339.8618\n",
      "Ep. 870 done, reward: -17.0, running_reward: -18.8543, time (sec): 3350.2140\n",
      "Ep. 872 done, reward: -18.0, running_reward: -18.8472, time (sec): 3360.5667\n",
      "Ep. 874 done, reward: -18.0, running_reward: -18.8204, time (sec): 3370.0069\n",
      "Ep. 876 done, reward: -19.0, running_reward: -18.8141, time (sec): 3379.1129\n",
      "Ep. 878 done, reward: -18.0, running_reward: -18.8276, time (sec): 3389.0108\n",
      "Ep. 880 done, reward: -17.0, running_reward: -18.8209, time (sec): 3398.3739\n",
      "Ep. 882 done, reward: -19.0, running_reward: -18.8245, time (sec): 3410.1641\n",
      "Ep. 884 done, reward: -18.0, running_reward: -18.8180, time (sec): 3418.0976\n",
      "Ep. 886 done, reward: -20.0, running_reward: -18.8118, time (sec): 3427.1637\n",
      "Ep. 888 done, reward: -15.0, running_reward: -18.7558, time (sec): 3438.1125\n",
      "Ep. 890 done, reward: -20.0, running_reward: -18.7706, time (sec): 3446.8037\n",
      "Ep. 892 done, reward: -20.0, running_reward: -18.7753, time (sec): 3455.9455\n",
      "Ep. 894 done, reward: -16.0, running_reward: -18.7300, time (sec): 3467.0580\n",
      "Ep. 896 done, reward: -17.0, running_reward: -18.7153, time (sec): 3478.6451\n",
      "Ep. 898 done, reward: -17.0, running_reward: -18.6713, time (sec): 3489.5950\n",
      "Ep. 900 done, reward: -19.0, running_reward: -18.6778, time (sec): 3499.3664\n",
      "Ep. 902 done, reward: -18.0, running_reward: -18.6841, time (sec): 3508.5756\n",
      "Ep. 904 done, reward: -20.0, running_reward: -18.7202, time (sec): 3518.4289\n",
      "Ep. 906 done, reward: -16.0, running_reward: -18.6958, time (sec): 3528.8191\n",
      "Ep. 908 done, reward: -18.0, running_reward: -18.7018, time (sec): 3537.7790\n",
      "Ep. 910 done, reward: -20.0, running_reward: -18.7276, time (sec): 3547.7656\n",
      "Ep. 912 done, reward: -20.0, running_reward: -18.7232, time (sec): 3558.2234\n",
      "Ep. 914 done, reward: -20.0, running_reward: -18.7288, time (sec): 3567.9994\n",
      "Ep. 916 done, reward: -20.0, running_reward: -18.7442, time (sec): 3578.1739\n",
      "Ep. 918 done, reward: -19.0, running_reward: -18.7196, time (sec): 3588.1942\n",
      "Ep. 920 done, reward: -18.0, running_reward: -18.7053, time (sec): 3598.4968\n",
      "Ep. 922 done, reward: -17.0, running_reward: -18.6911, time (sec): 3609.9686\n",
      "Ep. 924 done, reward: -19.0, running_reward: -18.6577, time (sec): 3620.0503\n",
      "Ep. 926 done, reward: -19.0, running_reward: -18.6348, time (sec): 3630.2897\n",
      "Ep. 928 done, reward: -17.0, running_reward: -18.6023, time (sec): 3641.9044\n",
      "Ep. 930 done, reward: -17.0, running_reward: -18.6100, time (sec): 3651.8974\n",
      "Ep. 932 done, reward: -18.0, running_reward: -18.6177, time (sec): 3660.9592\n",
      "Ep. 934 done, reward: -18.0, running_reward: -18.6054, time (sec): 3671.8790\n",
      "Ep. 936 done, reward: -21.0, running_reward: -18.5738, time (sec): 3681.9682\n",
      "Ep. 938 done, reward: -19.0, running_reward: -18.5922, time (sec): 3691.4756\n",
      "Ep. 940 done, reward: -19.0, running_reward: -18.5904, time (sec): 3700.2560\n",
      "Ep. 942 done, reward: -19.0, running_reward: -18.5788, time (sec): 3710.5170\n",
      "Ep. 944 done, reward: -19.0, running_reward: -18.5970, time (sec): 3719.1587\n",
      "Ep. 946 done, reward: -21.0, running_reward: -18.6053, time (sec): 3731.1404\n",
      "Ep. 948 done, reward: -19.0, running_reward: -18.5933, time (sec): 3741.6441\n",
      "Ep. 950 done, reward: -19.0, running_reward: -18.5816, time (sec): 3751.1223\n",
      "Ep. 952 done, reward: -16.0, running_reward: -18.5599, time (sec): 3760.9372\n",
      "Ep. 954 done, reward: -19.0, running_reward: -18.5687, time (sec): 3771.9758\n",
      "Ep. 956 done, reward: -19.0, running_reward: -18.5773, time (sec): 3781.6481\n",
      "Ep. 958 done, reward: -15.0, running_reward: -18.5259, time (sec): 3792.8974\n",
      "Ep. 960 done, reward: -19.0, running_reward: -18.5353, time (sec): 3803.7326\n",
      "Ep. 962 done, reward: -18.0, running_reward: -18.5148, time (sec): 3813.9209\n",
      "Ep. 964 done, reward: -17.0, running_reward: -18.5242, time (sec): 3824.6566\n",
      "Ep. 966 done, reward: -17.0, running_reward: -18.5137, time (sec): 3834.9300\n",
      "Ep. 968 done, reward: -17.0, running_reward: -18.5034, time (sec): 3845.3428\n",
      "Ep. 970 done, reward: -21.0, running_reward: -18.5333, time (sec): 3855.8306\n",
      "Ep. 972 done, reward: -19.0, running_reward: -18.4633, time (sec): 3867.0723\n",
      "Ep. 974 done, reward: -17.0, running_reward: -18.4243, time (sec): 3878.5029\n",
      "Ep. 976 done, reward: -19.0, running_reward: -18.4259, time (sec): 3888.8853\n",
      "Ep. 978 done, reward: -19.0, running_reward: -18.4373, time (sec): 3896.7936\n",
      "Ep. 980 done, reward: -19.0, running_reward: -18.4485, time (sec): 3906.6881\n",
      "Ep. 982 done, reward: -16.0, running_reward: -18.3998, time (sec): 3917.0903\n",
      "Ep. 984 done, reward: -15.0, running_reward: -18.3717, time (sec): 3927.9859\n",
      "Ep. 986 done, reward: -16.0, running_reward: -18.3542, time (sec): 3938.6211\n",
      "Ep. 988 done, reward: -16.0, running_reward: -18.3371, time (sec): 3949.1749\n",
      "Ep. 990 done, reward: -19.0, running_reward: -18.3404, time (sec): 3959.9540\n",
      "Ep. 992 done, reward: -19.0, running_reward: -18.3634, time (sec): 3970.6233\n",
      "Ep. 994 done, reward: -20.0, running_reward: -18.3762, time (sec): 3980.4716\n",
      "Ep. 996 done, reward: -19.0, running_reward: -18.3787, time (sec): 3989.5176\n",
      "Ep. 998 done, reward: -13.0, running_reward: -18.3112, time (sec): 4001.4615\n",
      "Ep. 1000 done, reward: -20.0, running_reward: -18.3349, time (sec): 4010.9746\n",
      "Ep. 1002 done, reward: -21.0, running_reward: -18.3682, time (sec): 4020.5939\n",
      "Ep. 1004 done, reward: -17.0, running_reward: -18.3608, time (sec): 4031.5756\n",
      "Ep. 1006 done, reward: -18.0, running_reward: -18.3536, time (sec): 4041.8457\n",
      "Ep. 1008 done, reward: -14.0, running_reward: -18.3065, time (sec): 4053.3155\n",
      "Ep. 1010 done, reward: -18.0, running_reward: -18.2806, time (sec): 4066.1110\n",
      "Ep. 1012 done, reward: -19.0, running_reward: -18.2653, time (sec): 4076.7486\n",
      "Ep. 1014 done, reward: -18.0, running_reward: -18.2402, time (sec): 4086.4000\n",
      "Ep. 1016 done, reward: -21.0, running_reward: -18.2555, time (sec): 4096.0825\n",
      "Ep. 1018 done, reward: -16.0, running_reward: -18.2502, time (sec): 4107.6864\n",
      "Ep. 1020 done, reward: -20.0, running_reward: -18.2553, time (sec): 4118.3979\n",
      "Ep. 1022 done, reward: -21.0, running_reward: -18.2704, time (sec): 4128.9631\n",
      "Ep. 1024 done, reward: -19.0, running_reward: -18.2750, time (sec): 4139.2445\n",
      "Ep. 1026 done, reward: -21.0, running_reward: -18.2896, time (sec): 4151.2745\n",
      "Ep. 1028 done, reward: -20.0, running_reward: -18.2939, time (sec): 4162.4066\n",
      "Ep. 1030 done, reward: -15.0, running_reward: -18.2680, time (sec): 4172.3108\n",
      "Ep. 1032 done, reward: -19.0, running_reward: -18.2331, time (sec): 4183.0076\n",
      "Ep. 1034 done, reward: -21.0, running_reward: -18.2683, time (sec): 4192.8170\n",
      "Ep. 1036 done, reward: -11.0, running_reward: -18.1732, time (sec): 4205.9528\n",
      "Ep. 1038 done, reward: -16.0, running_reward: -18.1398, time (sec): 4217.7892\n",
      "Ep. 1040 done, reward: -21.0, running_reward: -18.1769, time (sec): 4227.9292\n",
      "Ep. 1042 done, reward: -13.0, running_reward: -18.1135, time (sec): 4240.2600\n",
      "Ep. 1044 done, reward: -16.0, running_reward: -18.0913, time (sec): 4250.9160\n",
      "Ep. 1046 done, reward: -19.0, running_reward: -18.0797, time (sec): 4262.1679\n",
      "Ep. 1048 done, reward: -14.0, running_reward: -18.0084, time (sec): 4275.1681\n",
      "Ep. 1050 done, reward: -19.0, running_reward: -17.9984, time (sec): 4287.4074\n",
      "Ep. 1052 done, reward: -15.0, running_reward: -17.9387, time (sec): 4299.4909\n",
      "Ep. 1054 done, reward: -19.0, running_reward: -17.9005, time (sec): 4310.7850\n",
      "Ep. 1056 done, reward: -14.0, running_reward: -17.8723, time (sec): 4322.7085\n",
      "Ep. 1058 done, reward: -14.0, running_reward: -17.7953, time (sec): 4336.1471\n",
      "Ep. 1060 done, reward: -19.0, running_reward: -17.8093, time (sec): 4347.1232\n",
      "Ep. 1062 done, reward: -16.0, running_reward: -17.7733, time (sec): 4358.9907\n",
      "Ep. 1064 done, reward: -20.0, running_reward: -17.7979, time (sec): 4369.3087\n",
      "Ep. 1066 done, reward: -17.0, running_reward: -17.7820, time (sec): 4380.0512\n",
      "Ep. 1068 done, reward: -19.0, running_reward: -17.7963, time (sec): 4390.2373\n",
      "Ep. 1070 done, reward: -18.0, running_reward: -17.8004, time (sec): 4400.6926\n",
      "Ep. 1072 done, reward: -21.0, running_reward: -17.8244, time (sec): 4412.1304\n",
      "Ep. 1074 done, reward: -20.0, running_reward: -17.8578, time (sec): 4422.8040\n",
      "Ep. 1076 done, reward: -19.0, running_reward: -17.8806, time (sec): 4432.2050\n",
      "Ep. 1078 done, reward: -18.0, running_reward: -17.8829, time (sec): 4442.8278\n",
      "Ep. 1080 done, reward: -15.0, running_reward: -17.8454, time (sec): 4454.8269\n",
      "Ep. 1082 done, reward: -21.0, running_reward: -17.8685, time (sec): 4465.0563\n",
      "Ep. 1084 done, reward: -15.0, running_reward: -17.7917, time (sec): 4477.3761\n",
      "Ep. 1086 done, reward: -13.0, running_reward: -17.7359, time (sec): 4489.0006\n",
      "Ep. 1088 done, reward: -20.0, running_reward: -17.7414, time (sec): 4497.4838\n",
      "Ep. 1090 done, reward: -17.0, running_reward: -17.6969, time (sec): 4510.4337\n",
      "Ep. 1092 done, reward: -13.0, running_reward: -17.6727, time (sec): 4522.1086\n",
      "Ep. 1094 done, reward: -17.0, running_reward: -17.6594, time (sec): 4534.8428\n",
      "Ep. 1096 done, reward: -19.0, running_reward: -17.6563, time (sec): 4546.2033\n",
      "Ep. 1098 done, reward: -16.0, running_reward: -17.6234, time (sec): 4559.4457\n",
      "Ep. 1100 done, reward: -19.0, running_reward: -17.5914, time (sec): 4570.1016\n",
      "Ep. 1102 done, reward: -15.0, running_reward: -17.5794, time (sec): 4581.0204\n",
      "Ep. 1104 done, reward: -17.0, running_reward: -17.5679, time (sec): 4592.1314\n",
      "Ep. 1106 done, reward: -16.0, running_reward: -17.5268, time (sec): 4604.4290\n",
      "Ep. 1108 done, reward: -21.0, running_reward: -17.5563, time (sec): 4615.8655\n",
      "Ep. 1110 done, reward: -17.0, running_reward: -17.5056, time (sec): 4627.6145\n",
      "Ep. 1112 done, reward: -21.0, running_reward: -17.5455, time (sec): 4638.0624\n",
      "Ep. 1114 done, reward: -21.0, running_reward: -17.6142, time (sec): 4648.0509\n",
      "Ep. 1116 done, reward: -19.0, running_reward: -17.6220, time (sec): 4659.7076\n",
      "Ep. 1118 done, reward: -19.0, running_reward: -17.6197, time (sec): 4670.8177\n",
      "Ep. 1120 done, reward: -17.0, running_reward: -17.6371, time (sec): 4683.5071\n",
      "Ep. 1122 done, reward: -18.0, running_reward: -17.6245, time (sec): 4693.9393\n",
      "Ep. 1124 done, reward: -17.0, running_reward: -17.5923, time (sec): 4704.8589\n",
      "Ep. 1126 done, reward: -19.0, running_reward: -17.6005, time (sec): 4715.3650\n",
      "Ep. 1128 done, reward: -17.0, running_reward: -17.6182, time (sec): 4727.3756\n",
      "Ep. 1130 done, reward: -17.0, running_reward: -17.5663, time (sec): 4739.2477\n",
      "Ep. 1132 done, reward: -15.0, running_reward: -17.5549, time (sec): 4752.8894\n",
      "Ep. 1134 done, reward: -19.0, running_reward: -17.5539, time (sec): 4765.2565\n",
      "Ep. 1136 done, reward: -13.0, running_reward: -17.5227, time (sec): 4777.3273\n",
      "Ep. 1138 done, reward: -13.0, running_reward: -17.5119, time (sec): 4788.7973\n",
      "Ep. 1140 done, reward: -17.0, running_reward: -17.5314, time (sec): 4800.5632\n",
      "Ep. 1142 done, reward: -17.0, running_reward: -17.5406, time (sec): 4812.9203\n",
      "Ep. 1144 done, reward: -16.0, running_reward: -17.5001, time (sec): 4826.1087\n",
      "Ep. 1146 done, reward: -20.0, running_reward: -17.5201, time (sec): 4837.7065\n",
      "Ep. 1148 done, reward: -17.0, running_reward: -17.5494, time (sec): 4850.1855\n",
      "Ep. 1150 done, reward: -16.0, running_reward: -17.5581, time (sec): 4860.7094\n",
      "Ep. 1152 done, reward: -19.0, running_reward: -17.5868, time (sec): 4871.6631\n",
      "Ep. 1154 done, reward: -17.0, running_reward: -17.6147, time (sec): 4882.6764\n",
      "Ep. 1156 done, reward: -18.0, running_reward: -17.6323, time (sec): 4894.1459\n",
      "Ep. 1158 done, reward: -16.0, running_reward: -17.5998, time (sec): 4904.6366\n",
      "Ep. 1160 done, reward: -18.0, running_reward: -17.6177, time (sec): 4916.2274\n",
      "Ep. 1162 done, reward: -19.0, running_reward: -17.6452, time (sec): 4928.3025\n",
      "Ep. 1164 done, reward: -16.0, running_reward: -17.6620, time (sec): 4939.2682\n",
      "Ep. 1166 done, reward: -15.0, running_reward: -17.6288, time (sec): 4949.8957\n",
      "Ep. 1168 done, reward: -17.0, running_reward: -17.6163, time (sec): 4960.4735\n",
      "Ep. 1170 done, reward: -17.0, running_reward: -17.5743, time (sec): 4973.6280\n",
      "Ep. 1172 done, reward: -17.0, running_reward: -17.5926, time (sec): 4984.7939\n",
      "Ep. 1174 done, reward: -16.0, running_reward: -17.6005, time (sec): 4997.0675\n",
      "Ep. 1176 done, reward: -19.0, running_reward: -17.5689, time (sec): 5008.9372\n",
      "Ep. 1178 done, reward: -15.0, running_reward: -17.5574, time (sec): 5021.0052\n",
      "Ep. 1180 done, reward: -17.0, running_reward: -17.5562, time (sec): 5034.6680\n",
      "Ep. 1182 done, reward: -18.0, running_reward: -17.5750, time (sec): 5044.7696\n",
      "Ep. 1184 done, reward: -18.0, running_reward: -17.5735, time (sec): 5056.3488\n",
      "Ep. 1186 done, reward: -20.0, running_reward: -17.6119, time (sec): 5068.5241\n",
      "Ep. 1188 done, reward: -14.0, running_reward: -17.5895, time (sec): 5079.6925\n",
      "Ep. 1190 done, reward: -19.0, running_reward: -17.6374, time (sec): 5089.6113\n",
      "Ep. 1192 done, reward: -16.0, running_reward: -17.6345, time (sec): 5101.1437\n",
      "Ep. 1194 done, reward: -19.0, running_reward: -17.6617, time (sec): 5111.0528\n",
      "Ep. 1196 done, reward: -17.0, running_reward: -17.6386, time (sec): 5122.5050\n",
      "Ep. 1198 done, reward: -17.0, running_reward: -17.6358, time (sec): 5133.1792\n",
      "Ep. 1200 done, reward: -20.0, running_reward: -17.6334, time (sec): 5144.9861\n",
      "Ep. 1202 done, reward: -21.0, running_reward: -17.6410, time (sec): 5156.3787\n",
      "Ep. 1204 done, reward: -17.0, running_reward: -17.6282, time (sec): 5169.2083\n",
      "Ep. 1206 done, reward: -19.0, running_reward: -17.6357, time (sec): 5179.5475\n",
      "Ep. 1208 done, reward: -19.0, running_reward: -17.6430, time (sec): 5191.7453\n",
      "Ep. 1210 done, reward: -17.0, running_reward: -17.6302, time (sec): 5203.2712\n",
      "Ep. 1212 done, reward: -19.0, running_reward: -17.5882, time (sec): 5215.1655\n",
      "Ep. 1214 done, reward: -10.0, running_reward: -17.5065, time (sec): 5229.7758\n",
      "Ep. 1216 done, reward: -17.0, running_reward: -17.5162, time (sec): 5240.6403\n",
      "Ep. 1218 done, reward: -18.0, running_reward: -17.5160, time (sec): 5252.4121\n",
      "Ep. 1220 done, reward: -18.0, running_reward: -17.5058, time (sec): 5265.6579\n",
      "Ep. 1222 done, reward: -16.0, running_reward: -17.4560, time (sec): 5276.8817\n",
      "Ep. 1224 done, reward: -14.0, running_reward: -17.4268, time (sec): 5290.4563\n",
      "Ep. 1226 done, reward: -19.0, running_reward: -17.4383, time (sec): 5302.5856\n",
      "Ep. 1228 done, reward: -19.0, running_reward: -17.4694, time (sec): 5313.4651\n",
      "Ep. 1230 done, reward: -13.0, running_reward: -17.4399, time (sec): 5325.4277\n",
      "Ep. 1232 done, reward: -13.0, running_reward: -17.3812, time (sec): 5339.4702\n",
      "Ep. 1234 done, reward: -21.0, running_reward: -17.3938, time (sec): 5350.6250\n",
      "Ep. 1236 done, reward: -19.0, running_reward: -17.4060, time (sec): 5363.9523\n",
      "Ep. 1238 done, reward: -15.0, running_reward: -17.3779, time (sec): 5376.0061\n",
      "Ep. 1240 done, reward: -17.0, running_reward: -17.3902, time (sec): 5389.0385\n",
      "Ep. 1242 done, reward: -13.0, running_reward: -17.3325, time (sec): 5402.2549\n",
      "Ep. 1244 done, reward: -17.0, running_reward: -17.3457, time (sec): 5414.8378\n",
      "Ep. 1246 done, reward: -17.0, running_reward: -17.3388, time (sec): 5428.7985\n",
      "Ep. 1248 done, reward: -13.0, running_reward: -17.3119, time (sec): 5442.3106\n",
      "Ep. 1250 done, reward: -16.0, running_reward: -17.3056, time (sec): 5456.6003\n",
      "Ep. 1252 done, reward: -15.0, running_reward: -17.3191, time (sec): 5470.0848\n",
      "Ep. 1254 done, reward: -19.0, running_reward: -17.3328, time (sec): 5486.3213\n",
      "Ep. 1256 done, reward: -15.0, running_reward: -17.3259, time (sec): 5502.8489\n",
      "Ep. 1258 done, reward: -19.0, running_reward: -17.3395, time (sec): 5515.4408\n",
      "Ep. 1260 done, reward: -16.0, running_reward: -17.3227, time (sec): 5533.5339\n",
      "Ep. 1262 done, reward: -19.0, running_reward: -17.3165, time (sec): 5547.3558\n",
      "Ep. 1264 done, reward: -15.0, running_reward: -17.2506, time (sec): 5562.9033\n",
      "Ep. 1266 done, reward: -19.0, running_reward: -17.2359, time (sec): 5576.2564\n",
      "Ep. 1268 done, reward: -15.0, running_reward: -17.2508, time (sec): 5589.6685\n",
      "Ep. 1270 done, reward: -16.0, running_reward: -17.2655, time (sec): 5605.5601\n",
      "Ep. 1272 done, reward: -18.0, running_reward: -17.2504, time (sec): 5619.8014\n",
      "Ep. 1274 done, reward: -19.0, running_reward: -17.2753, time (sec): 5632.2642\n",
      "Ep. 1276 done, reward: -18.0, running_reward: -17.2898, time (sec): 5645.2267\n",
      "Ep. 1278 done, reward: -13.0, running_reward: -17.2638, time (sec): 5658.0544\n",
      "Ep. 1280 done, reward: -17.0, running_reward: -17.2585, time (sec): 5670.2596\n",
      "Ep. 1282 done, reward: -18.0, running_reward: -17.2436, time (sec): 5684.4374\n",
      "Ep. 1284 done, reward: -16.0, running_reward: -17.2288, time (sec): 5696.9926\n",
      "Ep. 1286 done, reward: -14.0, running_reward: -17.2140, time (sec): 5708.8247\n",
      "Ep. 1288 done, reward: -21.0, running_reward: -17.2101, time (sec): 5721.5107\n",
      "Ep. 1290 done, reward: -19.0, running_reward: -17.2161, time (sec): 5734.8506\n",
      "Ep. 1292 done, reward: -16.0, running_reward: -17.2216, time (sec): 5749.0579\n",
      "Ep. 1294 done, reward: -18.0, running_reward: -17.2173, time (sec): 5761.9589\n",
      "Ep. 1296 done, reward: -17.0, running_reward: -17.2228, time (sec): 5773.6037\n",
      "Ep. 1298 done, reward: -16.0, running_reward: -17.1589, time (sec): 5789.3433\n",
      "Ep. 1300 done, reward: -13.0, running_reward: -17.0959, time (sec): 5803.1443\n",
      "Ep. 1302 done, reward: -16.0, running_reward: -17.0840, time (sec): 5815.4686\n",
      "Ep. 1304 done, reward: -17.0, running_reward: -17.1022, time (sec): 5827.3599\n",
      "Ep. 1306 done, reward: -19.0, running_reward: -17.0904, time (sec): 5842.1506\n",
      "Ep. 1308 done, reward: -18.0, running_reward: -17.1184, time (sec): 5855.2556\n",
      "Ep. 1310 done, reward: -14.0, running_reward: -17.0366, time (sec): 5871.1244\n",
      "Ep. 1312 done, reward: -19.0, running_reward: -17.0558, time (sec): 5883.9984\n",
      "Ep. 1314 done, reward: -14.0, running_reward: -16.9950, time (sec): 5899.3847\n",
      "Ep. 1316 done, reward: -15.0, running_reward: -16.9454, time (sec): 5914.6942\n",
      "Ep. 1318 done, reward: -18.0, running_reward: -16.9763, time (sec): 5928.5632\n",
      "Ep. 1320 done, reward: -18.0, running_reward: -16.9571, time (sec): 5941.6152\n",
      "Ep. 1322 done, reward: -19.0, running_reward: -16.9779, time (sec): 5953.7493\n",
      "Ep. 1324 done, reward: -18.0, running_reward: -16.9884, time (sec): 5965.9424\n",
      "Ep. 1326 done, reward: -16.0, running_reward: -16.9786, time (sec): 5978.1156\n",
      "Ep. 1328 done, reward: -15.0, running_reward: -16.9293, time (sec): 5993.5743\n",
      "Ep. 1330 done, reward: -16.0, running_reward: -16.9306, time (sec): 6006.2456\n",
      "Ep. 1332 done, reward: -15.0, running_reward: -16.9318, time (sec): 6021.3412\n",
      "Ep. 1334 done, reward: -16.0, running_reward: -16.9331, time (sec): 6035.5799\n",
      "Ep. 1336 done, reward: -19.0, running_reward: -16.9940, time (sec): 6047.4002\n",
      "Ep. 1338 done, reward: -17.0, running_reward: -16.9941, time (sec): 6059.6732\n",
      "Ep. 1340 done, reward: -19.0, running_reward: -16.9746, time (sec): 6072.7743\n",
      "Ep. 1342 done, reward: -17.0, running_reward: -16.9751, time (sec): 6085.3251\n",
      "Ep. 1344 done, reward: -14.0, running_reward: -16.9159, time (sec): 6100.0476\n",
      "Ep. 1346 done, reward: -13.0, running_reward: -16.8776, time (sec): 6112.3372\n",
      "Ep. 1348 done, reward: -15.0, running_reward: -16.8600, time (sec): 6124.5591\n",
      "Ep. 1350 done, reward: -15.0, running_reward: -16.8824, time (sec): 6137.7000\n",
      "Ep. 1352 done, reward: -15.0, running_reward: -16.8549, time (sec): 6149.1802\n",
      "Ep. 1354 done, reward: -17.0, running_reward: -16.7984, time (sec): 6162.5011\n",
      "Ep. 1356 done, reward: -13.0, running_reward: -16.7426, time (sec): 6176.3636\n",
      "Ep. 1358 done, reward: -19.0, running_reward: -16.7380, time (sec): 6189.5170\n",
      "Ep. 1360 done, reward: -14.0, running_reward: -16.6835, time (sec): 6203.1361\n",
      "Ep. 1362 done, reward: -16.0, running_reward: -16.6897, time (sec): 6215.5529\n",
      "Ep. 1364 done, reward: -14.0, running_reward: -16.6758, time (sec): 6228.0363\n",
      "Ep. 1366 done, reward: -19.0, running_reward: -16.7121, time (sec): 6242.2787\n",
      "Ep. 1368 done, reward: -18.0, running_reward: -16.7180, time (sec): 6255.9946\n",
      "Ep. 1370 done, reward: -16.0, running_reward: -16.7136, time (sec): 6268.6427\n",
      "Ep. 1372 done, reward: -20.0, running_reward: -16.7790, time (sec): 6282.2240\n",
      "Ep. 1374 done, reward: -21.0, running_reward: -16.8135, time (sec): 6297.3159\n",
      "Ep. 1376 done, reward: -16.0, running_reward: -16.7775, time (sec): 6310.9200\n",
      "Ep. 1378 done, reward: -19.0, running_reward: -16.8217, time (sec): 6321.8300\n",
      "Ep. 1380 done, reward: -15.0, running_reward: -16.7954, time (sec): 6335.4436\n",
      "Ep. 1382 done, reward: -15.0, running_reward: -16.7794, time (sec): 6349.9346\n",
      "Ep. 1384 done, reward: -18.0, running_reward: -16.7839, time (sec): 6362.6607\n",
      "Ep. 1386 done, reward: -19.0, running_reward: -16.7884, time (sec): 6375.5075\n",
      "Ep. 1388 done, reward: -13.0, running_reward: -16.6932, time (sec): 6392.4432\n",
      "Ep. 1390 done, reward: -13.0, running_reward: -16.6692, time (sec): 6407.7559\n",
      "Ep. 1392 done, reward: -17.0, running_reward: -16.6362, time (sec): 6420.7070\n",
      "Ep. 1394 done, reward: -17.0, running_reward: -16.6435, time (sec): 6434.7578\n",
      "Ep. 1396 done, reward: -14.0, running_reward: -16.6404, time (sec): 6446.9184\n",
      "Ep. 1398 done, reward: -15.0, running_reward: -16.5978, time (sec): 6460.9872\n",
      "Ep. 1400 done, reward: -17.0, running_reward: -16.5761, time (sec): 6476.9042\n",
      "Ep. 1402 done, reward: -14.0, running_reward: -16.5546, time (sec): 6491.6445\n",
      "Ep. 1404 done, reward: -16.0, running_reward: -16.5435, time (sec): 6504.6150\n",
      "Ep. 1406 done, reward: -17.0, running_reward: -16.5526, time (sec): 6517.1639\n",
      "Ep. 1408 done, reward: -19.0, running_reward: -16.5617, time (sec): 6530.3616\n",
      "Ep. 1410 done, reward: -15.0, running_reward: -16.5207, time (sec): 6545.7410\n",
      "Ep. 1412 done, reward: -8.0, running_reward: -16.4403, time (sec): 6561.5783\n",
      "Ep. 1414 done, reward: -17.0, running_reward: -16.4415, time (sec): 6575.9450\n",
      "Ep. 1416 done, reward: -13.0, running_reward: -16.4126, time (sec): 6591.1547\n",
      "Ep. 1418 done, reward: -20.0, running_reward: -16.3949, time (sec): 6606.5730\n",
      "Ep. 1420 done, reward: -15.0, running_reward: -16.3770, time (sec): 6622.0930\n",
      "Ep. 1422 done, reward: -14.0, running_reward: -16.3990, time (sec): 6634.9693\n",
      "Ep. 1424 done, reward: -19.0, running_reward: -16.4310, time (sec): 6651.1596\n",
      "Ep. 1426 done, reward: -19.0, running_reward: -16.4524, time (sec): 6664.7708\n",
      "Ep. 1428 done, reward: -16.0, running_reward: -16.4335, time (sec): 6679.9721\n",
      "Ep. 1430 done, reward: -16.0, running_reward: -16.4447, time (sec): 6691.1038\n",
      "Ep. 1432 done, reward: -17.0, running_reward: -16.4161, time (sec): 6706.1168\n",
      "Ep. 1434 done, reward: -15.0, running_reward: -16.3880, time (sec): 6722.1642\n",
      "Ep. 1436 done, reward: -17.0, running_reward: -16.3902, time (sec): 6736.5922\n",
      "Ep. 1438 done, reward: -15.0, running_reward: -16.3626, time (sec): 6751.2860\n",
      "Ep. 1440 done, reward: -14.0, running_reward: -16.3354, time (sec): 6765.8250\n",
      "Ep. 1442 done, reward: -14.0, running_reward: -16.3087, time (sec): 6779.1414\n",
      "Ep. 1444 done, reward: -16.0, running_reward: -16.3025, time (sec): 6792.1770\n",
      "Ep. 1446 done, reward: -10.0, running_reward: -16.2662, time (sec): 6808.3890\n",
      "Ep. 1448 done, reward: -16.0, running_reward: -16.2312, time (sec): 6823.3863\n",
      "Ep. 1450 done, reward: -17.0, running_reward: -16.2267, time (sec): 6836.9574\n",
      "Ep. 1452 done, reward: -19.0, running_reward: -16.2324, time (sec): 6853.6947\n",
      "Ep. 1454 done, reward: -13.0, running_reward: -16.2077, time (sec): 6870.0921\n",
      "Ep. 1456 done, reward: -12.0, running_reward: -16.1735, time (sec): 6886.9370\n",
      "Ep. 1458 done, reward: -15.0, running_reward: -16.1699, time (sec): 6900.2810\n",
      "Ep. 1460 done, reward: -15.0, running_reward: -16.1664, time (sec): 6915.5825\n",
      "Ep. 1462 done, reward: -17.0, running_reward: -16.1632, time (sec): 6930.8629\n",
      "Ep. 1464 done, reward: -14.0, running_reward: -16.1202, time (sec): 6945.2613\n",
      "Ep. 1466 done, reward: -16.0, running_reward: -16.0980, time (sec): 6959.9817\n",
      "Ep. 1468 done, reward: -11.0, running_reward: -16.0064, time (sec): 6976.2911\n",
      "Ep. 1470 done, reward: -18.0, running_reward: -16.0164, time (sec): 6989.4779\n",
      "Ep. 1472 done, reward: -17.0, running_reward: -16.0261, time (sec): 7003.6728\n",
      "Ep. 1474 done, reward: -15.0, running_reward: -15.9858, time (sec): 7017.8043\n",
      "Ep. 1476 done, reward: -10.0, running_reward: -15.9261, time (sec): 7033.7752\n",
      "Ep. 1478 done, reward: -16.0, running_reward: -15.8880, time (sec): 7046.3584\n",
      "Ep. 1480 done, reward: -19.0, running_reward: -15.9499, time (sec): 7059.7829\n",
      "Ep. 1482 done, reward: -14.0, running_reward: -15.9309, time (sec): 7074.0886\n",
      "Ep. 1484 done, reward: -17.0, running_reward: -15.9621, time (sec): 7085.8441\n",
      "Ep. 1486 done, reward: -15.0, running_reward: -15.9727, time (sec): 7100.8312\n",
      "Ep. 1488 done, reward: -14.0, running_reward: -15.9829, time (sec): 7114.4846\n",
      "Ep. 1490 done, reward: -16.0, running_reward: -15.9535, time (sec): 7129.6962\n",
      "Ep. 1492 done, reward: -18.0, running_reward: -16.0042, time (sec): 7142.9375\n",
      "Ep. 1494 done, reward: -18.0, running_reward: -16.0439, time (sec): 7156.2398\n",
      "Ep. 1496 done, reward: -18.0, running_reward: -16.0333, time (sec): 7169.7035\n",
      "Ep. 1498 done, reward: -19.0, running_reward: -16.0725, time (sec): 7183.5748\n",
      "Ep. 1500 done, reward: -15.0, running_reward: -16.0512, time (sec): 7198.2604\n",
      "Ep. 1502 done, reward: -11.0, running_reward: -16.0398, time (sec): 7212.3088\n",
      "Ep. 1504 done, reward: -15.0, running_reward: -15.9993, time (sec): 7227.5153\n",
      "Ep. 1506 done, reward: -16.0, running_reward: -15.9795, time (sec): 7244.4853\n",
      "Ep. 1508 done, reward: -15.0, running_reward: -15.9798, time (sec): 7256.5211\n",
      "Ep. 1510 done, reward: -14.0, running_reward: -15.9701, time (sec): 7270.2222\n",
      "Ep. 1512 done, reward: -11.0, running_reward: -15.9405, time (sec): 7285.4747\n",
      "Ep. 1514 done, reward: -16.0, running_reward: -15.9120, time (sec): 7300.8771\n",
      "Ep. 1516 done, reward: -11.0, running_reward: -15.8736, time (sec): 7315.3387\n",
      "Ep. 1518 done, reward: -19.0, running_reward: -15.9062, time (sec): 7327.4319\n",
      "Ep. 1520 done, reward: -17.0, running_reward: -15.9180, time (sec): 7342.7644\n",
      "Ep. 1522 done, reward: -17.0, running_reward: -15.9396, time (sec): 7357.9169\n",
      "Ep. 1524 done, reward: -16.0, running_reward: -15.9309, time (sec): 7373.7189\n",
      "Ep. 1526 done, reward: -19.0, running_reward: -15.9622, time (sec): 7386.9817\n",
      "Ep. 1528 done, reward: -13.0, running_reward: -15.9429, time (sec): 7403.7544\n",
      "Ep. 1530 done, reward: -18.0, running_reward: -15.9739, time (sec): 7418.1061\n",
      "Ep. 1532 done, reward: -17.0, running_reward: -15.9844, time (sec): 7432.3163\n",
      "Ep. 1534 done, reward: -20.0, running_reward: -16.0248, time (sec): 7445.1315\n",
      "Ep. 1536 done, reward: -18.0, running_reward: -16.0839, time (sec): 7459.4940\n",
      "Ep. 1538 done, reward: -12.0, running_reward: -16.0323, time (sec): 7475.3637\n",
      "Ep. 1540 done, reward: -19.0, running_reward: -16.0517, time (sec): 7490.8260\n",
      "Ep. 1542 done, reward: -14.0, running_reward: -16.0604, time (sec): 7504.9163\n",
      "Ep. 1544 done, reward: -18.0, running_reward: -16.0594, time (sec): 7519.4515\n",
      "Ep. 1546 done, reward: -12.0, running_reward: -15.9489, time (sec): 7537.7525\n",
      "Ep. 1548 done, reward: -12.0, running_reward: -15.9100, time (sec): 7551.0686\n",
      "Ep. 1550 done, reward: -14.0, running_reward: -15.8818, time (sec): 7566.3052\n",
      "Ep. 1552 done, reward: -15.0, running_reward: -15.8841, time (sec): 7580.3628\n",
      "Ep. 1554 done, reward: -19.0, running_reward: -15.8867, time (sec): 7595.1327\n",
      "Ep. 1556 done, reward: -15.0, running_reward: -15.8889, time (sec): 7610.4876\n",
      "Ep. 1558 done, reward: -14.0, running_reward: -15.8612, time (sec): 7625.1310\n",
      "Ep. 1560 done, reward: -18.0, running_reward: -15.8344, time (sec): 7642.4465\n",
      "Ep. 1562 done, reward: -12.0, running_reward: -15.7878, time (sec): 7656.5796\n",
      "Ep. 1564 done, reward: -10.0, running_reward: -15.7419, time (sec): 7671.1407\n",
      "Ep. 1566 done, reward: -19.0, running_reward: -15.7969, time (sec): 7686.2569\n",
      "Ep. 1568 done, reward: -17.0, running_reward: -15.8010, time (sec): 7702.3201\n",
      "Ep. 1570 done, reward: -13.0, running_reward: -15.7453, time (sec): 7715.3506\n",
      "Ep. 1572 done, reward: -17.0, running_reward: -15.7307, time (sec): 7728.1239\n",
      "Ep. 1574 done, reward: -13.0, running_reward: -15.6961, time (sec): 7746.0320\n",
      "Ep. 1576 done, reward: -15.0, running_reward: -15.6427, time (sec): 7762.5206\n",
      "Ep. 1578 done, reward: -14.0, running_reward: -15.6001, time (sec): 7777.7616\n",
      "Ep. 1580 done, reward: -19.0, running_reward: -15.6776, time (sec): 7790.1311\n",
      "Ep. 1582 done, reward: -20.0, running_reward: -15.6943, time (sec): 7802.7602\n",
      "Ep. 1584 done, reward: -16.0, running_reward: -15.6905, time (sec): 7817.3771\n",
      "Ep. 1586 done, reward: -15.0, running_reward: -15.6669, time (sec): 7832.8361\n",
      "Ep. 1588 done, reward: -14.0, running_reward: -15.6436, time (sec): 7848.2082\n",
      "Ep. 1590 done, reward: -18.0, running_reward: -15.6905, time (sec): 7860.5512\n",
      "Ep. 1592 done, reward: -17.0, running_reward: -15.6374, time (sec): 7877.4990\n",
      "Ep. 1594 done, reward: -18.0, running_reward: -15.6745, time (sec): 7891.4256\n",
      "Ep. 1596 done, reward: -11.0, running_reward: -15.5815, time (sec): 7906.1259\n",
      "Ep. 1598 done, reward: -12.0, running_reward: -15.5597, time (sec): 7922.6009\n",
      "Ep. 1600 done, reward: -8.0, running_reward: -15.5380, time (sec): 7938.3715\n",
      "Ep. 1602 done, reward: -18.0, running_reward: -15.5572, time (sec): 7954.7364\n",
      "Ep. 1604 done, reward: -15.0, running_reward: -15.5165, time (sec): 7969.2125\n",
      "Ep. 1606 done, reward: -19.0, running_reward: -15.4868, time (sec): 7983.5176\n",
      "Ep. 1608 done, reward: -9.0, running_reward: -15.3874, time (sec): 8001.4621\n",
      "Ep. 1610 done, reward: -14.0, running_reward: -15.3994, time (sec): 8017.4792\n",
      "Ep. 1612 done, reward: -16.0, running_reward: -15.3717, time (sec): 8034.2783\n",
      "Ep. 1614 done, reward: -15.0, running_reward: -15.3643, time (sec): 8049.4406\n",
      "Ep. 1616 done, reward: -17.0, running_reward: -15.3276, time (sec): 8066.1305\n",
      "Ep. 1618 done, reward: -15.0, running_reward: -15.3310, time (sec): 8081.1026\n",
      "Ep. 1620 done, reward: -14.0, running_reward: -15.2748, time (sec): 8097.4119\n",
      "Ep. 1622 done, reward: -17.0, running_reward: -15.3190, time (sec): 8110.7463\n",
      "Ep. 1624 done, reward: -12.0, running_reward: -15.2926, time (sec): 8126.4516\n",
      "Ep. 1626 done, reward: -14.0, running_reward: -15.2866, time (sec): 8143.9950\n",
      "Ep. 1628 done, reward: -16.0, running_reward: -15.3008, time (sec): 8160.4729\n",
      "Ep. 1630 done, reward: -16.0, running_reward: -15.2554, time (sec): 8175.7529\n",
      "Ep. 1632 done, reward: -13.0, running_reward: -15.2303, time (sec): 8192.3422\n",
      "Ep. 1634 done, reward: -15.0, running_reward: -15.2356, time (sec): 8208.6847\n",
      "Ep. 1636 done, reward: -16.0, running_reward: -15.3003, time (sec): 8222.6433\n",
      "Ep. 1638 done, reward: -15.0, running_reward: -15.2646, time (sec): 8237.3443\n",
      "Ep. 1640 done, reward: -12.0, running_reward: -15.2393, time (sec): 8255.7980\n",
      "Ep. 1642 done, reward: -16.0, running_reward: -15.2841, time (sec): 8269.3129\n",
      "Ep. 1644 done, reward: -14.0, running_reward: -15.2783, time (sec): 8284.9469\n",
      "Ep. 1646 done, reward: -16.0, running_reward: -15.2729, time (sec): 8300.5666\n",
      "Ep. 1648 done, reward: -16.0, running_reward: -15.2676, time (sec): 8314.7876\n",
      "Ep. 1650 done, reward: -15.0, running_reward: -15.2523, time (sec): 8330.2737\n",
      "Ep. 1652 done, reward: -17.0, running_reward: -15.2673, time (sec): 8345.0623\n",
      "Ep. 1654 done, reward: -17.0, running_reward: -15.2424, time (sec): 8361.8353\n",
      "Ep. 1656 done, reward: -13.0, running_reward: -15.1582, time (sec): 8381.0809\n",
      "Ep. 1658 done, reward: -14.0, running_reward: -15.0757, time (sec): 8399.9875\n",
      "Ep. 1660 done, reward: -17.0, running_reward: -15.1140, time (sec): 8414.4850\n",
      "Ep. 1662 done, reward: -19.0, running_reward: -15.1815, time (sec): 8428.5642\n",
      "Ep. 1664 done, reward: -15.0, running_reward: -15.1976, time (sec): 8442.2040\n",
      "Ep. 1666 done, reward: -17.0, running_reward: -15.1939, time (sec): 8456.1266\n",
      "Ep. 1668 done, reward: -14.0, running_reward: -15.1900, time (sec): 8472.4594\n",
      "Ep. 1670 done, reward: -15.0, running_reward: -15.1961, time (sec): 8488.3237\n",
      "Ep. 1672 done, reward: -17.0, running_reward: -15.2122, time (sec): 8502.1809\n",
      "Ep. 1674 done, reward: -13.0, running_reward: -15.1880, time (sec): 8518.8226\n",
      "Ep. 1676 done, reward: -13.0, running_reward: -15.1840, time (sec): 8535.1325\n",
      "Ep. 1678 done, reward: -18.0, running_reward: -15.2302, time (sec): 8551.6964\n",
      "Ep. 1680 done, reward: -17.0, running_reward: -15.2753, time (sec): 8566.7554\n",
      "Ep. 1682 done, reward: -10.0, running_reward: -15.1703, time (sec): 8586.0358\n",
      "Ep. 1684 done, reward: -19.0, running_reward: -15.2465, time (sec): 8598.3894\n",
      "Ep. 1686 done, reward: -15.0, running_reward: -15.2515, time (sec): 8615.1297\n",
      "Ep. 1688 done, reward: -17.0, running_reward: -15.2764, time (sec): 8631.6945\n",
      "Ep. 1690 done, reward: -15.0, running_reward: -15.2907, time (sec): 8645.8034\n",
      "Ep. 1692 done, reward: -17.0, running_reward: -15.3049, time (sec): 8660.8828\n",
      "Ep. 1694 done, reward: -14.0, running_reward: -15.2591, time (sec): 8677.2426\n",
      "Ep. 1696 done, reward: -11.0, running_reward: -15.2140, time (sec): 8693.4408\n",
      "Ep. 1698 done, reward: -17.0, running_reward: -15.2099, time (sec): 8707.8417\n",
      "Ep. 1700 done, reward: -16.0, running_reward: -15.2157, time (sec): 8721.4699\n",
      "Ep. 1702 done, reward: -15.0, running_reward: -15.1719, time (sec): 8740.7576\n",
      "Ep. 1704 done, reward: -17.0, running_reward: -15.1983, time (sec): 8761.1841\n",
      "Ep. 1706 done, reward: -14.0, running_reward: -15.1646, time (sec): 8778.5973\n",
      "Ep. 1708 done, reward: -19.0, running_reward: -15.1914, time (sec): 8794.7206\n",
      "Ep. 1710 done, reward: -15.0, running_reward: -15.1381, time (sec): 8810.4174\n",
      "Ep. 1712 done, reward: -17.0, running_reward: -15.1752, time (sec): 8822.6776\n",
      "Ep. 1714 done, reward: -17.0, running_reward: -15.1620, time (sec): 8838.6635\n",
      "Ep. 1716 done, reward: -10.0, running_reward: -15.1087, time (sec): 8857.2484\n",
      "Ep. 1718 done, reward: -13.0, running_reward: -15.1064, time (sec): 8872.8633\n",
      "Ep. 1720 done, reward: -17.0, running_reward: -15.1144, time (sec): 8889.7222\n",
      "Ep. 1722 done, reward: -17.0, running_reward: -15.1024, time (sec): 8905.4184\n",
      "Ep. 1724 done, reward: -12.0, running_reward: -15.0605, time (sec): 8922.7887\n",
      "Ep. 1726 done, reward: -10.0, running_reward: -14.9696, time (sec): 8942.3170\n",
      "Ep. 1728 done, reward: -16.0, running_reward: -15.0199, time (sec): 8957.3064\n",
      "Ep. 1730 done, reward: -17.0, running_reward: -15.0296, time (sec): 8975.2186\n",
      "Ep. 1732 done, reward: -12.0, running_reward: -14.9891, time (sec): 8992.9563\n",
      "Ep. 1734 done, reward: -16.0, running_reward: -14.9993, time (sec): 9007.5667\n",
      "Ep. 1736 done, reward: -12.0, running_reward: -14.9891, time (sec): 9022.5711\n",
      "Ep. 1738 done, reward: -7.0, running_reward: -14.8895, time (sec): 9041.2009\n",
      "Ep. 1740 done, reward: -19.0, running_reward: -14.8921, time (sec): 9058.1725\n",
      "Ep. 1742 done, reward: -17.0, running_reward: -14.8549, time (sec): 9077.5905\n",
      "Ep. 1744 done, reward: -15.0, running_reward: -14.8974, time (sec): 9092.2167\n",
      "Ep. 1746 done, reward: -15.0, running_reward: -14.8697, time (sec): 9109.7080\n",
      "Ep. 1748 done, reward: -15.0, running_reward: -14.9020, time (sec): 9125.4937\n",
      "Ep. 1750 done, reward: -10.0, running_reward: -14.8341, time (sec): 9142.4939\n",
      "Ep. 1752 done, reward: -17.0, running_reward: -14.8772, time (sec): 9158.6757\n",
      "Ep. 1754 done, reward: -15.0, running_reward: -14.8104, time (sec): 9176.4229\n",
      "Ep. 1756 done, reward: -16.0, running_reward: -14.7846, time (sec): 9192.6677\n",
      "Ep. 1758 done, reward: -13.0, running_reward: -14.7688, time (sec): 9206.6859\n",
      "Ep. 1760 done, reward: -19.0, running_reward: -14.8035, time (sec): 9223.8779\n",
      "Ep. 1762 done, reward: -8.0, running_reward: -14.7276, time (sec): 9243.4980\n",
      "Ep. 1764 done, reward: -19.0, running_reward: -14.7730, time (sec): 9257.8386\n",
      "Ep. 1766 done, reward: -14.0, running_reward: -14.7378, time (sec): 9277.6884\n",
      "Ep. 1768 done, reward: -15.0, running_reward: -14.8024, time (sec): 9290.9161\n",
      "Ep. 1770 done, reward: -19.0, running_reward: -14.8760, time (sec): 9306.6411\n",
      "Ep. 1772 done, reward: -13.0, running_reward: -14.8486, time (sec): 9324.8056\n",
      "Ep. 1774 done, reward: -16.0, running_reward: -14.8418, time (sec): 9339.1507\n",
      "Ep. 1776 done, reward: -13.0, running_reward: -14.8052, time (sec): 9355.1056\n",
      "Ep. 1778 done, reward: -15.0, running_reward: -14.7793, time (sec): 9371.1268\n",
      "Ep. 1780 done, reward: -16.0, running_reward: -14.7739, time (sec): 9387.4299\n",
      "Ep. 1782 done, reward: -17.0, running_reward: -14.7885, time (sec): 9404.3612\n",
      "Ep. 1784 done, reward: -15.0, running_reward: -14.8323, time (sec): 9418.3711\n",
      "Ep. 1786 done, reward: -11.0, running_reward: -14.7660, time (sec): 9435.8101\n",
      "Ep. 1788 done, reward: -16.0, running_reward: -14.7410, time (sec): 9453.7388\n",
      "Ep. 1790 done, reward: -12.0, running_reward: -14.6766, time (sec): 9470.6057\n",
      "Ep. 1792 done, reward: -15.0, running_reward: -14.7028, time (sec): 9486.1344\n",
      "Ep. 1794 done, reward: -13.0, running_reward: -14.6986, time (sec): 9504.1215\n",
      "Ep. 1796 done, reward: -17.0, running_reward: -14.7048, time (sec): 9521.0415\n",
      "Ep. 1798 done, reward: -14.0, running_reward: -14.7007, time (sec): 9536.6006\n",
      "Ep. 1800 done, reward: -14.0, running_reward: -14.6373, time (sec): 9557.0584\n",
      "Ep. 1802 done, reward: -16.0, running_reward: -14.5951, time (sec): 9574.4386\n",
      "Ep. 1804 done, reward: -19.0, running_reward: -14.6233, time (sec): 9590.6058\n",
      "Ep. 1806 done, reward: -18.0, running_reward: -14.6806, time (sec): 9606.2465\n",
      "Ep. 1808 done, reward: -15.0, running_reward: -14.7266, time (sec): 9617.9184\n",
      "Ep. 1810 done, reward: -15.0, running_reward: -14.7716, time (sec): 9634.2214\n",
      "Ep. 1812 done, reward: -15.0, running_reward: -14.7069, time (sec): 9652.1943\n",
      "Ep. 1814 done, reward: -16.0, running_reward: -14.7425, time (sec): 9668.8026\n",
      "Ep. 1816 done, reward: -19.0, running_reward: -14.7678, time (sec): 9682.6715\n",
      "Ep. 1818 done, reward: -13.0, running_reward: -14.7723, time (sec): 9699.3479\n",
      "Ep. 1820 done, reward: -12.0, running_reward: -14.6874, time (sec): 9716.8655\n",
      "Ep. 1822 done, reward: -10.0, running_reward: -14.6139, time (sec): 9736.3162\n",
      "Ep. 1824 done, reward: -13.0, running_reward: -14.5521, time (sec): 9755.7792\n",
      "Ep. 1826 done, reward: -17.0, running_reward: -14.5612, time (sec): 9771.8574\n",
      "Ep. 1828 done, reward: -16.0, running_reward: -14.5799, time (sec): 9787.8665\n",
      "Ep. 1830 done, reward: -13.0, running_reward: -14.5584, time (sec): 9805.0997\n",
      "Ep. 1832 done, reward: -12.0, running_reward: -14.5174, time (sec): 9822.8207\n",
      "Ep. 1834 done, reward: -9.0, running_reward: -14.3878, time (sec): 9842.6833\n",
      "Ep. 1836 done, reward: -14.0, running_reward: -14.4296, time (sec): 9859.6638\n",
      "Ep. 1838 done, reward: -12.0, running_reward: -14.4208, time (sec): 9876.7425\n",
      "Ep. 1840 done, reward: -15.0, running_reward: -14.3729, time (sec): 9897.8895\n",
      "Ep. 1842 done, reward: -12.0, running_reward: -14.3455, time (sec): 9913.6709\n",
      "Ep. 1844 done, reward: -16.0, running_reward: -14.3488, time (sec): 9930.1598\n",
      "Ep. 1846 done, reward: -13.0, running_reward: -14.3516, time (sec): 9946.6051\n",
      "Ep. 1848 done, reward: -19.0, running_reward: -14.4441, time (sec): 9963.6186\n",
      "Ep. 1850 done, reward: -16.0, running_reward: -14.4454, time (sec): 9979.9299\n",
      "Ep. 1852 done, reward: -15.0, running_reward: -14.4366, time (sec): 9996.8231\n",
      "Ep. 1854 done, reward: -19.0, running_reward: -14.4482, time (sec): 10013.2534\n",
      "Ep. 1856 done, reward: -15.0, running_reward: -14.4394, time (sec): 10029.3566\n",
      "Ep. 1858 done, reward: -19.0, running_reward: -14.4708, time (sec): 10043.9260\n",
      "Ep. 1860 done, reward: -15.0, running_reward: -14.4813, time (sec): 10061.9885\n",
      "Ep. 1862 done, reward: -14.0, running_reward: -14.4816, time (sec): 10079.0629\n",
      "Ep. 1864 done, reward: -16.0, running_reward: -14.5217, time (sec): 10095.1291\n",
      "Ep. 1866 done, reward: -16.0, running_reward: -14.5610, time (sec): 10110.7746\n",
      "Ep. 1868 done, reward: -12.0, running_reward: -14.4705, time (sec): 10129.6747\n",
      "Ep. 1870 done, reward: -17.0, running_reward: -14.4812, time (sec): 10145.5697\n",
      "Ep. 1872 done, reward: -17.0, running_reward: -14.4521, time (sec): 10163.2944\n",
      "Ep. 1874 done, reward: -9.0, running_reward: -14.4030, time (sec): 10181.2315\n",
      "Ep. 1876 done, reward: -7.0, running_reward: -14.3349, time (sec): 10201.0491\n",
      "Ep. 1878 done, reward: -15.0, running_reward: -14.3284, time (sec): 10217.7231\n",
      "Ep. 1880 done, reward: -8.0, running_reward: -14.2618, time (sec): 10237.0897\n",
      "Ep. 1882 done, reward: -16.0, running_reward: -14.2667, time (sec): 10251.6894\n",
      "Ep. 1884 done, reward: -16.0, running_reward: -14.2715, time (sec): 10268.9172\n",
      "Ep. 1886 done, reward: -12.0, running_reward: -14.2362, time (sec): 10290.4920\n",
      "Ep. 1888 done, reward: -17.0, running_reward: -14.2813, time (sec): 10305.3289\n",
      "Ep. 1890 done, reward: -15.0, running_reward: -14.2956, time (sec): 10322.6362\n",
      "Ep. 1892 done, reward: -15.0, running_reward: -14.3096, time (sec): 10341.7832\n",
      "Ep. 1894 done, reward: -15.0, running_reward: -14.3036, time (sec): 10358.1729\n",
      "Ep. 1896 done, reward: -13.0, running_reward: -14.2776, time (sec): 10376.5506\n",
      "Ep. 1898 done, reward: -15.0, running_reward: -14.2029, time (sec): 10395.0607\n",
      "Ep. 1900 done, reward: -17.0, running_reward: -14.2190, time (sec): 10411.0738\n",
      "Ep. 1902 done, reward: -16.0, running_reward: -14.2049, time (sec): 10428.7620\n",
      "Ep. 1904 done, reward: -7.0, running_reward: -14.1308, time (sec): 10447.6750\n",
      "Ep. 1906 done, reward: -12.0, running_reward: -14.0983, time (sec): 10464.1536\n",
      "Ep. 1908 done, reward: -13.0, running_reward: -14.0864, time (sec): 10481.0109\n",
      "Ep. 1910 done, reward: -17.0, running_reward: -14.1146, time (sec): 10497.9075\n",
      "Ep. 1912 done, reward: -17.0, running_reward: -14.0929, time (sec): 10515.8335\n",
      "Ep. 1914 done, reward: -17.0, running_reward: -14.1309, time (sec): 10534.4483\n",
      "Ep. 1916 done, reward: -11.0, running_reward: -14.0587, time (sec): 10552.7898\n",
      "Ep. 1918 done, reward: -17.0, running_reward: -14.0875, time (sec): 10567.5784\n",
      "Ep. 1920 done, reward: -15.0, running_reward: -14.1057, time (sec): 10585.1558\n",
      "Ep. 1922 done, reward: -16.0, running_reward: -14.1434, time (sec): 10601.9369\n",
      "Ep. 1924 done, reward: -11.0, running_reward: -14.1798, time (sec): 10616.1985\n",
      "Ep. 1926 done, reward: -14.0, running_reward: -14.2159, time (sec): 10631.2422\n",
      "Ep. 1928 done, reward: -16.0, running_reward: -14.2415, time (sec): 10646.8629\n",
      "Ep. 1930 done, reward: -15.0, running_reward: -14.2764, time (sec): 10665.3455\n",
      "Ep. 1932 done, reward: -13.0, running_reward: -14.2510, time (sec): 10684.6312\n",
      "Ep. 1934 done, reward: -15.0, running_reward: -14.2659, time (sec): 10701.2170\n",
      "Ep. 1936 done, reward: -16.0, running_reward: -14.3103, time (sec): 10716.4757\n",
      "Ep. 1938 done, reward: -17.0, running_reward: -14.3341, time (sec): 10735.3786\n",
      "Ep. 1940 done, reward: -11.0, running_reward: -14.3074, time (sec): 10755.1429\n",
      "Ep. 1942 done, reward: -13.0, running_reward: -14.2417, time (sec): 10772.4100\n",
      "Ep. 1944 done, reward: -13.0, running_reward: -14.2467, time (sec): 10789.9364\n",
      "Ep. 1946 done, reward: -13.0, running_reward: -14.2714, time (sec): 10806.1566\n",
      "Ep. 1948 done, reward: -11.0, running_reward: -14.2459, time (sec): 10823.2241\n",
      "Ep. 1950 done, reward: -15.0, running_reward: -14.2807, time (sec): 10839.8527\n",
      "Ep. 1952 done, reward: -15.0, running_reward: -14.2554, time (sec): 10856.4810\n",
      "Ep. 1954 done, reward: -15.0, running_reward: -14.3099, time (sec): 10873.9391\n",
      "Ep. 1956 done, reward: -17.0, running_reward: -14.3337, time (sec): 10892.9201\n",
      "Ep. 1958 done, reward: -20.0, running_reward: -14.3870, time (sec): 10908.1304\n",
      "Ep. 1960 done, reward: -9.0, running_reward: -14.3293, time (sec): 10926.7372\n",
      "Ep. 1962 done, reward: -13.0, running_reward: -14.2831, time (sec): 10947.2100\n",
      "Ep. 1964 done, reward: -13.0, running_reward: -14.2279, time (sec): 10963.9627\n",
      "Ep. 1966 done, reward: -15.0, running_reward: -14.2234, time (sec): 10979.4291\n",
      "Ep. 1968 done, reward: -10.0, running_reward: -14.1790, time (sec): 10995.8920\n",
      "Ep. 1970 done, reward: -19.0, running_reward: -14.1957, time (sec): 11013.5909\n",
      "Ep. 1972 done, reward: -15.0, running_reward: -14.1523, time (sec): 11032.4624\n",
      "Ep. 1974 done, reward: -17.0, running_reward: -14.1793, time (sec): 11048.7151\n",
      "Ep. 1976 done, reward: -15.0, running_reward: -14.1560, time (sec): 11066.3325\n",
      "Ep. 1978 done, reward: -11.0, running_reward: -14.1130, time (sec): 11084.2998\n",
      "Ep. 1980 done, reward: -13.0, running_reward: -14.1107, time (sec): 11100.6280\n",
      "Ep. 1982 done, reward: -20.0, running_reward: -14.1982, time (sec): 11115.0507\n",
      "Ep. 1984 done, reward: -15.0, running_reward: -14.1745, time (sec): 11130.8710\n",
      "Ep. 1986 done, reward: -17.0, running_reward: -14.2010, time (sec): 11149.1528\n",
      "Ep. 1988 done, reward: -14.0, running_reward: -14.2267, time (sec): 11165.0234\n",
      "Ep. 1990 done, reward: -14.0, running_reward: -14.2321, time (sec): 11181.5922\n",
      "Ep. 1992 done, reward: -16.0, running_reward: -14.1881, time (sec): 11199.2356\n",
      "Ep. 1994 done, reward: -18.0, running_reward: -14.2343, time (sec): 11214.4943\n",
      "Ep. 1996 done, reward: -18.0, running_reward: -14.2597, time (sec): 11231.6079\n",
      "Ep. 1998 done, reward: -18.0, running_reward: -14.3440, time (sec): 11245.2451\n",
      "Ep. 2000 done, reward: -9.0, running_reward: -14.3268, time (sec): 11262.5300\n",
      "Ep. 2002 done, reward: -12.0, running_reward: -14.2904, time (sec): 11281.3515\n",
      "Ep. 2004 done, reward: -13.0, running_reward: -14.2746, time (sec): 11301.1954\n",
      "Ep. 2006 done, reward: -7.0, running_reward: -14.2090, time (sec): 11320.8309\n",
      "Ep. 2008 done, reward: -14.0, running_reward: -14.1158, time (sec): 11340.1950\n",
      "Ep. 2010 done, reward: -17.0, running_reward: -14.1336, time (sec): 11356.9034\n",
      "Ep. 2012 done, reward: -12.0, running_reward: -14.1010, time (sec): 11374.6136\n",
      "Ep. 2014 done, reward: -16.0, running_reward: -14.0695, time (sec): 11392.6273\n",
      "Ep. 2016 done, reward: -14.0, running_reward: -14.1176, time (sec): 11409.5680\n",
      "Ep. 2018 done, reward: -15.0, running_reward: -14.1649, time (sec): 11425.8857\n",
      "Ep. 2020 done, reward: -9.0, running_reward: -14.1413, time (sec): 11443.6766\n",
      "Ep. 2022 done, reward: -16.0, running_reward: -14.1486, time (sec): 11459.9289\n",
      "Ep. 2024 done, reward: -13.0, running_reward: -14.1752, time (sec): 11479.1818\n",
      "Ep. 2026 done, reward: -12.0, running_reward: -14.1518, time (sec): 11494.8036\n",
      "Ep. 2028 done, reward: -17.0, running_reward: -14.1292, time (sec): 11511.4892\n",
      "Ep. 2030 done, reward: -18.0, running_reward: -14.1370, time (sec): 11527.2267\n",
      "Ep. 2032 done, reward: -19.0, running_reward: -14.2535, time (sec): 11543.9978\n",
      "Ep. 2034 done, reward: -15.0, running_reward: -14.2684, time (sec): 11561.3175\n",
      "Ep. 2036 done, reward: -13.0, running_reward: -14.2828, time (sec): 11577.3742\n",
      "Ep. 2038 done, reward: -15.0, running_reward: -14.2772, time (sec): 11594.4251\n",
      "Ep. 2040 done, reward: -17.0, running_reward: -14.3017, time (sec): 11609.5738\n",
      "Ep. 2042 done, reward: -19.0, running_reward: -14.3160, time (sec): 11627.0448\n",
      "Ep. 2044 done, reward: -14.0, running_reward: -14.2899, time (sec): 11645.7251\n",
      "Ep. 2046 done, reward: -15.0, running_reward: -14.2050, time (sec): 11665.3537\n",
      "Ep. 2048 done, reward: -17.0, running_reward: -14.2310, time (sec): 11679.8202\n",
      "Ep. 2050 done, reward: -11.0, running_reward: -14.1667, time (sec): 11699.2695\n",
      "Ep. 2052 done, reward: -17.0, running_reward: -14.1835, time (sec): 11714.9840\n",
      "Ep. 2054 done, reward: -18.0, running_reward: -14.2000, time (sec): 11732.7612\n",
      "Ep. 2056 done, reward: -13.0, running_reward: -14.1365, time (sec): 11750.8701\n",
      "Ep. 2058 done, reward: -15.0, running_reward: -14.1537, time (sec): 11767.3366\n",
      "Ep. 2060 done, reward: -14.0, running_reward: -14.1209, time (sec): 11783.5022\n",
      "Ep. 2062 done, reward: -16.0, running_reward: -14.1682, time (sec): 11801.0871\n",
      "Ep. 2064 done, reward: -11.0, running_reward: -14.1448, time (sec): 11819.7482\n",
      "Ep. 2066 done, reward: -15.0, running_reward: -14.2014, time (sec): 11836.0698\n",
      "Ep. 2068 done, reward: -7.0, running_reward: -14.0977, time (sec): 11856.6467\n",
      "Ep. 2070 done, reward: -6.0, running_reward: -14.0158, time (sec): 11874.1886\n",
      "Ep. 2072 done, reward: -14.0, running_reward: -13.9956, time (sec): 11890.2238\n",
      "Ep. 2074 done, reward: -13.0, running_reward: -14.0154, time (sec): 11909.9217\n",
      "Ep. 2076 done, reward: -13.0, running_reward: -13.9853, time (sec): 11927.3671\n",
      "Ep. 2078 done, reward: -15.0, running_reward: -14.0253, time (sec): 11945.2133\n",
      "Ep. 2080 done, reward: -13.0, running_reward: -13.9653, time (sec): 11961.7304\n",
      "Ep. 2082 done, reward: -14.0, running_reward: -14.0155, time (sec): 11976.5247\n",
      "Ep. 2084 done, reward: -18.0, running_reward: -14.0651, time (sec): 11990.0132\n",
      "Ep. 2086 done, reward: -11.0, running_reward: -13.9843, time (sec): 12009.3830\n",
      "Ep. 2088 done, reward: -12.0, running_reward: -13.9646, time (sec): 12026.7557\n",
      "Ep. 2090 done, reward: -11.0, running_reward: -13.9452, time (sec): 12046.0185\n",
      "Ep. 2092 done, reward: -15.0, running_reward: -13.8474, time (sec): 12066.6754\n",
      "Ep. 2094 done, reward: -14.0, running_reward: -13.8405, time (sec): 12085.9267\n",
      "Ep. 2096 done, reward: -13.0, running_reward: -13.7941, time (sec): 12104.4093\n",
      "Ep. 2098 done, reward: -4.0, running_reward: -13.6982, time (sec): 12124.3119\n",
      "Ep. 2100 done, reward: -14.0, running_reward: -13.6844, time (sec): 12143.4441\n",
      "Ep. 2102 done, reward: -17.0, running_reward: -13.7306, time (sec): 12158.6054\n",
      "Ep. 2104 done, reward: -12.0, running_reward: -13.7061, time (sec): 12176.8365\n",
      "Ep. 2106 done, reward: -15.0, running_reward: -13.7318, time (sec): 12196.1658\n",
      "Ep. 2108 done, reward: -14.0, running_reward: -13.7866, time (sec): 12211.4574\n",
      "Ep. 2110 done, reward: -8.0, running_reward: -13.7408, time (sec): 12233.4781\n",
      "Ep. 2112 done, reward: -10.0, running_reward: -13.6564, time (sec): 12256.7847\n",
      "Ep. 2114 done, reward: -10.0, running_reward: -13.6332, time (sec): 12276.5426\n",
      "Ep. 2116 done, reward: -12.0, running_reward: -13.6106, time (sec): 12293.3020\n",
      "Ep. 2118 done, reward: -13.0, running_reward: -13.5687, time (sec): 12312.7225\n",
      "Ep. 2120 done, reward: -13.0, running_reward: -13.5970, time (sec): 12331.4508\n",
      "Ep. 2122 done, reward: -18.0, running_reward: -13.6153, time (sec): 12347.9574\n",
      "Ep. 2124 done, reward: -13.0, running_reward: -13.6526, time (sec): 12364.0536\n",
      "Ep. 2126 done, reward: -7.0, running_reward: -13.5796, time (sec): 12381.7130\n",
      "Ep. 2128 done, reward: -15.0, running_reward: -13.5287, time (sec): 12401.4315\n",
      "Ep. 2130 done, reward: -16.0, running_reward: -13.5680, time (sec): 12416.9208\n",
      "Ep. 2132 done, reward: -13.0, running_reward: -13.5863, time (sec): 12435.4548\n",
      "Ep. 2134 done, reward: -14.0, running_reward: -13.5649, time (sec): 12454.1379\n",
      "Ep. 2136 done, reward: -13.0, running_reward: -13.5140, time (sec): 12473.7127\n",
      "Ep. 2138 done, reward: -17.0, running_reward: -13.5042, time (sec): 12493.3437\n",
      "Ep. 2140 done, reward: -8.0, running_reward: -13.4442, time (sec): 12510.6490\n",
      "Ep. 2142 done, reward: -17.0, running_reward: -13.5149, time (sec): 12527.0901\n",
      "Ep. 2144 done, reward: -11.0, running_reward: -13.4055, time (sec): 12546.6321\n",
      "Ep. 2146 done, reward: -11.0, running_reward: -13.4368, time (sec): 12562.6327\n",
      "Ep. 2148 done, reward: -12.0, running_reward: -13.4082, time (sec): 12580.4682\n",
      "Ep. 2150 done, reward: -17.0, running_reward: -13.3609, time (sec): 12600.1060\n",
      "Ep. 2152 done, reward: -10.0, running_reward: -13.3237, time (sec): 12619.3775\n",
      "Ep. 2154 done, reward: -12.0, running_reward: -13.3073, time (sec): 12639.2528\n",
      "Ep. 2156 done, reward: -13.0, running_reward: -13.3408, time (sec): 12654.9250\n",
      "Ep. 2158 done, reward: -12.0, running_reward: -13.3834, time (sec): 12671.5474\n",
      "Ep. 2160 done, reward: -19.0, running_reward: -13.4754, time (sec): 12687.8586\n",
      "Ep. 2162 done, reward: -17.0, running_reward: -13.4861, time (sec): 12706.6405\n",
      "Ep. 2164 done, reward: -12.0, running_reward: -13.4268, time (sec): 12728.3822\n",
      "Ep. 2166 done, reward: -4.0, running_reward: -13.3283, time (sec): 12749.2158\n",
      "Ep. 2168 done, reward: -11.0, running_reward: -13.2424, time (sec): 12769.4049\n",
      "Ep. 2170 done, reward: -7.0, running_reward: -13.1677, time (sec): 12788.6007\n",
      "Ep. 2172 done, reward: -11.0, running_reward: -13.1443, time (sec): 12808.2420\n",
      "Ep. 2174 done, reward: -15.0, running_reward: -13.1813, time (sec): 12825.1536\n",
      "Ep. 2176 done, reward: -9.0, running_reward: -13.1278, time (sec): 12846.5599\n",
      "Ep. 2178 done, reward: -12.0, running_reward: -13.1548, time (sec): 12866.6794\n",
      "Ep. 2180 done, reward: -10.0, running_reward: -13.1217, time (sec): 12887.1260\n",
      "Ep. 2182 done, reward: -14.0, running_reward: -13.1095, time (sec): 12907.6518\n",
      "Ep. 2184 done, reward: -10.0, running_reward: -13.1268, time (sec): 12926.0432\n",
      "Ep. 2186 done, reward: -13.0, running_reward: -13.1243, time (sec): 12942.1615\n",
      "Ep. 2188 done, reward: -16.0, running_reward: -13.1617, time (sec): 12956.7922\n",
      "Ep. 2190 done, reward: -13.0, running_reward: -13.1882, time (sec): 12974.7536\n",
      "Ep. 2192 done, reward: -15.0, running_reward: -13.2243, time (sec): 12992.4025\n",
      "Ep. 2194 done, reward: -10.0, running_reward: -13.1106, time (sec): 13014.4594\n",
      "Ep. 2196 done, reward: -14.0, running_reward: -13.1580, time (sec): 13032.5519\n",
      "Ep. 2198 done, reward: -14.0, running_reward: -13.1154, time (sec): 13055.2316\n",
      "Ep. 2200 done, reward: -10.0, running_reward: -13.0732, time (sec): 13071.6762\n",
      "Ep. 2202 done, reward: -11.0, running_reward: -13.0616, time (sec): 13091.2716\n",
      "Ep. 2204 done, reward: -15.0, running_reward: -13.0705, time (sec): 13109.4634\n",
      "Ep. 2206 done, reward: -10.0, running_reward: -13.0292, time (sec): 13131.4202\n",
      "Ep. 2208 done, reward: -11.0, running_reward: -13.0383, time (sec): 13148.2297\n",
      "Ep. 2210 done, reward: -7.0, running_reward: -13.0171, time (sec): 13166.7576\n",
      "Ep. 2212 done, reward: -13.0, running_reward: -13.0465, time (sec): 13185.9756\n",
      "Ep. 2214 done, reward: -15.0, running_reward: -13.0656, time (sec): 13205.7123\n",
      "Ep. 2216 done, reward: -12.0, running_reward: -13.1038, time (sec): 13221.7659\n",
      "Ep. 2218 done, reward: -16.0, running_reward: -13.0723, time (sec): 13239.9066\n",
      "Ep. 2220 done, reward: -15.0, running_reward: -13.0117, time (sec): 13262.4666\n",
      "Ep. 2222 done, reward: -10.0, running_reward: -13.0309, time (sec): 13279.7539\n",
      "Ep. 2224 done, reward: -8.0, running_reward: -12.9011, time (sec): 13304.2835\n",
      "Ep. 2226 done, reward: -8.0, running_reward: -12.8234, time (sec): 13324.3760\n",
      "Ep. 2228 done, reward: -8.0, running_reward: -12.7967, time (sec): 13343.8633\n",
      "Ep. 2230 done, reward: -6.0, running_reward: -12.7505, time (sec): 13362.0296\n",
      "Ep. 2232 done, reward: -10.0, running_reward: -12.7156, time (sec): 13381.1526\n",
      "Ep. 2234 done, reward: -17.0, running_reward: -12.7613, time (sec): 13396.7772\n",
      "Ep. 2236 done, reward: -12.0, running_reward: -12.7065, time (sec): 13414.8127\n",
      "Ep. 2238 done, reward: -9.0, running_reward: -12.5833, time (sec): 13435.5319\n",
      "Ep. 2240 done, reward: -12.0, running_reward: -12.6014, time (sec): 13455.0320\n",
      "Ep. 2242 done, reward: -14.0, running_reward: -12.6193, time (sec): 13473.3211\n",
      "Ep. 2244 done, reward: -8.0, running_reward: -12.5373, time (sec): 13496.1942\n",
      "Ep. 2246 done, reward: -11.0, running_reward: -12.5364, time (sec): 13518.5255\n",
      "Ep. 2248 done, reward: -13.0, running_reward: -12.5357, time (sec): 13538.1385\n",
      "Ep. 2250 done, reward: -10.0, running_reward: -12.5248, time (sec): 13559.2393\n",
      "Ep. 2252 done, reward: -8.0, running_reward: -12.4348, time (sec): 13582.3783\n",
      "Ep. 2254 done, reward: -12.0, running_reward: -12.4162, time (sec): 13598.9294\n",
      "Ep. 2256 done, reward: -5.0, running_reward: -12.3182, time (sec): 13619.6770\n",
      "Ep. 2258 done, reward: -10.0, running_reward: -12.3017, time (sec): 13636.7840\n",
      "Ep. 2260 done, reward: -9.0, running_reward: -12.2261, time (sec): 13657.1734\n",
      "Ep. 2262 done, reward: -10.0, running_reward: -12.2115, time (sec): 13677.7672\n",
      "Ep. 2264 done, reward: -11.0, running_reward: -12.2270, time (sec): 13697.0301\n",
      "Ep. 2266 done, reward: -11.0, running_reward: -12.2224, time (sec): 13714.8261\n",
      "Ep. 2268 done, reward: -13.0, running_reward: -12.2577, time (sec): 13734.7403\n",
      "Ep. 2270 done, reward: -11.0, running_reward: -12.2425, time (sec): 13753.9216\n",
      "Ep. 2272 done, reward: -14.0, running_reward: -12.2577, time (sec): 13774.7181\n",
      "Ep. 2274 done, reward: -14.0, running_reward: -12.1637, time (sec): 13794.9195\n",
      "Ep. 2276 done, reward: -5.0, running_reward: -12.0706, time (sec): 13815.8290\n",
      "Ep. 2278 done, reward: -14.0, running_reward: -12.0991, time (sec): 13833.7553\n",
      "Ep. 2280 done, reward: -9.0, running_reward: -12.0374, time (sec): 13854.9726\n",
      "Ep. 2282 done, reward: -17.0, running_reward: -12.0075, time (sec): 13875.1136\n",
      "Ep. 2284 done, reward: -13.0, running_reward: -11.9877, time (sec): 13895.9071\n",
      "Ep. 2286 done, reward: -7.0, running_reward: -11.9973, time (sec): 13916.3810\n",
      "Ep. 2288 done, reward: -14.0, running_reward: -12.0669, time (sec): 13933.8084\n",
      "Ep. 2290 done, reward: -8.0, running_reward: -12.0750, time (sec): 13951.4669\n",
      "Ep. 2292 done, reward: -16.0, running_reward: -12.0838, time (sec): 13968.8750\n",
      "Ep. 2294 done, reward: -13.0, running_reward: -12.0625, time (sec): 13989.8640\n",
      "Ep. 2296 done, reward: -12.0, running_reward: -12.0711, time (sec): 14008.4102\n",
      "Ep. 2298 done, reward: -14.0, running_reward: -12.0996, time (sec): 14025.4015\n",
      "Ep. 2300 done, reward: -12.0, running_reward: -12.1075, time (sec): 14043.9191\n",
      "Ep. 2302 done, reward: -14.0, running_reward: -12.0957, time (sec): 14061.8723\n",
      "Ep. 2304 done, reward: -13.0, running_reward: -12.1335, time (sec): 14080.1846\n",
      "Ep. 2306 done, reward: -2.0, running_reward: -12.0506, time (sec): 14101.0395\n",
      "Ep. 2308 done, reward: -13.0, running_reward: -12.0299, time (sec): 14120.7229\n",
      "Ep. 2310 done, reward: -11.0, running_reward: -11.9896, time (sec): 14141.3419\n",
      "Ep. 2312 done, reward: -16.0, running_reward: -12.0496, time (sec): 14156.6745\n",
      "Ep. 2314 done, reward: -18.0, running_reward: -12.0789, time (sec): 14172.8138\n",
      "Ep. 2316 done, reward: -13.0, running_reward: -12.0775, time (sec): 14192.1864\n",
      "Ep. 2318 done, reward: -11.0, running_reward: -12.0560, time (sec): 14211.1396\n",
      "Ep. 2320 done, reward: -8.0, running_reward: -12.0050, time (sec): 14231.5419\n",
      "Ep. 2322 done, reward: -6.0, running_reward: -11.9548, time (sec): 14249.6950\n",
      "Ep. 2324 done, reward: -14.0, running_reward: -11.9856, time (sec): 14269.0134\n",
      "Ep. 2326 done, reward: -13.0, running_reward: -12.0157, time (sec): 14286.5346\n",
      "Ep. 2328 done, reward: -4.0, running_reward: -11.8562, time (sec): 14313.1995\n",
      "Ep. 2330 done, reward: -14.0, running_reward: -11.9087, time (sec): 14333.8936\n",
      "Ep. 2332 done, reward: -15.0, running_reward: -11.9604, time (sec): 14356.6457\n",
      "Ep. 2334 done, reward: -13.0, running_reward: -11.9613, time (sec): 14376.7756\n",
      "Ep. 2336 done, reward: -11.0, running_reward: -11.9520, time (sec): 14396.5652\n",
      "Ep. 2338 done, reward: -14.0, running_reward: -11.9631, time (sec): 14417.9165\n",
      "Ep. 2340 done, reward: -15.0, running_reward: -11.9839, time (sec): 14437.7140\n",
      "Ep. 2342 done, reward: -13.0, running_reward: -11.9645, time (sec): 14455.3170\n",
      "Ep. 2344 done, reward: -13.0, running_reward: -11.9455, time (sec): 14476.1832\n",
      "Ep. 2346 done, reward: -17.0, running_reward: -12.0263, time (sec): 14493.1409\n",
      "Ep. 2348 done, reward: -11.0, running_reward: -12.0158, time (sec): 14510.0041\n",
      "Ep. 2350 done, reward: -15.0, running_reward: -12.0950, time (sec): 14524.9585\n",
      "Ep. 2352 done, reward: -14.0, running_reward: -12.1329, time (sec): 14542.8192\n",
      "Ep. 2354 done, reward: -13.0, running_reward: -12.1402, time (sec): 14564.7889\n",
      "Ep. 2356 done, reward: -10.0, running_reward: -12.1076, time (sec): 14582.8116\n",
      "Ep. 2358 done, reward: -16.0, running_reward: -12.0563, time (sec): 14602.5906\n",
      "Ep. 2360 done, reward: -14.0, running_reward: -12.0851, time (sec): 14621.1313\n",
      "Ep. 2362 done, reward: -17.0, running_reward: -12.1631, time (sec): 14640.3872\n",
      "Ep. 2364 done, reward: -9.0, running_reward: -12.1101, time (sec): 14663.7718\n",
      "Ep. 2366 done, reward: -12.0, running_reward: -12.0683, time (sec): 14684.3751\n",
      "Ep. 2368 done, reward: -18.0, running_reward: -12.1368, time (sec): 14699.7254\n",
      "Ep. 2370 done, reward: -8.0, running_reward: -12.1040, time (sec): 14718.0340\n",
      "Ep. 2372 done, reward: -15.0, running_reward: -12.1715, time (sec): 14736.9840\n",
      "Ep. 2374 done, reward: -15.0, running_reward: -12.2080, time (sec): 14757.4417\n",
      "Ep. 2376 done, reward: -14.0, running_reward: -12.2140, time (sec): 14775.4460\n",
      "Ep. 2378 done, reward: -11.0, running_reward: -12.1898, time (sec): 14796.8373\n",
      "Ep. 2380 done, reward: -15.0, running_reward: -12.2556, time (sec): 14814.3381\n",
      "Ep. 2382 done, reward: -15.0, running_reward: -12.2904, time (sec): 14832.8202\n",
      "Ep. 2384 done, reward: -11.0, running_reward: -12.2846, time (sec): 14853.0358\n",
      "Ep. 2386 done, reward: -13.0, running_reward: -12.3087, time (sec): 14872.1015\n",
      "Ep. 2388 done, reward: -10.0, running_reward: -12.3123, time (sec): 14891.4668\n",
      "Ep. 2390 done, reward: -15.0, running_reward: -12.3657, time (sec): 14906.1343\n",
      "Ep. 2392 done, reward: -10.0, running_reward: -12.3385, time (sec): 14926.4268\n",
      "Ep. 2394 done, reward: -15.0, running_reward: -12.3518, time (sec): 14944.5748\n",
      "Ep. 2396 done, reward: -9.0, running_reward: -12.2554, time (sec): 14963.9865\n",
      "Ep. 2398 done, reward: -12.0, running_reward: -12.2602, time (sec): 14985.7912\n",
      "Ep. 2400 done, reward: -6.0, running_reward: -12.2050, time (sec): 15004.7007\n",
      "Ep. 2402 done, reward: -13.0, running_reward: -12.2208, time (sec): 15023.3308\n",
      "Ep. 2404 done, reward: -8.0, running_reward: -12.1863, time (sec): 15044.0299\n",
      "Ep. 2406 done, reward: -9.0, running_reward: -12.2120, time (sec): 15062.2208\n",
      "Ep. 2408 done, reward: -14.0, running_reward: -12.2773, time (sec): 15080.4687\n",
      "Ep. 2410 done, reward: -15.0, running_reward: -12.3314, time (sec): 15097.7724\n",
      "Ep. 2412 done, reward: -17.0, running_reward: -12.3650, time (sec): 15115.9707\n",
      "Ep. 2414 done, reward: -14.0, running_reward: -12.4074, time (sec): 15136.3585\n",
      "Ep. 2416 done, reward: -7.0, running_reward: -12.3493, time (sec): 15156.8137\n",
      "Ep. 2418 done, reward: -14.0, running_reward: -12.3821, time (sec): 15174.8383\n",
      "Ep. 2420 done, reward: -15.0, running_reward: -12.4144, time (sec): 15194.3498\n",
      "Ep. 2422 done, reward: -13.0, running_reward: -12.4756, time (sec): 15211.6742\n",
      "Ep. 2424 done, reward: -14.0, running_reward: -12.5356, time (sec): 15227.5410\n",
      "Ep. 2426 done, reward: -16.0, running_reward: -12.5650, time (sec): 15245.7560\n",
      "Ep. 2428 done, reward: -17.0, running_reward: -12.5641, time (sec): 15264.1678\n",
      "Ep. 2430 done, reward: -10.0, running_reward: -12.4933, time (sec): 15287.2416\n",
      "Ep. 2432 done, reward: -5.0, running_reward: -12.4531, time (sec): 15310.3164\n",
      "Ep. 2434 done, reward: -15.0, running_reward: -12.4840, time (sec): 15329.4315\n",
      "Ep. 2436 done, reward: -16.0, running_reward: -12.5638, time (sec): 15349.1168\n",
      "Ep. 2438 done, reward: -15.0, running_reward: -12.5826, time (sec): 15369.9339\n",
      "Ep. 2440 done, reward: -9.0, running_reward: -12.4816, time (sec): 15392.4591\n",
      "Ep. 2442 done, reward: -9.0, running_reward: -12.4024, time (sec): 15410.9437\n",
      "Ep. 2444 done, reward: -4.0, running_reward: -12.3639, time (sec): 15433.0304\n",
      "Ep. 2446 done, reward: -16.0, running_reward: -12.3769, time (sec): 15454.9091\n",
      "Ep. 2448 done, reward: -11.0, running_reward: -12.4188, time (sec): 15469.5003\n",
      "Ep. 2450 done, reward: -12.0, running_reward: -12.4203, time (sec): 15487.2962\n",
      "Ep. 2452 done, reward: -15.0, running_reward: -12.3925, time (sec): 15505.8805\n",
      "Ep. 2454 done, reward: -11.0, running_reward: -12.3846, time (sec): 15524.1359\n",
      "Ep. 2456 done, reward: -16.0, running_reward: -12.3476, time (sec): 15544.4052\n",
      "Ep. 2458 done, reward: -12.0, running_reward: -12.3407, time (sec): 15561.1317\n",
      "Ep. 2460 done, reward: -9.0, running_reward: -12.3336, time (sec): 15580.2400\n",
      "Ep. 2462 done, reward: -12.0, running_reward: -12.3171, time (sec): 15597.5312\n",
      "Ep. 2464 done, reward: -9.0, running_reward: -12.2313, time (sec): 15619.0560\n",
      "Ep. 2466 done, reward: -8.0, running_reward: -12.1174, time (sec): 15639.1028\n",
      "Ep. 2468 done, reward: -11.0, running_reward: -12.1050, time (sec): 15658.3335\n",
      "Ep. 2470 done, reward: -17.0, running_reward: -12.0638, time (sec): 15676.6669\n",
      "Ep. 2472 done, reward: -11.0, running_reward: -12.0328, time (sec): 15697.6015\n",
      "Ep. 2474 done, reward: -14.0, running_reward: -12.1016, time (sec): 15714.3161\n",
      "Ep. 2476 done, reward: -13.0, running_reward: -12.0799, time (sec): 15733.7685\n",
      "Ep. 2478 done, reward: -13.0, running_reward: -12.0388, time (sec): 15752.1895\n",
      "Ep. 2480 done, reward: -4.0, running_reward: -11.9382, time (sec): 15774.9381\n",
      "Ep. 2482 done, reward: -7.0, running_reward: -11.8103, time (sec): 15797.1870\n",
      "Ep. 2484 done, reward: -16.0, running_reward: -11.8837, time (sec): 15817.1713\n",
      "Ep. 2486 done, reward: -8.0, running_reward: -11.8857, time (sec): 15836.7684\n",
      "Ep. 2488 done, reward: -15.0, running_reward: -11.8684, time (sec): 15856.0884\n",
      "Ep. 2490 done, reward: -13.0, running_reward: -11.8315, time (sec): 15875.4718\n",
      "Ep. 2492 done, reward: -9.0, running_reward: -11.8247, time (sec): 15894.8170\n",
      "Ep. 2494 done, reward: -13.0, running_reward: -11.8382, time (sec): 15912.3285\n",
      "Ep. 2496 done, reward: -15.0, running_reward: -11.8714, time (sec): 15930.1800\n",
      "Ep. 2498 done, reward: -13.0, running_reward: -11.9038, time (sec): 15949.1857\n",
      "Ep. 2500 done, reward: -11.0, running_reward: -11.8660, time (sec): 15969.9977\n",
      "Ep. 2502 done, reward: -10.0, running_reward: -11.8387, time (sec): 15991.0967\n",
      "Ep. 2504 done, reward: -13.0, running_reward: -11.9015, time (sec): 16009.8849\n",
      "Ep. 2506 done, reward: -4.0, running_reward: -11.7739, time (sec): 16032.4401\n",
      "Ep. 2508 done, reward: -11.0, running_reward: -11.7783, time (sec): 16051.8594\n",
      "Ep. 2510 done, reward: -14.0, running_reward: -11.7829, time (sec): 16070.7098\n",
      "Ep. 2512 done, reward: -15.0, running_reward: -11.8568, time (sec): 16088.2947\n",
      "Ep. 2514 done, reward: -13.0, running_reward: -11.9390, time (sec): 16107.4722\n",
      "Ep. 2516 done, reward: -8.0, running_reward: -11.9497, time (sec): 16127.5913\n",
      "Ep. 2518 done, reward: -16.0, running_reward: -11.9610, time (sec): 16145.6471\n",
      "Ep. 2520 done, reward: -13.0, running_reward: -11.9916, time (sec): 16163.5400\n",
      "Ep. 2522 done, reward: -17.0, running_reward: -11.9824, time (sec): 16181.4233\n",
      "Ep. 2524 done, reward: -11.0, running_reward: -11.9133, time (sec): 16200.7969\n",
      "Ep. 2526 done, reward: -15.0, running_reward: -11.9252, time (sec): 16218.8990\n",
      "Ep. 2528 done, reward: -12.0, running_reward: -11.9465, time (sec): 16240.0354\n",
      "Ep. 2530 done, reward: -13.0, running_reward: -11.9675, time (sec): 16257.2982\n",
      "Ep. 2532 done, reward: -12.0, running_reward: -11.9087, time (sec): 16278.3183\n",
      "Ep. 2534 done, reward: -12.0, running_reward: -11.8907, time (sec): 16295.9343\n",
      "Ep. 2536 done, reward: -10.0, running_reward: -11.8828, time (sec): 16314.9923\n",
      "Ep. 2538 done, reward: -17.0, running_reward: -11.8956, time (sec): 16334.8350\n",
      "Ep. 2540 done, reward: -7.0, running_reward: -11.8674, time (sec): 16356.7145\n",
      "Ep. 2542 done, reward: -12.0, running_reward: -11.8602, time (sec): 16376.2163\n",
      "Ep. 2544 done, reward: -16.0, running_reward: -11.8832, time (sec): 16394.0141\n",
      "Ep. 2546 done, reward: -9.0, running_reward: -11.8060, time (sec): 16416.4972\n",
      "Ep. 2548 done, reward: -5.0, running_reward: -11.6804, time (sec): 16441.2163\n",
      "Ep. 2550 done, reward: -12.0, running_reward: -11.6571, time (sec): 16461.4622\n",
      "Ep. 2552 done, reward: -15.0, running_reward: -11.6840, time (sec): 16481.2532\n",
      "Ep. 2554 done, reward: -10.0, running_reward: -11.7297, time (sec): 16498.1551\n",
      "Ep. 2556 done, reward: -10.0, running_reward: -11.7052, time (sec): 16516.8228\n",
      "Ep. 2558 done, reward: -9.0, running_reward: -11.6415, time (sec): 16539.5762\n",
      "Ep. 2560 done, reward: -6.0, running_reward: -11.6282, time (sec): 16564.1776\n",
      "Ep. 2562 done, reward: -15.0, running_reward: -11.5963, time (sec): 16583.7529\n",
      "Ep. 2564 done, reward: -13.0, running_reward: -11.6440, time (sec): 16603.8672\n",
      "Ep. 2566 done, reward: -13.0, running_reward: -11.6314, time (sec): 16623.7744\n",
      "Ep. 2568 done, reward: -3.0, running_reward: -11.5685, time (sec): 16645.6315\n",
      "Ep. 2570 done, reward: -5.0, running_reward: -11.5566, time (sec): 16663.7651\n",
      "Ep. 2572 done, reward: -13.0, running_reward: -11.5458, time (sec): 16681.8995\n",
      "Ep. 2574 done, reward: -11.0, running_reward: -11.5745, time (sec): 16698.4261\n",
      "Ep. 2576 done, reward: -7.0, running_reward: -11.5330, time (sec): 16720.5288\n",
      "Ep. 2578 done, reward: -8.0, running_reward: -11.4726, time (sec): 16741.8744\n",
      "Ep. 2580 done, reward: -9.0, running_reward: -11.4629, time (sec): 16761.3044\n",
      "Ep. 2582 done, reward: -16.0, running_reward: -11.5235, time (sec): 16779.3137\n",
      "Ep. 2584 done, reward: -15.0, running_reward: -11.4343, time (sec): 16804.1572\n",
      "Ep. 2586 done, reward: -5.0, running_reward: -11.3657, time (sec): 16822.8280\n",
      "Ep. 2588 done, reward: -15.0, running_reward: -11.3588, time (sec): 16841.8624\n",
      "Ep. 2590 done, reward: -9.0, running_reward: -11.3317, time (sec): 16860.1135\n",
      "Ep. 2592 done, reward: -13.0, running_reward: -11.4243, time (sec): 16880.5629\n",
      "Ep. 2594 done, reward: -8.0, running_reward: -11.3660, time (sec): 16899.7382\n",
      "Ep. 2596 done, reward: -9.0, running_reward: -11.2793, time (sec): 16923.1787\n",
      "Ep. 2598 done, reward: -13.0, running_reward: -11.2839, time (sec): 16941.7165\n",
      "Ep. 2600 done, reward: -8.0, running_reward: -11.2284, time (sec): 16964.4916\n",
      "Ep. 2602 done, reward: -17.0, running_reward: -11.3235, time (sec): 16983.2532\n",
      "Ep. 2604 done, reward: -8.0, running_reward: -11.2672, time (sec): 17001.8663\n",
      "Ep. 2606 done, reward: -4.0, running_reward: -11.2711, time (sec): 17021.0585\n",
      "Ep. 2608 done, reward: 10.0, running_reward: -11.0755, time (sec): 17040.1858\n",
      "Ep. 2610 done, reward: -6.0, running_reward: -11.0339, time (sec): 17061.5141\n",
      "Ep. 2612 done, reward: -8.0, running_reward: -11.0131, time (sec): 17081.5619\n",
      "Ep. 2614 done, reward: -6.0, running_reward: -11.0322, time (sec): 17103.1274\n",
      "Ep. 2616 done, reward: -11.0, running_reward: -11.0117, time (sec): 17123.2068\n",
      "Ep. 2618 done, reward: -7.0, running_reward: -10.9616, time (sec): 17147.2028\n",
      "Ep. 2620 done, reward: -18.0, running_reward: -10.9928, time (sec): 17167.9344\n",
      "Ep. 2622 done, reward: -12.0, running_reward: -11.0029, time (sec): 17185.5402\n",
      "Ep. 2624 done, reward: -9.0, running_reward: -11.0027, time (sec): 17204.3244\n",
      "Ep. 2626 done, reward: -15.0, running_reward: -11.0228, time (sec): 17225.0377\n",
      "Ep. 2628 done, reward: -15.0, running_reward: -11.0723, time (sec): 17243.9552\n",
      "Ep. 2630 done, reward: -1.0, running_reward: -11.0104, time (sec): 17263.9305\n",
      "Ep. 2632 done, reward: -19.0, running_reward: -11.0011, time (sec): 17281.6340\n",
      "Ep. 2634 done, reward: -10.0, running_reward: -10.9812, time (sec): 17301.5717\n",
      "Ep. 2636 done, reward: -7.0, running_reward: -10.9218, time (sec): 17323.5677\n",
      "Ep. 2638 done, reward: -7.0, running_reward: -10.8734, time (sec): 17343.8675\n",
      "Ep. 2640 done, reward: -12.0, running_reward: -10.8661, time (sec): 17362.8990\n",
      "Ep. 2642 done, reward: -9.0, running_reward: -10.8389, time (sec): 17382.5349\n",
      "Ep. 2644 done, reward: -13.0, running_reward: -10.8819, time (sec): 17401.5196\n",
      "Ep. 2646 done, reward: -8.0, running_reward: -10.7751, time (sec): 17422.9805\n",
      "Ep. 2648 done, reward: -13.0, running_reward: -10.7599, time (sec): 17442.7874\n",
      "Ep. 2650 done, reward: -13.0, running_reward: -10.7748, time (sec): 17459.5981\n",
      "Ep. 2652 done, reward: -7.0, running_reward: -10.6997, time (sec): 17479.7882\n",
      "Ep. 2654 done, reward: -3.0, running_reward: -10.5762, time (sec): 17502.5155\n",
      "Ep. 2656 done, reward: -13.0, running_reward: -10.5848, time (sec): 17522.5893\n",
      "Ep. 2658 done, reward: -7.0, running_reward: -10.5135, time (sec): 17544.1550\n",
      "Ep. 2660 done, reward: -9.0, running_reward: -10.4635, time (sec): 17566.7727\n",
      "Ep. 2662 done, reward: -14.0, running_reward: -10.5240, time (sec): 17584.2171\n",
      "Ep. 2664 done, reward: -4.0, running_reward: -10.4833, time (sec): 17606.2991\n",
      "Ep. 2666 done, reward: -14.0, running_reward: -10.5533, time (sec): 17623.0823\n",
      "Ep. 2668 done, reward: -8.0, running_reward: -10.5124, time (sec): 17645.7972\n",
      "Ep. 2670 done, reward: -13.0, running_reward: -10.4926, time (sec): 17666.0825\n",
      "Ep. 2672 done, reward: -17.0, running_reward: -10.5825, time (sec): 17684.0662\n",
      "Ep. 2674 done, reward: -12.0, running_reward: -10.6107, time (sec): 17704.1049\n",
      "Ep. 2676 done, reward: -15.0, running_reward: -10.6089, time (sec): 17722.3024\n",
      "Ep. 2678 done, reward: -10.0, running_reward: -10.5968, time (sec): 17742.1817\n",
      "Ep. 2680 done, reward: -8.0, running_reward: -10.5451, time (sec): 17763.7648\n",
      "Ep. 2682 done, reward: -10.0, running_reward: -10.4650, time (sec): 17784.5621\n",
      "Ep. 2684 done, reward: 11.0, running_reward: -10.1665, time (sec): 17805.9350\n",
      "Ep. 2686 done, reward: -5.0, running_reward: -10.1231, time (sec): 17829.3282\n",
      "Ep. 2688 done, reward: -11.0, running_reward: -10.1010, time (sec): 17850.8126\n",
      "Ep. 2690 done, reward: -11.0, running_reward: -10.1585, time (sec): 17870.5094\n",
      "Ep. 2692 done, reward: -12.0, running_reward: -10.1852, time (sec): 17889.2568\n",
      "Ep. 2694 done, reward: -8.0, running_reward: -10.1714, time (sec): 17907.5206\n",
      "Ep. 2696 done, reward: -9.0, running_reward: -10.1481, time (sec): 17929.4301\n",
      "Ep. 2698 done, reward: -8.0, running_reward: -10.1648, time (sec): 17946.5742\n",
      "Ep. 2700 done, reward: -13.0, running_reward: -10.1816, time (sec): 17966.9935\n",
      "Ep. 2702 done, reward: -7.0, running_reward: -10.1678, time (sec): 17987.1272\n",
      "Ep. 2704 done, reward: -11.0, running_reward: -10.2041, time (sec): 18006.2446\n",
      "Ep. 2706 done, reward: -10.0, running_reward: -10.2298, time (sec): 18024.3799\n",
      "Ep. 2708 done, reward: -13.0, running_reward: -10.2948, time (sec): 18042.7018\n",
      "Ep. 2710 done, reward: -7.0, running_reward: -10.2886, time (sec): 18060.8450\n",
      "Ep. 2712 done, reward: -14.0, running_reward: -10.2338, time (sec): 18082.7360\n",
      "Ep. 2714 done, reward: -10.0, running_reward: -10.1697, time (sec): 18104.3378\n",
      "Ep. 2716 done, reward: 3.0, running_reward: -9.9968, time (sec): 18129.3363\n",
      "Ep. 2718 done, reward: -11.0, running_reward: -9.9375, time (sec): 18152.1640\n",
      "Ep. 2720 done, reward: -11.0, running_reward: -10.0082, time (sec): 18170.5239\n",
      "Ep. 2722 done, reward: -18.0, running_reward: -10.1771, time (sec): 18189.3735\n",
      "Ep. 2724 done, reward: -12.0, running_reward: -10.2233, time (sec): 18209.1812\n",
      "Ep. 2726 done, reward: -11.0, running_reward: -10.2090, time (sec): 18234.4347\n",
      "Ep. 2728 done, reward: -15.0, running_reward: -10.2747, time (sec): 18252.6136\n",
      "Ep. 2730 done, reward: -15.0, running_reward: -10.2994, time (sec): 18272.2995\n",
      "Ep. 2732 done, reward: -9.0, running_reward: -10.3131, time (sec): 18292.5149\n",
      "Ep. 2734 done, reward: -5.0, running_reward: -10.2965, time (sec): 18310.4132\n",
      "Ep. 2736 done, reward: -11.0, running_reward: -10.2907, time (sec): 18328.9406\n",
      "Ep. 2738 done, reward: -7.0, running_reward: -10.2252, time (sec): 18352.4711\n",
      "Ep. 2740 done, reward: -12.0, running_reward: -10.2506, time (sec): 18374.7497\n",
      "Ep. 2742 done, reward: -9.0, running_reward: -10.3050, time (sec): 18392.9728\n",
      "Ep. 2744 done, reward: -11.0, running_reward: -10.3188, time (sec): 18412.9194\n",
      "Ep. 2746 done, reward: -12.0, running_reward: -10.3324, time (sec): 18431.0897\n",
      "Ep. 2748 done, reward: -4.0, running_reward: -10.2856, time (sec): 18451.4742\n",
      "Ep. 2750 done, reward: -13.0, running_reward: -10.3198, time (sec): 18471.2249\n",
      "Ep. 2752 done, reward: 4.0, running_reward: -10.2032, time (sec): 18491.2988\n",
      "Ep. 2754 done, reward: -15.0, running_reward: -10.2392, time (sec): 18508.1311\n",
      "Ep. 2756 done, reward: -14.0, running_reward: -10.3141, time (sec): 18529.0452\n",
      "Ep. 2758 done, reward: 7.0, running_reward: -10.1279, time (sec): 18551.8923\n",
      "Ep. 2760 done, reward: -9.0, running_reward: -10.1253, time (sec): 18572.8549\n",
      "Ep. 2762 done, reward: -17.0, running_reward: -10.2225, time (sec): 18591.9392\n",
      "Ep. 2764 done, reward: -15.0, running_reward: -10.1988, time (sec): 18611.2230\n",
      "Ep. 2766 done, reward: -13.0, running_reward: -10.1852, time (sec): 18632.6438\n",
      "Ep. 2768 done, reward: -12.0, running_reward: -10.2015, time (sec): 18654.8646\n",
      "Ep. 2770 done, reward: -13.0, running_reward: -10.2275, time (sec): 18676.8057\n",
      "Ep. 2772 done, reward: -1.0, running_reward: -10.0934, time (sec): 18701.8280\n",
      "Ep. 2774 done, reward: -13.0, running_reward: -10.1017, time (sec): 18719.1865\n",
      "Ep. 2776 done, reward: -4.0, running_reward: -10.0694, time (sec): 18741.9847\n",
      "Ep. 2778 done, reward: -10.0, running_reward: -10.0779, time (sec): 18760.5141\n",
      "Ep. 2780 done, reward: -13.0, running_reward: -10.1262, time (sec): 18779.1119\n",
      "Ep. 2782 done, reward: -14.0, running_reward: -10.1835, time (sec): 18797.8675\n",
      "Ep. 2784 done, reward: -17.0, running_reward: -10.2696, time (sec): 18815.7038\n",
      "Ep. 2786 done, reward: -10.0, running_reward: -10.2741, time (sec): 18834.5630\n",
      "Ep. 2788 done, reward: -8.0, running_reward: -10.2190, time (sec): 18854.6628\n",
      "Ep. 2790 done, reward: -5.0, running_reward: -10.1943, time (sec): 18875.6375\n",
      "Ep. 2792 done, reward: -9.0, running_reward: -10.1904, time (sec): 18895.4219\n",
      "Ep. 2794 done, reward: -8.0, running_reward: -10.1270, time (sec): 18917.9249\n",
      "Ep. 2796 done, reward: -17.0, running_reward: -10.2538, time (sec): 18937.1784\n",
      "Ep. 2798 done, reward: -13.0, running_reward: -10.2788, time (sec): 18958.2865\n",
      "Ep. 2800 done, reward: -14.0, running_reward: -10.3033, time (sec): 18980.5265\n",
      "Ep. 2802 done, reward: -14.0, running_reward: -10.3571, time (sec): 18996.7547\n",
      "Ep. 2804 done, reward: -13.0, running_reward: -10.4295, time (sec): 19017.2496\n",
      "Ep. 2806 done, reward: -14.0, running_reward: -10.4808, time (sec): 19035.9503\n",
      "Ep. 2808 done, reward: -10.0, running_reward: -10.4019, time (sec): 19058.4193\n",
      "Ep. 2810 done, reward: -9.0, running_reward: -10.4037, time (sec): 19077.1719\n",
      "Ep. 2812 done, reward: -7.0, running_reward: -10.3261, time (sec): 19099.0739\n",
      "Ep. 2814 done, reward: -6.0, running_reward: -10.2697, time (sec): 19119.9304\n",
      "Ep. 2816 done, reward: -12.0, running_reward: -10.2546, time (sec): 19138.8641\n",
      "Ep. 2818 done, reward: -15.0, running_reward: -10.3193, time (sec): 19159.5006\n",
      "Ep. 2820 done, reward: -7.0, running_reward: -10.1147, time (sec): 19179.9182\n",
      "Ep. 2822 done, reward: -7.0, running_reward: -10.0230, time (sec): 19201.5966\n",
      "Ep. 2824 done, reward: -13.0, running_reward: -10.0129, time (sec): 19223.5316\n",
      "Ep. 2826 done, reward: -15.0, running_reward: -10.1320, time (sec): 19239.8281\n",
      "Ep. 2828 done, reward: -4.0, running_reward: -10.0100, time (sec): 19261.0899\n",
      "Ep. 2830 done, reward: -14.0, running_reward: -10.0795, time (sec): 19278.9721\n",
      "Ep. 2832 done, reward: -8.0, running_reward: -10.0876, time (sec): 19297.6511\n",
      "Ep. 2834 done, reward: -14.0, running_reward: -10.1159, time (sec): 19318.0852\n",
      "Ep. 2836 done, reward: -9.0, running_reward: -10.0838, time (sec): 19339.9306\n",
      "Ep. 2838 done, reward: -13.0, running_reward: -10.1221, time (sec): 19356.4158\n",
      "Ep. 2840 done, reward: -13.0, running_reward: -10.2288, time (sec): 19373.9805\n",
      "Ep. 2842 done, reward: -15.0, running_reward: -10.2644, time (sec): 19394.7200\n",
      "Ep. 2844 done, reward: -17.0, running_reward: -10.2895, time (sec): 19415.6198\n",
      "Ep. 2846 done, reward: -13.0, running_reward: -10.3435, time (sec): 19433.2440\n",
      "Ep. 2848 done, reward: -10.0, running_reward: -10.3564, time (sec): 19453.2248\n",
      "Ep. 2850 done, reward: -12.0, running_reward: -10.4089, time (sec): 19472.4844\n",
      "Ep. 2852 done, reward: 1.0, running_reward: -10.2908, time (sec): 19495.0096\n",
      "Ep. 2854 done, reward: -11.0, running_reward: -10.3049, time (sec): 19518.3038\n",
      "Ep. 2856 done, reward: -12.0, running_reward: -10.2891, time (sec): 19539.5399\n",
      "Ep. 2858 done, reward: -3.0, running_reward: -10.2134, time (sec): 19560.1742\n",
      "Ep. 2860 done, reward: -8.0, running_reward: -10.1297, time (sec): 19585.9059\n",
      "Ep. 2862 done, reward: -5.0, running_reward: -10.1168, time (sec): 19607.9822\n",
      "Ep. 2864 done, reward: -7.0, running_reward: -10.0745, time (sec): 19628.9580\n",
      "Ep. 2866 done, reward: -11.0, running_reward: -10.1424, time (sec): 19648.3208\n",
      "Ep. 2868 done, reward: -9.0, running_reward: -10.0603, time (sec): 19672.9822\n",
      "Ep. 2870 done, reward: -4.0, running_reward: -10.0288, time (sec): 19695.4119\n",
      "Ep. 2872 done, reward: -10.0, running_reward: -10.0678, time (sec): 19714.6898\n",
      "Ep. 2874 done, reward: -14.0, running_reward: -10.1065, time (sec): 19734.9094\n",
      "Ep. 2876 done, reward: -17.0, running_reward: -10.1744, time (sec): 19752.1607\n",
      "Ep. 2878 done, reward: -5.0, running_reward: -10.1704, time (sec): 19773.0838\n",
      "Ep. 2880 done, reward: -13.0, running_reward: -10.1772, time (sec): 19791.8184\n",
      "Ep. 2882 done, reward: -15.0, running_reward: -10.2237, time (sec): 19812.9826\n",
      "Ep. 2884 done, reward: -10.0, running_reward: -10.2687, time (sec): 19828.6510\n",
      "Ep. 2886 done, reward: -7.0, running_reward: -10.1839, time (sec): 19850.5827\n",
      "Ep. 2888 done, reward: -12.0, running_reward: -10.0517, time (sec): 19870.4392\n",
      "Ep. 2890 done, reward: -13.0, running_reward: -10.0015, time (sec): 19891.8549\n",
      "Ep. 2892 done, reward: -11.0, running_reward: -10.0412, time (sec): 19912.4590\n",
      "Ep. 2894 done, reward: -10.0, running_reward: -10.0700, time (sec): 19934.2320\n",
      "Ep. 2896 done, reward: -10.0, running_reward: -10.0093, time (sec): 19958.2357\n",
      "Ep. 2898 done, reward: -6.0, running_reward: -9.9988, time (sec): 19982.7069\n",
      "Ep. 2900 done, reward: -19.0, running_reward: -10.0888, time (sec): 20003.0991\n",
      "Ep. 2902 done, reward: -12.0, running_reward: -10.0674, time (sec): 20023.5309\n",
      "Ep. 2904 done, reward: -11.0, running_reward: -10.0860, time (sec): 20043.1249\n",
      "Ep. 2906 done, reward: -4.0, running_reward: -10.0342, time (sec): 20065.4058\n",
      "Ep. 2908 done, reward: -8.0, running_reward: -10.0531, time (sec): 20089.4370\n",
      "Ep. 2910 done, reward: -11.0, running_reward: -10.0719, time (sec): 20110.8486\n",
      "Ep. 2912 done, reward: -9.0, running_reward: -10.0902, time (sec): 20131.7570\n",
      "Ep. 2914 done, reward: -6.0, running_reward: -10.0583, time (sec): 20152.7919\n",
      "Ep. 2916 done, reward: -10.0, running_reward: -10.1066, time (sec): 20173.8288\n",
      "Ep. 2918 done, reward: -11.0, running_reward: -10.0848, time (sec): 20199.5596\n",
      "Ep. 2920 done, reward: -14.0, running_reward: -10.1726, time (sec): 20215.8285\n",
      "Ep. 2922 done, reward: -11.0, running_reward: -10.1693, time (sec): 20236.4585\n",
      "Ep. 2924 done, reward: -11.0, running_reward: -10.1660, time (sec): 20256.5427\n",
      "Ep. 2926 done, reward: -9.0, running_reward: -10.0933, time (sec): 20277.3120\n",
      "Ep. 2928 done, reward: -14.0, running_reward: -10.0820, time (sec): 20296.8003\n",
      "Ep. 2930 done, reward: -13.0, running_reward: -10.1202, time (sec): 20315.2752\n",
      "Ep. 2932 done, reward: -14.0, running_reward: -10.1677, time (sec): 20334.1760\n",
      "Ep. 2934 done, reward: -15.0, running_reward: -10.2342, time (sec): 20355.3006\n",
      "Ep. 2936 done, reward: -4.0, running_reward: -10.1398, time (sec): 20378.2621\n",
      "Ep. 2938 done, reward: -3.0, running_reward: -10.1166, time (sec): 20400.1201\n",
      "Ep. 2940 done, reward: -2.0, running_reward: -9.9649, time (sec): 20424.5435\n",
      "Ep. 2942 done, reward: -7.0, running_reward: -9.9257, time (sec): 20445.2005\n",
      "Ep. 2944 done, reward: -17.0, running_reward: -10.0863, time (sec): 20461.6350\n",
      "Ep. 2946 done, reward: -13.0, running_reward: -10.0849, time (sec): 20482.2541\n",
      "Ep. 2948 done, reward: -9.0, running_reward: -10.1128, time (sec): 20503.8552\n",
      "Ep. 2950 done, reward: -7.0, running_reward: -10.1301, time (sec): 20524.1248\n",
      "Ep. 2952 done, reward: -19.0, running_reward: -10.2274, time (sec): 20543.1545\n",
      "Ep. 2954 done, reward: -10.0, running_reward: -10.1833, time (sec): 20565.8605\n",
      "Ep. 2956 done, reward: -15.0, running_reward: -10.2989, time (sec): 20587.1772\n",
      "Ep. 2958 done, reward: -13.0, running_reward: -10.3032, time (sec): 20606.1619\n",
      "Ep. 2960 done, reward: -13.0, running_reward: -10.2677, time (sec): 20625.9917\n",
      "Ep. 2962 done, reward: -10.0, running_reward: -10.2921, time (sec): 20646.4796\n",
      "Ep. 2964 done, reward: -10.0, running_reward: -10.3160, time (sec): 20665.8609\n",
      "Ep. 2966 done, reward: -17.0, running_reward: -10.4094, time (sec): 20682.2513\n",
      "Ep. 2968 done, reward: -9.0, running_reward: -10.4309, time (sec): 20703.9666\n",
      "Ep. 2970 done, reward: -7.0, running_reward: -10.4022, time (sec): 20728.3731\n",
      "Ep. 2972 done, reward: -7.0, running_reward: -10.3147, time (sec): 20751.8653\n",
      "Ep. 2974 done, reward: -17.0, running_reward: -10.3487, time (sec): 20774.7970\n",
      "Ep. 2976 done, reward: -14.0, running_reward: -10.3719, time (sec): 20792.7028\n",
      "Ep. 2978 done, reward: -15.0, running_reward: -10.4442, time (sec): 20812.4791\n",
      "Ep. 2980 done, reward: -3.0, running_reward: -10.2564, time (sec): 20839.1374\n",
      "Ep. 2982 done, reward: -10.0, running_reward: -10.2513, time (sec): 20860.5637\n",
      "Ep. 2984 done, reward: -6.0, running_reward: -10.0875, time (sec): 20883.8652\n",
      "Ep. 2986 done, reward: -7.0, running_reward: -10.0459, time (sec): 20906.3209\n",
      "Ep. 2988 done, reward: -8.0, running_reward: -10.0151, time (sec): 20929.5269\n",
      "Ep. 2990 done, reward: -8.0, running_reward: -10.0146, time (sec): 20949.5097\n",
      "Ep. 2992 done, reward: -11.0, running_reward: -9.9946, time (sec): 20972.2139\n",
      "Ep. 2994 done, reward: -11.0, running_reward: -9.9651, time (sec): 20994.7812\n",
      "Ep. 2996 done, reward: -11.0, running_reward: -10.0055, time (sec): 21017.7256\n",
      "Ep. 2998 done, reward: -9.0, running_reward: -10.0152, time (sec): 21038.2801\n",
      "Ep. 3000 done, reward: -6.0, running_reward: -9.9056, time (sec): 21059.9793\n",
      "Ep. 3002 done, reward: -13.0, running_reward: -9.9375, time (sec): 21082.4770\n",
      "Ep. 3004 done, reward: -15.0, running_reward: -10.0382, time (sec): 21103.6956\n",
      "Ep. 3006 done, reward: -11.0, running_reward: -10.0672, time (sec): 21124.6896\n",
      "Ep. 3008 done, reward: -13.0, running_reward: -10.1454, time (sec): 21145.1105\n",
      "Ep. 3010 done, reward: -7.0, running_reward: -10.1422, time (sec): 21166.6351\n",
      "Ep. 3012 done, reward: -7.0, running_reward: -10.0896, time (sec): 21189.2098\n",
      "Ep. 3014 done, reward: -8.0, running_reward: -10.1074, time (sec): 21208.9020\n",
      "Ep. 3016 done, reward: -11.0, running_reward: -10.1747, time (sec): 21227.2380\n",
      "Ep. 3018 done, reward: -14.0, running_reward: -10.2607, time (sec): 21245.7243\n",
      "Ep. 3020 done, reward: -5.0, running_reward: -10.2451, time (sec): 21270.3580\n",
      "Ep. 3022 done, reward: 1.0, running_reward: -10.1401, time (sec): 21294.4050\n",
      "Ep. 3024 done, reward: -14.0, running_reward: -10.1773, time (sec): 21312.7292\n",
      "Ep. 3026 done, reward: -11.0, running_reward: -10.1541, time (sec): 21336.7883\n",
      "Ep. 3028 done, reward: -13.0, running_reward: -10.2008, time (sec): 21356.4295\n",
      "Ep. 3030 done, reward: -7.0, running_reward: -10.1371, time (sec): 21380.2298\n",
      "Ep. 3032 done, reward: -10.0, running_reward: -10.1641, time (sec): 21398.6795\n",
      "Ep. 3034 done, reward: -7.0, running_reward: -10.1605, time (sec): 21416.7800\n",
      "Ep. 3036 done, reward: -13.0, running_reward: -10.2269, time (sec): 21435.6247\n",
      "Ep. 3038 done, reward: -9.0, running_reward: -10.1827, time (sec): 21456.8670\n",
      "Ep. 3040 done, reward: -7.0, running_reward: -10.1986, time (sec): 21478.6262\n",
      "Ep. 3042 done, reward: -9.0, running_reward: -10.1549, time (sec): 21501.6740\n",
      "Ep. 3044 done, reward: -2.0, running_reward: -10.0422, time (sec): 21527.8906\n",
      "Ep. 3046 done, reward: -15.0, running_reward: -10.0418, time (sec): 21549.0229\n",
      "Ep. 3048 done, reward: -5.0, running_reward: -9.9910, time (sec): 21571.1609\n",
      "Ep. 3050 done, reward: -8.0, running_reward: -9.9613, time (sec): 21595.2023\n",
      "Ep. 3052 done, reward: -12.0, running_reward: -9.9523, time (sec): 21615.5212\n",
      "Ep. 3054 done, reward: -13.0, running_reward: -9.9734, time (sec): 21635.9397\n",
      "Ep. 3056 done, reward: -15.0, running_reward: -10.0338, time (sec): 21655.6051\n",
      "Ep. 3058 done, reward: -6.0, running_reward: -9.9733, time (sec): 21679.4289\n",
      "Ep. 3060 done, reward: -8.0, running_reward: -9.9539, time (sec): 21701.9184\n",
      "Ep. 3062 done, reward: -9.0, running_reward: -9.9349, time (sec): 21725.2117\n",
      "Ep. 3064 done, reward: -3.0, running_reward: -9.8266, time (sec): 21748.8446\n",
      "Ep. 3066 done, reward: -11.0, running_reward: -9.8004, time (sec): 21773.6837\n",
      "Ep. 3068 done, reward: -9.0, running_reward: -9.8538, time (sec): 21795.5896\n",
      "Ep. 3070 done, reward: -16.0, running_reward: -9.9167, time (sec): 21815.7162\n",
      "Ep. 3072 done, reward: -19.0, running_reward: -10.0480, time (sec): 21832.3585\n",
      "Ep. 3074 done, reward: -17.0, running_reward: -10.1467, time (sec): 21852.5488\n",
      "Ep. 3076 done, reward: -6.0, running_reward: -10.1929, time (sec): 21873.5734\n",
      "Ep. 3078 done, reward: -12.0, running_reward: -10.1893, time (sec): 21895.7046\n",
      "Ep. 3080 done, reward: -11.0, running_reward: -10.1658, time (sec): 21921.1097\n",
      "Ep. 3082 done, reward: -7.0, running_reward: -10.1721, time (sec): 21941.9903\n",
      "Ep. 3084 done, reward: -5.0, running_reward: -10.0296, time (sec): 21965.9400\n",
      "Ep. 3086 done, reward: -9.0, running_reward: -9.9992, time (sec): 21987.7982\n",
      "Ep. 3088 done, reward: -11.0, running_reward: -10.0092, time (sec): 22008.9933\n",
      "Ep. 3090 done, reward: -17.0, running_reward: -10.1483, time (sec): 22026.1880\n",
      "Ep. 3092 done, reward: -5.0, running_reward: -10.0855, time (sec): 22050.7834\n",
      "Ep. 3094 done, reward: -9.0, running_reward: -10.0441, time (sec): 22069.4643\n",
      "Ep. 3096 done, reward: -13.0, running_reward: -10.0336, time (sec): 22093.4407\n",
      "Ep. 3098 done, reward: -11.0, running_reward: -9.9538, time (sec): 22115.6997\n",
      "Ep. 3100 done, reward: 2.0, running_reward: -9.8644, time (sec): 22138.7089\n",
      "Ep. 3102 done, reward: -13.0, running_reward: -9.9466, time (sec): 22155.4492\n",
      "Ep. 3104 done, reward: -11.0, running_reward: -9.9676, time (sec): 22176.1313\n",
      "Ep. 3106 done, reward: -5.0, running_reward: -9.9083, time (sec): 22198.8217\n",
      "Ep. 3108 done, reward: -11.0, running_reward: -9.8410, time (sec): 22222.4809\n",
      "Ep. 3110 done, reward: -12.0, running_reward: -9.9235, time (sec): 22241.0715\n",
      "Ep. 3112 done, reward: -13.0, running_reward: -9.8957, time (sec): 22262.1385\n",
      "Ep. 3114 done, reward: -9.0, running_reward: -9.9570, time (sec): 22279.6656\n",
      "Ep. 3116 done, reward: -18.0, running_reward: -10.0874, time (sec): 22297.4438\n",
      "Ep. 3118 done, reward: -15.0, running_reward: -10.1059, time (sec): 22317.1647\n",
      "Ep. 3120 done, reward: -12.0, running_reward: -10.0842, time (sec): 22336.9580\n",
      "Ep. 3122 done, reward: -12.0, running_reward: -10.0729, time (sec): 22360.0384\n",
      "Ep. 3124 done, reward: -11.0, running_reward: -10.0418, time (sec): 22381.4821\n",
      "Ep. 3126 done, reward: -5.0, running_reward: -9.9613, time (sec): 22407.7554\n",
      "Ep. 3128 done, reward: -8.0, running_reward: -9.9619, time (sec): 22426.7729\n",
      "Ep. 3130 done, reward: -11.0, running_reward: -9.9528, time (sec): 22453.9226\n",
      "Ep. 3132 done, reward: 2.0, running_reward: -9.8139, time (sec): 22475.3167\n",
      "Ep. 3134 done, reward: -14.0, running_reward: -9.8775, time (sec): 22494.2003\n",
      "Ep. 3136 done, reward: -16.0, running_reward: -9.9300, time (sec): 22513.4450\n",
      "Ep. 3138 done, reward: -7.0, running_reward: -9.8420, time (sec): 22538.4187\n",
      "Ep. 3140 done, reward: -15.0, running_reward: -9.8654, time (sec): 22561.1955\n",
      "Ep. 3142 done, reward: -11.0, running_reward: -9.8880, time (sec): 22579.2807\n",
      "Ep. 3144 done, reward: -17.0, running_reward: -9.9305, time (sec): 22599.4204\n",
      "Ep. 3146 done, reward: -6.0, running_reward: -9.8226, time (sec): 22621.3491\n",
      "Ep. 3148 done, reward: -8.0, running_reward: -9.7764, time (sec): 22645.0882\n",
      "Ep. 3150 done, reward: -7.0, running_reward: -9.7014, time (sec): 22672.8029\n",
      "Ep. 3152 done, reward: -12.0, running_reward: -9.7273, time (sec): 22694.0613\n",
      "Ep. 3154 done, reward: -12.0, running_reward: -9.6637, time (sec): 22717.8459\n",
      "Ep. 3156 done, reward: -17.0, running_reward: -9.7503, time (sec): 22737.3460\n",
      "Ep. 3158 done, reward: -12.0, running_reward: -9.7455, time (sec): 22760.8877\n",
      "Ep. 3160 done, reward: -13.0, running_reward: -9.7509, time (sec): 22782.7165\n",
      "Ep. 3162 done, reward: 4.0, running_reward: -9.6356, time (sec): 22806.4569\n",
      "Ep. 3164 done, reward: -14.0, running_reward: -9.7027, time (sec): 22825.2892\n",
      "Ep. 3166 done, reward: -11.0, running_reward: -9.7681, time (sec): 22846.1389\n",
      "Ep. 3168 done, reward: -4.0, running_reward: -9.7622, time (sec): 22867.3887\n",
      "Ep. 3170 done, reward: -13.0, running_reward: -9.7574, time (sec): 22888.5758\n",
      "Ep. 3172 done, reward: -5.0, running_reward: -9.7419, time (sec): 22911.4438\n",
      "Ep. 3174 done, reward: -7.0, running_reward: -9.7071, time (sec): 22933.3645\n",
      "Ep. 3176 done, reward: -5.0, running_reward: -9.6630, time (sec): 22954.0481\n",
      "Ep. 3178 done, reward: -10.0, running_reward: -9.6301, time (sec): 22974.9570\n",
      "Ep. 3180 done, reward: -10.0, running_reward: -9.6968, time (sec): 22994.0339\n",
      "Ep. 3182 done, reward: -7.0, running_reward: -9.6828, time (sec): 23014.3679\n",
      "Ep. 3184 done, reward: -5.0, running_reward: -9.6391, time (sec): 23034.9268\n",
      "Ep. 3186 done, reward: -12.0, running_reward: -9.6762, time (sec): 23055.9846\n",
      "Ep. 3188 done, reward: -7.0, running_reward: -9.6229, time (sec): 23076.3971\n",
      "Ep. 3190 done, reward: -12.0, running_reward: -9.6801, time (sec): 23097.3510\n",
      "Ep. 3192 done, reward: -5.0, running_reward: -9.6365, time (sec): 23120.8854\n",
      "Ep. 3194 done, reward: -8.0, running_reward: -9.6237, time (sec): 23144.4977\n",
      "Ep. 3196 done, reward: -1.0, running_reward: -9.5808, time (sec): 23170.2358\n",
      "Ep. 3198 done, reward: -10.0, running_reward: -9.5891, time (sec): 23189.4655\n",
      "Ep. 3200 done, reward: -9.0, running_reward: -9.5576, time (sec): 23216.2532\n",
      "Ep. 3202 done, reward: -13.0, running_reward: -9.5172, time (sec): 23237.3903\n",
      "Ep. 3204 done, reward: -6.0, running_reward: -9.5759, time (sec): 23257.0754\n",
      "Ep. 3206 done, reward: -5.0, running_reward: -9.5641, time (sec): 23280.4287\n",
      "Ep. 3208 done, reward: -12.0, running_reward: -9.5828, time (sec): 23302.3444\n",
      "Ep. 3210 done, reward: -8.0, running_reward: -9.5711, time (sec): 23321.0730\n",
      "Ep. 3212 done, reward: -16.0, running_reward: -9.5803, time (sec): 23341.3980\n",
      "Ep. 3214 done, reward: -10.0, running_reward: -9.6282, time (sec): 23359.4089\n",
      "Ep. 3216 done, reward: -2.0, running_reward: -9.4863, time (sec): 23384.9349\n",
      "Ep. 3218 done, reward: -11.0, running_reward: -9.5263, time (sec): 23405.4445\n",
      "Ep. 3220 done, reward: -10.0, running_reward: -9.4665, time (sec): 23429.3087\n",
      "Ep. 3222 done, reward: -5.0, running_reward: -9.3677, time (sec): 23455.6072\n",
      "Ep. 3224 done, reward: 3.0, running_reward: -9.1810, time (sec): 23479.1293\n",
      "Ep. 3226 done, reward: -5.0, running_reward: -9.1968, time (sec): 23500.2161\n",
      "Ep. 3228 done, reward: -5.0, running_reward: -9.0935, time (sec): 23525.1699\n",
      "Ep. 3230 done, reward: -7.0, running_reward: -8.9924, time (sec): 23546.7147\n",
      "Ep. 3232 done, reward: -5.0, running_reward: -8.8139, time (sec): 23569.7280\n",
      "Ep. 3234 done, reward: -7.0, running_reward: -8.8174, time (sec): 23593.3779\n",
      "Ep. 3236 done, reward: -4.0, running_reward: -8.7513, time (sec): 23614.3863\n",
      "Ep. 3238 done, reward: -7.0, running_reward: -8.6669, time (sec): 23639.2779\n",
      "Ep. 3240 done, reward: -6.0, running_reward: -8.6634, time (sec): 23660.8768\n",
      "Ep. 3242 done, reward: -7.0, running_reward: -8.6303, time (sec): 23684.8616\n",
      "Ep. 3244 done, reward: -13.0, running_reward: -8.6281, time (sec): 23709.8704\n",
      "Ep. 3246 done, reward: -12.0, running_reward: -8.7051, time (sec): 23733.5591\n",
      "Ep. 3248 done, reward: -5.0, running_reward: -8.6116, time (sec): 23761.4350\n",
      "Ep. 3250 done, reward: -15.0, running_reward: -8.6397, time (sec): 23782.2492\n",
      "Ep. 3252 done, reward: -11.0, running_reward: -8.5382, time (sec): 23802.7404\n",
      "Ep. 3254 done, reward: -9.0, running_reward: -8.5870, time (sec): 23823.5438\n",
      "Ep. 3256 done, reward: -9.0, running_reward: -8.6150, time (sec): 23848.9930\n",
      "Ep. 3258 done, reward: -15.0, running_reward: -8.6926, time (sec): 23869.2311\n",
      "Ep. 3260 done, reward: -5.0, running_reward: -8.6983, time (sec): 23895.5060\n",
      "Ep. 3262 done, reward: -5.0, running_reward: -8.6148, time (sec): 23920.8066\n",
      "Ep. 3264 done, reward: -5.0, running_reward: -8.6022, time (sec): 23944.6477\n",
      "Ep. 3266 done, reward: -8.0, running_reward: -8.5705, time (sec): 23968.5603\n",
      "Ep. 3268 done, reward: -10.0, running_reward: -8.5791, time (sec): 23994.2417\n",
      "Ep. 3270 done, reward: -5.0, running_reward: -8.5376, time (sec): 24018.6813\n",
      "Ep. 3272 done, reward: -3.0, running_reward: -8.5264, time (sec): 24042.7964\n",
      "Ep. 3274 done, reward: -12.0, running_reward: -8.5163, time (sec): 24065.7808\n",
      "Ep. 3276 done, reward: -10.0, running_reward: -8.4567, time (sec): 24088.3437\n",
      "Ep. 3278 done, reward: -9.0, running_reward: -8.4081, time (sec): 24110.6803\n",
      "Ep. 3280 done, reward: -15.0, running_reward: -8.5294, time (sec): 24129.6112\n",
      "Ep. 3282 done, reward: -15.0, running_reward: -8.5988, time (sec): 24150.5121\n",
      "Ep. 3284 done, reward: -9.0, running_reward: -8.5672, time (sec): 24171.1600\n",
      "Ep. 3286 done, reward: -18.0, running_reward: -8.6856, time (sec): 24190.5175\n",
      "Ep. 3288 done, reward: -13.0, running_reward: -8.7021, time (sec): 24211.3567\n",
      "Ep. 3290 done, reward: -9.0, running_reward: -8.6091, time (sec): 24235.1174\n",
      "Ep. 3292 done, reward: -13.0, running_reward: -8.6172, time (sec): 24257.7915\n",
      "Ep. 3294 done, reward: -13.0, running_reward: -8.6550, time (sec): 24278.3910\n",
      "Ep. 3296 done, reward: -6.0, running_reward: -8.6516, time (sec): 24300.4332\n",
      "Ep. 3298 done, reward: 6.0, running_reward: -8.5482, time (sec): 24321.4911\n",
      "Ep. 3300 done, reward: -9.0, running_reward: -8.5275, time (sec): 24344.1236\n",
      "Ep. 3302 done, reward: -11.0, running_reward: -8.5767, time (sec): 24368.3720\n",
      "Ep. 3304 done, reward: -12.0, running_reward: -8.5854, time (sec): 24390.4780\n",
      "Ep. 3306 done, reward: -11.0, running_reward: -8.5938, time (sec): 24412.6385\n",
      "Ep. 3308 done, reward: -13.0, running_reward: -8.7112, time (sec): 24432.5302\n",
      "Ep. 3310 done, reward: -7.0, running_reward: -8.7168, time (sec): 24455.3188\n",
      "Ep. 3312 done, reward: -15.0, running_reward: -8.7923, time (sec): 24477.5556\n",
      "Ep. 3314 done, reward: -2.0, running_reward: -8.7264, time (sec): 24501.1659\n",
      "Ep. 3316 done, reward: -10.0, running_reward: -8.7617, time (sec): 24523.8890\n",
      "Ep. 3318 done, reward: -9.0, running_reward: -8.6872, time (sec): 24548.0025\n",
      "Ep. 3320 done, reward: -9.0, running_reward: -8.6835, time (sec): 24570.6695\n",
      "Ep. 3322 done, reward: -12.0, running_reward: -8.7198, time (sec): 24593.8344\n",
      "Ep. 3324 done, reward: -15.0, running_reward: -8.7953, time (sec): 24615.6780\n",
      "Ep. 3326 done, reward: -6.0, running_reward: -8.7595, time (sec): 24636.9956\n",
      "Ep. 3328 done, reward: -8.0, running_reward: -8.7246, time (sec): 24662.1294\n",
      "Ep. 3330 done, reward: -12.0, running_reward: -8.7700, time (sec): 24682.7567\n",
      "Ep. 3332 done, reward: -5.0, running_reward: -8.7741, time (sec): 24707.5915\n",
      "Ep. 3334 done, reward: -7.0, running_reward: -8.8378, time (sec): 24725.6043\n",
      "Ep. 3336 done, reward: -9.0, running_reward: -8.9401, time (sec): 24746.4122\n",
      "Ep. 3338 done, reward: -6.0, running_reward: -8.9607, time (sec): 24766.8246\n",
      "Ep. 3340 done, reward: -12.0, running_reward: -8.8430, time (sec): 24787.7089\n",
      "Ep. 3342 done, reward: -11.0, running_reward: -8.9355, time (sec): 24810.2364\n",
      "Ep. 3344 done, reward: -10.0, running_reward: -8.9467, time (sec): 24832.2362\n",
      "Ep. 3346 done, reward: -4.0, running_reward: -8.8978, time (sec): 24857.1381\n",
      "Ep. 3348 done, reward: -6.0, running_reward: -8.7510, time (sec): 24881.0627\n",
      "Ep. 3350 done, reward: -13.0, running_reward: -8.8554, time (sec): 24900.1576\n",
      "Ep. 3352 done, reward: -8.0, running_reward: -8.9077, time (sec): 24919.8660\n",
      "Ep. 3354 done, reward: -18.0, running_reward: -8.9599, time (sec): 24944.8931\n",
      "Ep. 3356 done, reward: -15.0, running_reward: -9.0702, time (sec): 24966.2085\n",
      "Ep. 3358 done, reward: -2.0, running_reward: -9.0186, time (sec): 24987.8931\n",
      "Ep. 3360 done, reward: -10.0, running_reward: -9.0381, time (sec): 25008.4960\n",
      "Ep. 3362 done, reward: -8.0, running_reward: -9.0274, time (sec): 25032.4339\n",
      "Ep. 3364 done, reward: -10.0, running_reward: -9.1160, time (sec): 25052.1614\n",
      "Ep. 3366 done, reward: -2.0, running_reward: -9.0041, time (sec): 25078.3844\n",
      "Ep. 3368 done, reward: -6.0, running_reward: -8.9542, time (sec): 25105.0133\n",
      "Ep. 3370 done, reward: -9.0, running_reward: -8.9650, time (sec): 25129.0213\n",
      "Ep. 3372 done, reward: -5.0, running_reward: -8.9059, time (sec): 25154.0787\n",
      "Ep. 3374 done, reward: -11.0, running_reward: -8.9476, time (sec): 25174.6685\n",
      "Ep. 3376 done, reward: -9.0, running_reward: -8.8893, time (sec): 25197.5173\n",
      "Ep. 3378 done, reward: -10.0, running_reward: -8.9213, time (sec): 25217.9024\n",
      "Ep. 3380 done, reward: 8.0, running_reward: -8.7330, time (sec): 25238.1455\n",
      "Ep. 3382 done, reward: -11.0, running_reward: -8.7187, time (sec): 25258.9680\n",
      "Ep. 3384 done, reward: -14.0, running_reward: -8.7941, time (sec): 25278.0942\n",
      "Ep. 3386 done, reward: -13.0, running_reward: -8.8184, time (sec): 25301.0488\n",
      "Ep. 3388 done, reward: -1.0, running_reward: -8.7420, time (sec): 25328.8870\n",
      "Ep. 3390 done, reward: -7.0, running_reward: -8.7173, time (sec): 25352.8354\n",
      "Ep. 3392 done, reward: -6.0, running_reward: -8.7523, time (sec): 25376.7352\n",
      "Ep. 3394 done, reward: -10.0, running_reward: -8.5989, time (sec): 25398.1034\n",
      "Ep. 3396 done, reward: -9.0, running_reward: -8.5871, time (sec): 25419.2336\n",
      "Ep. 3398 done, reward: -14.0, running_reward: -8.5463, time (sec): 25445.2603\n",
      "Ep. 3400 done, reward: -7.0, running_reward: -8.5651, time (sec): 25470.2453\n",
      "Ep. 3402 done, reward: -11.0, running_reward: -8.5343, time (sec): 25495.8898\n",
      "Ep. 3404 done, reward: -9.0, running_reward: -8.5832, time (sec): 25516.9991\n",
      "Ep. 3406 done, reward: -10.0, running_reward: -8.5718, time (sec): 25539.7436\n",
      "Ep. 3408 done, reward: -7.0, running_reward: -8.5405, time (sec): 25565.4548\n",
      "Ep. 3410 done, reward: -9.0, running_reward: -8.5793, time (sec): 25589.6624\n",
      "Ep. 3412 done, reward: -12.0, running_reward: -8.5385, time (sec): 25613.1380\n",
      "Ep. 3414 done, reward: -8.0, running_reward: -8.5575, time (sec): 25637.3138\n",
      "Ep. 3416 done, reward: -7.0, running_reward: -8.5958, time (sec): 25658.2089\n",
      "Ep. 3418 done, reward: -8.0, running_reward: -8.5641, time (sec): 25679.4614\n",
      "Ep. 3420 done, reward: -9.0, running_reward: -8.5926, time (sec): 25702.9700\n",
      "Ep. 3422 done, reward: -11.0, running_reward: -8.5613, time (sec): 25726.7626\n",
      "Ep. 3424 done, reward: -8.0, running_reward: -8.5007, time (sec): 25749.0265\n",
      "Ep. 3426 done, reward: -14.0, running_reward: -8.4814, time (sec): 25772.0197\n",
      "Ep. 3428 done, reward: -12.0, running_reward: -8.5712, time (sec): 25793.4791\n",
      "Ep. 3430 done, reward: -13.0, running_reward: -8.6791, time (sec): 25814.7799\n",
      "Ep. 3432 done, reward: -8.0, running_reward: -8.6557, time (sec): 25836.8871\n",
      "Ep. 3434 done, reward: -9.0, running_reward: -8.6527, time (sec): 25862.9236\n",
      "Ep. 3436 done, reward: -10.0, running_reward: -8.7587, time (sec): 25883.0075\n",
      "Ep. 3438 done, reward: -13.0, running_reward: -8.7837, time (sec): 25902.2795\n",
      "Ep. 3440 done, reward: -9.0, running_reward: -8.7484, time (sec): 25926.9036\n",
      "Ep. 3442 done, reward: -3.0, running_reward: -8.6538, time (sec): 25953.3190\n",
      "Ep. 3444 done, reward: -2.0, running_reward: -8.4917, time (sec): 25977.3068\n",
      "Ep. 3446 done, reward: -11.0, running_reward: -8.4624, time (sec): 25999.6329\n",
      "Ep. 3448 done, reward: -15.0, running_reward: -8.5628, time (sec): 26020.7412\n",
      "Ep. 3450 done, reward: -8.0, running_reward: -8.5813, time (sec): 26041.4251\n",
      "Ep. 3452 done, reward: -8.0, running_reward: -8.5202, time (sec): 26069.9434\n",
      "Ep. 3454 done, reward: -15.0, running_reward: -8.5700, time (sec): 26095.2878\n",
      "Ep. 3456 done, reward: -9.0, running_reward: -8.5983, time (sec): 26115.7445\n",
      "Ep. 3458 done, reward: -17.0, running_reward: -8.7259, time (sec): 26134.6469\n",
      "Ep. 3460 done, reward: -13.0, running_reward: -8.7813, time (sec): 26157.3948\n",
      "Ep. 3462 done, reward: -2.0, running_reward: -8.6463, time (sec): 26185.6121\n",
      "Ep. 3464 done, reward: -3.0, running_reward: -8.5736, time (sec): 26214.6163\n",
      "Ep. 3466 done, reward: -4.0, running_reward: -8.5519, time (sec): 26239.9416\n",
      "Ep. 3468 done, reward: -15.0, running_reward: -8.6010, time (sec): 26260.8116\n",
      "Ep. 3470 done, reward: -11.0, running_reward: -8.5893, time (sec): 26283.5963\n",
      "Ep. 3472 done, reward: -8.0, running_reward: -8.6073, time (sec): 26305.7988\n",
      "Ep. 3474 done, reward: -11.0, running_reward: -8.6252, time (sec): 26327.3734\n",
      "Ep. 3476 done, reward: -2.0, running_reward: -8.5627, time (sec): 26352.1592\n",
      "Ep. 3478 done, reward: -14.0, running_reward: -8.5719, time (sec): 26379.6031\n",
      "Ep. 3480 done, reward: -14.0, running_reward: -8.6799, time (sec): 26400.1242\n",
      "Ep. 3482 done, reward: -7.0, running_reward: -8.6960, time (sec): 26423.1603\n",
      "Ep. 3484 done, reward: -5.0, running_reward: -8.6521, time (sec): 26447.4051\n",
      "Ep. 3486 done, reward: -4.0, running_reward: -8.6288, time (sec): 26470.6104\n",
      "Ep. 3488 done, reward: -1.0, running_reward: -8.5760, time (sec): 26492.2029\n",
      "Ep. 3490 done, reward: -14.0, running_reward: -8.6147, time (sec): 26511.4419\n",
      "Ep. 3492 done, reward: -3.0, running_reward: -8.5326, time (sec): 26540.7289\n",
      "Ep. 3494 done, reward: -10.0, running_reward: -8.5222, time (sec): 26562.9256\n",
      "Ep. 3496 done, reward: -10.0, running_reward: -8.5615, time (sec): 26584.9986\n",
      "Ep. 3498 done, reward: -8.0, running_reward: -8.5009, time (sec): 26607.5994\n",
      "Ep. 3500 done, reward: 5.0, running_reward: -8.4104, time (sec): 26627.5341\n",
      "Ep. 3502 done, reward: -7.0, running_reward: -8.4318, time (sec): 26650.0916\n",
      "Ep. 3504 done, reward: -1.0, running_reward: -8.4324, time (sec): 26675.5132\n",
      "Ep. 3506 done, reward: -11.0, running_reward: -8.5231, time (sec): 26693.7138\n",
      "Ep. 3508 done, reward: 6.0, running_reward: -8.3727, time (sec): 26718.5373\n",
      "Ep. 3510 done, reward: -6.0, running_reward: -8.2958, time (sec): 26741.3515\n",
      "Ep. 3512 done, reward: -11.0, running_reward: -8.3496, time (sec): 26763.4742\n",
      "Ep. 3514 done, reward: -13.0, running_reward: -8.4125, time (sec): 26785.6416\n",
      "Ep. 3516 done, reward: -10.0, running_reward: -8.4738, time (sec): 26808.3773\n",
      "Ep. 3518 done, reward: -12.0, running_reward: -8.5340, time (sec): 26830.7470\n",
      "Ep. 3520 done, reward: -8.0, running_reward: -8.4640, time (sec): 26860.4445\n",
      "Ep. 3522 done, reward: -11.0, running_reward: -8.4551, time (sec): 26884.1715\n",
      "Ep. 3524 done, reward: -3.0, running_reward: -8.4356, time (sec): 26906.8014\n",
      "Ep. 3526 done, reward: -17.0, running_reward: -8.4773, time (sec): 26929.9293\n",
      "Ep. 3528 done, reward: -4.0, running_reward: -8.4674, time (sec): 26951.0850\n",
      "Ep. 3530 done, reward: -17.0, running_reward: -8.5580, time (sec): 26971.0120\n",
      "Ep. 3532 done, reward: -9.0, running_reward: -8.5767, time (sec): 26993.4253\n",
      "Ep. 3534 done, reward: -11.0, running_reward: -8.4567, time (sec): 27017.0674\n",
      "Ep. 3536 done, reward: -5.0, running_reward: -8.2988, time (sec): 27038.2583\n",
      "Ep. 3538 done, reward: -6.0, running_reward: -8.3223, time (sec): 27061.5139\n",
      "Ep. 3540 done, reward: -10.0, running_reward: -8.3260, time (sec): 27083.8969\n",
      "Ep. 3542 done, reward: -11.0, running_reward: -8.3495, time (sec): 27104.4376\n",
      "Ep. 3544 done, reward: -1.0, running_reward: -8.1637, time (sec): 27131.3906\n",
      "Ep. 3546 done, reward: 8.0, running_reward: -8.0301, time (sec): 27152.3244\n",
      "Ep. 3548 done, reward: -9.0, running_reward: -7.9207, time (sec): 27176.4739\n",
      "Ep. 3550 done, reward: -10.0, running_reward: -7.9126, time (sec): 27199.8651\n",
      "Ep. 3552 done, reward: -3.0, running_reward: -7.7158, time (sec): 27225.2692\n",
      "Ep. 3554 done, reward: -13.0, running_reward: -7.7913, time (sec): 27245.3943\n",
      "Ep. 3556 done, reward: 1.0, running_reward: -7.7351, time (sec): 27272.1344\n",
      "Ep. 3558 done, reward: -9.0, running_reward: -7.7702, time (sec): 27298.0913\n",
      "Ep. 3560 done, reward: -8.0, running_reward: -7.7946, time (sec): 27320.6267\n",
      "Ep. 3562 done, reward: 3.0, running_reward: -7.5897, time (sec): 27344.8709\n",
      "Ep. 3564 done, reward: -10.0, running_reward: -7.5881, time (sec): 27368.8784\n",
      "Ep. 3566 done, reward: -9.0, running_reward: -7.5370, time (sec): 27394.7632\n",
      "Ep. 3568 done, reward: -10.0, running_reward: -7.4969, time (sec): 27417.1521\n",
      "Ep. 3570 done, reward: -6.0, running_reward: -7.4969, time (sec): 27440.9243\n",
      "Ep. 3572 done, reward: 2.0, running_reward: -7.3871, time (sec): 27465.3784\n",
      "Ep. 3574 done, reward: -7.0, running_reward: -7.3992, time (sec): 27489.0634\n",
      "Ep. 3576 done, reward: -17.0, running_reward: -7.3724, time (sec): 27510.1246\n",
      "Ep. 3578 done, reward: -17.0, running_reward: -7.4254, time (sec): 27533.8896\n",
      "Ep. 3580 done, reward: -9.0, running_reward: -7.3577, time (sec): 27558.6200\n",
      "Ep. 3582 done, reward: -7.0, running_reward: -7.2615, time (sec): 27585.2383\n",
      "Ep. 3584 done, reward: -8.0, running_reward: -7.3356, time (sec): 27606.0398\n",
      "Ep. 3586 done, reward: -4.0, running_reward: -7.3385, time (sec): 27626.2594\n",
      "Ep. 3588 done, reward: -15.0, running_reward: -7.4415, time (sec): 27650.5739\n",
      "Ep. 3590 done, reward: -14.0, running_reward: -7.5324, time (sec): 27670.5952\n",
      "Ep. 3592 done, reward: -11.0, running_reward: -7.6014, time (sec): 27691.3816\n",
      "Ep. 3594 done, reward: 5.0, running_reward: -7.5091, time (sec): 27713.9172\n",
      "Ep. 3596 done, reward: -12.0, running_reward: -7.5291, time (sec): 27735.7328\n",
      "Ep. 3598 done, reward: -4.0, running_reward: -7.4985, time (sec): 27761.8164\n",
      "Ep. 3600 done, reward: -14.0, running_reward: -7.6774, time (sec): 27782.2393\n",
      "Ep. 3602 done, reward: -9.0, running_reward: -7.6839, time (sec): 27804.0477\n",
      "Ep. 3604 done, reward: -1.0, running_reward: -7.5806, time (sec): 27831.8141\n",
      "Ep. 3606 done, reward: -7.0, running_reward: -7.5987, time (sec): 27854.3900\n",
      "Ep. 3608 done, reward: -12.0, running_reward: -7.6269, time (sec): 27877.7073\n",
      "Ep. 3610 done, reward: -5.0, running_reward: -7.5944, time (sec): 27900.6277\n",
      "Ep. 3612 done, reward: -8.0, running_reward: -7.6322, time (sec): 27921.2175\n",
      "Ep. 3614 done, reward: -7.0, running_reward: -7.6196, time (sec): 27944.1396\n",
      "Ep. 3616 done, reward: -3.0, running_reward: -7.5871, time (sec): 27967.2381\n",
      "Ep. 3618 done, reward: -7.0, running_reward: -7.5853, time (sec): 27992.1849\n",
      "Ep. 3620 done, reward: -13.0, running_reward: -7.6337, time (sec): 28011.5671\n",
      "Ep. 3622 done, reward: -10.0, running_reward: -7.6214, time (sec): 28033.6240\n",
      "Ep. 3624 done, reward: -8.0, running_reward: -7.6091, time (sec): 28056.9976\n",
      "Ep. 3626 done, reward: -8.0, running_reward: -7.6070, time (sec): 28082.2280\n",
      "Ep. 3628 done, reward: -1.0, running_reward: -7.5646, time (sec): 28105.6079\n",
      "Ep. 3630 done, reward: 7.0, running_reward: -7.3639, time (sec): 28129.2751\n",
      "Ep. 3632 done, reward: -13.0, running_reward: -7.3077, time (sec): 28149.3828\n",
      "Ep. 3634 done, reward: -11.0, running_reward: -7.3614, time (sec): 28173.0679\n",
      "Ep. 3636 done, reward: -5.0, running_reward: -7.3342, time (sec): 28198.4883\n",
      "Ep. 3638 done, reward: 3.0, running_reward: -7.0791, time (sec): 28224.3164\n",
      "Ep. 3640 done, reward: -16.0, running_reward: -7.1378, time (sec): 28246.7948\n",
      "Ep. 3642 done, reward: -10.0, running_reward: -7.2442, time (sec): 28267.7123\n",
      "Ep. 3644 done, reward: -3.0, running_reward: -7.1994, time (sec): 28294.7243\n",
      "Ep. 3646 done, reward: -12.0, running_reward: -7.2454, time (sec): 28320.1255\n",
      "Ep. 3648 done, reward: -6.0, running_reward: -7.1909, time (sec): 28345.2194\n",
      "Ep. 3650 done, reward: -5.0, running_reward: -7.1275, time (sec): 28367.9456\n",
      "Ep. 3652 done, reward: -9.0, running_reward: -7.1252, time (sec): 28392.6596\n",
      "Ep. 3654 done, reward: -3.0, running_reward: -7.0629, time (sec): 28418.7302\n",
      "Ep. 3656 done, reward: -6.0, running_reward: -7.0417, time (sec): 28446.1491\n",
      "Ep. 3658 done, reward: -5.0, running_reward: -7.0407, time (sec): 28469.9867\n",
      "Ep. 3660 done, reward: -4.0, running_reward: -7.0594, time (sec): 28492.7342\n",
      "Ep. 3662 done, reward: -3.0, running_reward: -6.8796, time (sec): 28518.1832\n",
      "Ep. 3664 done, reward: -7.0, running_reward: -6.8820, time (sec): 28544.0680\n",
      "Ep. 3666 done, reward: -17.0, running_reward: -6.8854, time (sec): 28566.5225\n",
      "Ep. 3668 done, reward: -13.0, running_reward: -6.9872, time (sec): 28587.9887\n",
      "Ep. 3670 done, reward: -9.0, running_reward: -6.9976, time (sec): 28614.4484\n",
      "Ep. 3672 done, reward: -5.0, running_reward: -6.9974, time (sec): 28640.1524\n",
      "Ep. 3674 done, reward: -11.0, running_reward: -7.0969, time (sec): 28658.5389\n",
      "Ep. 3676 done, reward: -11.0, running_reward: -7.0261, time (sec): 28683.2907\n",
      "Ep. 3678 done, reward: -10.0, running_reward: -6.9962, time (sec): 28705.7250\n",
      "Ep. 3680 done, reward: 5.0, running_reward: -6.7673, time (sec): 28733.6584\n",
      "Ep. 3682 done, reward: -7.0, running_reward: -6.8215, time (sec): 28756.0504\n",
      "Ep. 3684 done, reward: -7.0, running_reward: -6.8844, time (sec): 28779.4485\n",
      "Ep. 3686 done, reward: -10.0, running_reward: -6.9167, time (sec): 28803.5332\n",
      "Ep. 3688 done, reward: -3.0, running_reward: -6.8784, time (sec): 28831.7012\n",
      "Ep. 3690 done, reward: -13.0, running_reward: -6.9408, time (sec): 28854.1996\n",
      "Ep. 3692 done, reward: -10.0, running_reward: -6.9324, time (sec): 28877.0043\n",
      "Ep. 3694 done, reward: 1.0, running_reward: -6.7943, time (sec): 28901.4182\n",
      "Ep. 3696 done, reward: 1.0, running_reward: -6.7580, time (sec): 28925.8123\n",
      "Ep. 3698 done, reward: -5.0, running_reward: -6.7527, time (sec): 28950.4371\n",
      "Ep. 3700 done, reward: -2.0, running_reward: -6.5888, time (sec): 28974.8475\n",
      "Ep. 3702 done, reward: -7.0, running_reward: -6.5574, time (sec): 29000.1190\n",
      "Ep. 3704 done, reward: -5.0, running_reward: -6.5858, time (sec): 29021.0038\n",
      "Ep. 3706 done, reward: -9.0, running_reward: -6.6339, time (sec): 29042.7680\n",
      "Ep. 3708 done, reward: 2.0, running_reward: -6.4423, time (sec): 29068.1128\n",
      "Ep. 3710 done, reward: -6.0, running_reward: -6.4632, time (sec): 29091.9584\n",
      "Ep. 3712 done, reward: -10.0, running_reward: -6.5236, time (sec): 29116.5798\n",
      "Ep. 3714 done, reward: -5.0, running_reward: -6.5725, time (sec): 29135.9605\n",
      "Ep. 3716 done, reward: -3.0, running_reward: -6.5212, time (sec): 29161.8120\n",
      "Ep. 3718 done, reward: -8.0, running_reward: -6.5210, time (sec): 29185.8849\n",
      "Ep. 3720 done, reward: -15.0, running_reward: -6.6501, time (sec): 29205.0883\n",
      "Ep. 3722 done, reward: -11.0, running_reward: -6.6476, time (sec): 29227.4772\n",
      "Ep. 3724 done, reward: -11.0, running_reward: -6.6946, time (sec): 29247.0632\n",
      "Ep. 3726 done, reward: -7.0, running_reward: -6.5620, time (sec): 29272.0822\n",
      "Ep. 3728 done, reward: -2.0, running_reward: -6.4713, time (sec): 29299.5935\n",
      "Ep. 3730 done, reward: -14.0, running_reward: -6.5914, time (sec): 29321.4827\n",
      "Ep. 3732 done, reward: -3.0, running_reward: -6.4407, time (sec): 29347.1168\n",
      "Ep. 3734 done, reward: -3.0, running_reward: -6.4316, time (sec): 29372.8829\n",
      "Ep. 3736 done, reward: 11.0, running_reward: -6.3026, time (sec): 29397.6526\n",
      "Ep. 3738 done, reward: -7.0, running_reward: -6.3560, time (sec): 29419.2172\n",
      "Ep. 3740 done, reward: -9.0, running_reward: -6.3987, time (sec): 29441.7826\n",
      "Ep. 3742 done, reward: -7.0, running_reward: -6.3513, time (sec): 29470.8997\n",
      "Ep. 3744 done, reward: -8.0, running_reward: -6.4138, time (sec): 29494.0846\n",
      "Ep. 3746 done, reward: -12.0, running_reward: -6.5052, time (sec): 29517.2061\n",
      "Ep. 3748 done, reward: -10.0, running_reward: -6.4955, time (sec): 29542.2294\n",
      "Ep. 3750 done, reward: -9.0, running_reward: -6.3474, time (sec): 29563.6880\n",
      "Ep. 3752 done, reward: -15.0, running_reward: -6.4206, time (sec): 29587.6361\n",
      "Ep. 3754 done, reward: -11.0, running_reward: -6.5513, time (sec): 29611.6131\n",
      "Ep. 3756 done, reward: -5.0, running_reward: -6.5303, time (sec): 29636.7374\n",
      "Ep. 3758 done, reward: -14.0, running_reward: -6.6790, time (sec): 29657.0234\n",
      "Ep. 3760 done, reward: -13.0, running_reward: -6.7751, time (sec): 29677.2267\n",
      "Ep. 3762 done, reward: 5.0, running_reward: -6.5506, time (sec): 29702.8320\n",
      "Ep. 3764 done, reward: -2.0, running_reward: -6.5690, time (sec): 29724.9269\n",
      "Ep. 3766 done, reward: -6.0, running_reward: -6.6072, time (sec): 29751.8837\n",
      "Ep. 3768 done, reward: -4.0, running_reward: -6.5652, time (sec): 29779.1504\n",
      "Ep. 3770 done, reward: -2.0, running_reward: -6.5139, time (sec): 29803.7968\n",
      "Ep. 3772 done, reward: 5.0, running_reward: -6.4333, time (sec): 29829.5874\n",
      "Ep. 3774 done, reward: 2.0, running_reward: -6.2952, time (sec): 29856.2560\n",
      "Ep. 3776 done, reward: 1.0, running_reward: -6.1401, time (sec): 29883.1540\n",
      "Ep. 3778 done, reward: 1.0, running_reward: -6.0772, time (sec): 29911.7774\n",
      "Ep. 3780 done, reward: -10.0, running_reward: -6.1058, time (sec): 29932.7682\n",
      "Ep. 3782 done, reward: -12.0, running_reward: -6.1835, time (sec): 29956.4729\n",
      "Ep. 3784 done, reward: -1.0, running_reward: -6.1397, time (sec): 29980.8613\n",
      "Ep. 3786 done, reward: -1.0, running_reward: -6.0770, time (sec): 30005.3985\n",
      "Ep. 3788 done, reward: -9.0, running_reward: -5.9966, time (sec): 30028.8003\n",
      "Ep. 3790 done, reward: -1.0, running_reward: -5.9368, time (sec): 30054.3560\n",
      "Ep. 3792 done, reward: -11.0, running_reward: -5.9979, time (sec): 30077.4846\n",
      "Ep. 3794 done, reward: -11.0, running_reward: -6.1272, time (sec): 30097.7990\n",
      "Ep. 3796 done, reward: 2.0, running_reward: -5.8961, time (sec): 30120.5685\n",
      "Ep. 3798 done, reward: 13.0, running_reward: -5.7478, time (sec): 30140.2119\n",
      "Ep. 3800 done, reward: -3.0, running_reward: -5.7525, time (sec): 30164.5295\n",
      "Ep. 3802 done, reward: -10.0, running_reward: -5.7579, time (sec): 30190.6051\n",
      "Ep. 3804 done, reward: -11.0, running_reward: -5.8226, time (sec): 30213.6434\n",
      "Ep. 3806 done, reward: -11.0, running_reward: -5.9355, time (sec): 30235.4793\n",
      "Ep. 3808 done, reward: -16.0, running_reward: -6.0665, time (sec): 30254.4680\n",
      "Ep. 3810 done, reward: 7.0, running_reward: -5.9550, time (sec): 30280.1490\n",
      "Ep. 3812 done, reward: 1.0, running_reward: -5.9057, time (sec): 30306.6414\n",
      "Ep. 3814 done, reward: -8.0, running_reward: -5.9572, time (sec): 30329.7208\n",
      "Ep. 3816 done, reward: -3.0, running_reward: -5.9083, time (sec): 30357.2591\n",
      "Ep. 3818 done, reward: 6.0, running_reward: -5.8396, time (sec): 30379.0649\n",
      "Ep. 3820 done, reward: 1.0, running_reward: -5.7035, time (sec): 30404.8682\n",
      "Ep. 3822 done, reward: -2.0, running_reward: -5.6199, time (sec): 30430.8121\n",
      "Ep. 3824 done, reward: -2.0, running_reward: -5.5875, time (sec): 30455.0558\n",
      "Ep. 3826 done, reward: -15.0, running_reward: -5.6758, time (sec): 30479.0380\n",
      "Ep. 3828 done, reward: -5.0, running_reward: -5.7316, time (sec): 30500.9919\n",
      "Ep. 3830 done, reward: -9.0, running_reward: -5.8264, time (sec): 30524.7258\n",
      "Ep. 3832 done, reward: 6.0, running_reward: -5.7593, time (sec): 30547.5897\n",
      "Ep. 3834 done, reward: -3.0, running_reward: -5.7737, time (sec): 30573.4715\n",
      "Ep. 3836 done, reward: -6.0, running_reward: -5.6792, time (sec): 30595.8296\n",
      "Ep. 3838 done, reward: -2.0, running_reward: -5.6060, time (sec): 30620.9983\n",
      "Ep. 3840 done, reward: -3.0, running_reward: -5.5739, time (sec): 30649.7943\n",
      "Ep. 3842 done, reward: -6.0, running_reward: -5.6913, time (sec): 30669.2870\n",
      "Ep. 3844 done, reward: -3.0, running_reward: -5.6378, time (sec): 30693.5809\n",
      "Ep. 3846 done, reward: -15.0, running_reward: -5.7350, time (sec): 30715.8847\n",
      "Ep. 3848 done, reward: 2.0, running_reward: -5.6107, time (sec): 30741.9422\n",
      "Ep. 3850 done, reward: -10.0, running_reward: -5.6585, time (sec): 30766.0537\n",
      "Ep. 3852 done, reward: -1.0, running_reward: -5.6054, time (sec): 30794.1243\n",
      "Ep. 3854 done, reward: -4.0, running_reward: -5.5635, time (sec): 30817.7858\n",
      "Ep. 3856 done, reward: -6.0, running_reward: -5.5722, time (sec): 30843.6728\n",
      "Ep. 3858 done, reward: -7.0, running_reward: -5.5709, time (sec): 30870.3982\n",
      "Ep. 3860 done, reward: -2.0, running_reward: -5.5494, time (sec): 30893.4171\n",
      "Ep. 3862 done, reward: 1.0, running_reward: -5.4883, time (sec): 30917.6517\n",
      "Ep. 3864 done, reward: 5.0, running_reward: -5.3786, time (sec): 30941.3672\n",
      "Ep. 3866 done, reward: 5.0, running_reward: -5.2414, time (sec): 30967.1879\n",
      "Ep. 3868 done, reward: -9.0, running_reward: -5.2766, time (sec): 30990.5047\n",
      "Ep. 3870 done, reward: -11.0, running_reward: -5.3311, time (sec): 31012.9970\n",
      "Ep. 3872 done, reward: -4.0, running_reward: -5.3541, time (sec): 31037.3232\n",
      "Ep. 3874 done, reward: -6.0, running_reward: -5.3570, time (sec): 31059.4656\n",
      "Ep. 3876 done, reward: -17.0, running_reward: -5.4798, time (sec): 31079.9430\n",
      "Ep. 3878 done, reward: -8.0, running_reward: -5.5399, time (sec): 31102.5569\n",
      "Ep. 3880 done, reward: -4.0, running_reward: -5.5687, time (sec): 31128.3075\n",
      "Ep. 3882 done, reward: -4.0, running_reward: -5.5770, time (sec): 31151.7645\n",
      "Ep. 3884 done, reward: -5.0, running_reward: -5.4864, time (sec): 31178.0648\n",
      "Ep. 3886 done, reward: 2.0, running_reward: -5.4067, time (sec): 31202.3891\n",
      "Ep. 3888 done, reward: -4.0, running_reward: -5.3787, time (sec): 31231.1804\n",
      "Ep. 3890 done, reward: -17.0, running_reward: -5.4317, time (sec): 31254.9798\n",
      "Ep. 3892 done, reward: -3.0, running_reward: -5.4725, time (sec): 31278.1603\n",
      "Ep. 3894 done, reward: -1.0, running_reward: -5.4627, time (sec): 31301.9072\n",
      "Ep. 3896 done, reward: -6.0, running_reward: -5.3842, time (sec): 31325.8089\n",
      "Ep. 3898 done, reward: -3.0, running_reward: -5.3665, time (sec): 31350.0240\n",
      "Ep. 3900 done, reward: -8.0, running_reward: -5.4288, time (sec): 31376.2663\n",
      "Ep. 3902 done, reward: -3.0, running_reward: -5.4399, time (sec): 31397.9699\n",
      "Ep. 3904 done, reward: -3.0, running_reward: -5.3319, time (sec): 31422.6008\n",
      "Ep. 3906 done, reward: -4.0, running_reward: -5.3648, time (sec): 31444.5873\n",
      "Ep. 3908 done, reward: -17.0, running_reward: -5.4974, time (sec): 31467.3459\n",
      "Ep. 3910 done, reward: -5.0, running_reward: -5.4479, time (sec): 31498.1603\n",
      "Ep. 3912 done, reward: -1.0, running_reward: -5.3791, time (sec): 31525.5638\n",
      "Ep. 3914 done, reward: -8.0, running_reward: -5.3917, time (sec): 31547.6386\n",
      "Ep. 3916 done, reward: -13.0, running_reward: -5.5629, time (sec): 31565.6860\n",
      "Ep. 3918 done, reward: -11.0, running_reward: -5.5523, time (sec): 31585.9141\n",
      "Ep. 3920 done, reward: 1.0, running_reward: -5.6001, time (sec): 31608.1444\n",
      "Ep. 3922 done, reward: -3.0, running_reward: -5.6375, time (sec): 31629.4718\n",
      "Ep. 3924 done, reward: -3.0, running_reward: -5.6246, time (sec): 31655.2381\n",
      "Ep. 3926 done, reward: -8.0, running_reward: -5.6818, time (sec): 31679.6405\n",
      "Ep. 3928 done, reward: 2.0, running_reward: -5.6081, time (sec): 31703.8243\n",
      "Ep. 3930 done, reward: -5.0, running_reward: -5.5168, time (sec): 31728.1923\n",
      "Ep. 3932 done, reward: -8.0, running_reward: -5.4573, time (sec): 31754.8870\n",
      "Ep. 3934 done, reward: -10.0, running_reward: -5.5378, time (sec): 31779.6070\n",
      "Ep. 3936 done, reward: -8.0, running_reward: -5.6759, time (sec): 31803.1026\n",
      "Ep. 3938 done, reward: -15.0, running_reward: -5.6733, time (sec): 31823.7026\n",
      "Ep. 3940 done, reward: -10.0, running_reward: -5.7396, time (sec): 31845.8586\n",
      "Ep. 3942 done, reward: -15.0, running_reward: -5.9041, time (sec): 31866.5308\n",
      "Ep. 3944 done, reward: -11.0, running_reward: -5.9857, time (sec): 31890.9494\n",
      "Ep. 3946 done, reward: -3.0, running_reward: -6.0352, time (sec): 31915.1284\n",
      "Ep. 3948 done, reward: -3.0, running_reward: -5.9352, time (sec): 31939.4899\n",
      "Ep. 3950 done, reward: 4.0, running_reward: -5.8464, time (sec): 31963.6767\n",
      "Ep. 3952 done, reward: -11.0, running_reward: -5.8203, time (sec): 31986.5584\n",
      "Ep. 3954 done, reward: 2.0, running_reward: -5.7339, time (sec): 32012.7339\n",
      "Ep. 3956 done, reward: -9.0, running_reward: -5.6900, time (sec): 32037.3551\n",
      "Ep. 3958 done, reward: -5.0, running_reward: -5.5773, time (sec): 32060.0198\n",
      "Ep. 3960 done, reward: -8.0, running_reward: -5.6156, time (sec): 32084.2288\n",
      "Ep. 3962 done, reward: -7.0, running_reward: -5.6630, time (sec): 32106.3455\n",
      "Ep. 3964 done, reward: -2.0, running_reward: -5.5505, time (sec): 32133.4399\n",
      "Ep. 3966 done, reward: 1.0, running_reward: -5.4795, time (sec): 32158.5086\n",
      "Ep. 3968 done, reward: 1.0, running_reward: -5.3803, time (sec): 32187.5962\n",
      "Ep. 3970 done, reward: -2.0, running_reward: -5.2734, time (sec): 32213.5450\n",
      "Ep. 3972 done, reward: -3.0, running_reward: -5.1886, time (sec): 32243.4010\n",
      "Ep. 3974 done, reward: 6.0, running_reward: -5.0649, time (sec): 32267.7500\n",
      "Ep. 3976 done, reward: -8.0, running_reward: -5.1827, time (sec): 32288.0103\n",
      "Ep. 3978 done, reward: -5.0, running_reward: -5.2286, time (sec): 32311.6971\n",
      "Ep. 3980 done, reward: -13.0, running_reward: -5.3733, time (sec): 32330.1901\n",
      "Ep. 3982 done, reward: -9.0, running_reward: -5.3762, time (sec): 32355.5592\n",
      "Ep. 3984 done, reward: -15.0, running_reward: -5.5083, time (sec): 32376.2240\n",
      "Ep. 3986 done, reward: -3.0, running_reward: -5.3990, time (sec): 32403.2851\n",
      "Ep. 3988 done, reward: -8.0, running_reward: -5.3122, time (sec): 32427.1272\n",
      "Ep. 3990 done, reward: -15.0, running_reward: -5.3763, time (sec): 32450.6039\n",
      "Ep. 3992 done, reward: 5.0, running_reward: -5.2094, time (sec): 32474.2828\n",
      "Ep. 3994 done, reward: -1.0, running_reward: -5.1355, time (sec): 32499.2909\n",
      "Ep. 3996 done, reward: 3.0, running_reward: -5.0528, time (sec): 32521.5880\n",
      "Ep. 3998 done, reward: -9.0, running_reward: -5.0621, time (sec): 32548.0736\n",
      "Ep. 4000 done, reward: -6.0, running_reward: -5.1302, time (sec): 32570.5704\n",
      "Ep. 4002 done, reward: 3.0, running_reward: -5.0278, time (sec): 32595.9726\n",
      "Ep. 4004 done, reward: -3.0, running_reward: -4.9677, time (sec): 32621.6975\n",
      "Ep. 4006 done, reward: -6.0, running_reward: -5.0080, time (sec): 32645.6166\n",
      "Ep. 4008 done, reward: 3.0, running_reward: -4.9972, time (sec): 32669.2001\n",
      "Ep. 4010 done, reward: -13.0, running_reward: -5.1564, time (sec): 32688.9142\n",
      "Ep. 4012 done, reward: 2.0, running_reward: -5.1625, time (sec): 32713.9366\n",
      "Ep. 4014 done, reward: -4.0, running_reward: -5.1889, time (sec): 32739.8722\n",
      "Ep. 4016 done, reward: -3.0, running_reward: -5.1750, time (sec): 32769.0076\n",
      "Ep. 4018 done, reward: -9.0, running_reward: -5.1521, time (sec): 32793.8694\n",
      "Ep. 4020 done, reward: -11.0, running_reward: -5.2883, time (sec): 32816.1433\n",
      "Ep. 4022 done, reward: 1.0, running_reward: -5.1533, time (sec): 32842.9990\n",
      "Ep. 4024 done, reward: -8.0, running_reward: -5.1208, time (sec): 32867.5432\n",
      "Ep. 4026 done, reward: -10.0, running_reward: -5.2278, time (sec): 32887.3748\n",
      "Ep. 4028 done, reward: -10.0, running_reward: -5.2535, time (sec): 32908.5624\n",
      "Ep. 4030 done, reward: -1.0, running_reward: -5.2480, time (sec): 32934.5633\n",
      "Ep. 4032 done, reward: -5.0, running_reward: -5.1441, time (sec): 32957.1000\n",
      "Ep. 4034 done, reward: -7.0, running_reward: -5.2602, time (sec): 32977.9229\n",
      "Ep. 4036 done, reward: -6.0, running_reward: -5.2452, time (sec): 33002.9733\n",
      "Ep. 4038 done, reward: 2.0, running_reward: -5.2100, time (sec): 33027.8328\n",
      "Ep. 4040 done, reward: -10.0, running_reward: -5.2261, time (sec): 33053.5150\n",
      "Ep. 4042 done, reward: -4.0, running_reward: -5.2116, time (sec): 33078.0710\n",
      "Ep. 4044 done, reward: 1.0, running_reward: -5.0781, time (sec): 33105.7378\n",
      "Ep. 4046 done, reward: 5.0, running_reward: -5.0062, time (sec): 33130.9152\n",
      "Ep. 4048 done, reward: 8.0, running_reward: -4.9157, time (sec): 33152.0600\n",
      "Ep. 4050 done, reward: -13.0, running_reward: -4.9677, time (sec): 33171.6609\n",
      "Ep. 4052 done, reward: 2.0, running_reward: -5.0468, time (sec): 33193.1372\n",
      "Ep. 4054 done, reward: -12.0, running_reward: -5.1555, time (sec): 33217.3332\n",
      "Ep. 4056 done, reward: -11.0, running_reward: -5.2916, time (sec): 33237.8699\n",
      "Ep. 4058 done, reward: -9.0, running_reward: -5.3060, time (sec): 33260.5848\n",
      "Ep. 4060 done, reward: -7.0, running_reward: -5.1714, time (sec): 33280.0219\n",
      "Ep. 4062 done, reward: -7.0, running_reward: -5.2573, time (sec): 33302.0913\n",
      "Ep. 4064 done, reward: -8.0, running_reward: -5.2624, time (sec): 33325.8609\n",
      "Ep. 4066 done, reward: -7.0, running_reward: -5.2376, time (sec): 33351.3803\n",
      "Ep. 4068 done, reward: 2.0, running_reward: -5.1034, time (sec): 33377.4503\n",
      "Ep. 4070 done, reward: -6.0, running_reward: -5.1312, time (sec): 33406.9315\n",
      "Ep. 4072 done, reward: -5.0, running_reward: -5.1088, time (sec): 33430.4571\n",
      "Ep. 4074 done, reward: -5.0, running_reward: -5.0670, time (sec): 33454.1526\n",
      "Ep. 4076 done, reward: -9.0, running_reward: -5.1255, time (sec): 33477.7544\n",
      "Ep. 4078 done, reward: -7.0, running_reward: -5.1232, time (sec): 33502.3791\n",
      "Ep. 4080 done, reward: -7.0, running_reward: -5.1605, time (sec): 33524.2123\n",
      "Ep. 4082 done, reward: -5.0, running_reward: -5.2068, time (sec): 33544.9915\n",
      "Ep. 4084 done, reward: -2.0, running_reward: -5.1331, time (sec): 33571.5067\n",
      "Ep. 4086 done, reward: -7.0, running_reward: -5.1703, time (sec): 33593.9446\n",
      "Ep. 4088 done, reward: -5.0, running_reward: -5.1372, time (sec): 33619.9499\n",
      "Ep. 4090 done, reward: -4.0, running_reward: -5.1739, time (sec): 33644.7004\n",
      "Ep. 4092 done, reward: 2.0, running_reward: -5.1500, time (sec): 33671.1489\n",
      "Ep. 4094 done, reward: 1.0, running_reward: -5.1266, time (sec): 33695.9548\n",
      "Ep. 4096 done, reward: -7.0, running_reward: -5.1837, time (sec): 33725.3813\n",
      "Ep. 4098 done, reward: 1.0, running_reward: -5.1497, time (sec): 33754.0068\n",
      "Ep. 4100 done, reward: -14.0, running_reward: -5.3159, time (sec): 33778.5391\n",
      "Ep. 4102 done, reward: -5.0, running_reward: -5.3690, time (sec): 33800.5828\n",
      "Ep. 4104 done, reward: -8.0, running_reward: -5.4412, time (sec): 33824.7112\n",
      "Ep. 4106 done, reward: -4.0, running_reward: -5.3828, time (sec): 33851.7515\n",
      "Ep. 4108 done, reward: -7.0, running_reward: -5.4150, time (sec): 33874.1974\n",
      "Ep. 4110 done, reward: -5.0, running_reward: -5.4265, time (sec): 33898.3726\n",
      "Ep. 4112 done, reward: 10.0, running_reward: -5.2087, time (sec): 33921.8022\n",
      "Ep. 4114 done, reward: -4.0, running_reward: -5.1747, time (sec): 33945.9582\n",
      "Ep. 4116 done, reward: -2.0, running_reward: -5.1610, time (sec): 33967.6978\n",
      "Ep. 4118 done, reward: -9.0, running_reward: -5.1780, time (sec): 33994.8473\n",
      "Ep. 4120 done, reward: -7.0, running_reward: -5.2737, time (sec): 34016.7287\n",
      "Ep. 4122 done, reward: -8.0, running_reward: -5.1893, time (sec): 34038.8092\n",
      "Ep. 4124 done, reward: -13.0, running_reward: -5.2458, time (sec): 34065.4061\n",
      "Ep. 4126 done, reward: -4.0, running_reward: -5.2210, time (sec): 34090.6966\n",
      "Ep. 4128 done, reward: -7.0, running_reward: -5.2465, time (sec): 34114.9759\n",
      "Ep. 4130 done, reward: -12.0, running_reward: -5.2225, time (sec): 34133.3597\n",
      "Ep. 4132 done, reward: 5.0, running_reward: -5.1774, time (sec): 34153.6226\n",
      "Ep. 4134 done, reward: 5.0, running_reward: -5.0442, time (sec): 34183.0890\n",
      "Ep. 4136 done, reward: -9.0, running_reward: -5.1328, time (sec): 34202.9652\n",
      "Ep. 4138 done, reward: -11.0, running_reward: -5.2397, time (sec): 34224.7532\n",
      "Ep. 4140 done, reward: -1.0, running_reward: -5.2147, time (sec): 34251.3617\n",
      "Ep. 4142 done, reward: -9.0, running_reward: -5.3198, time (sec): 34273.5982\n",
      "Ep. 4144 done, reward: -10.0, running_reward: -5.3832, time (sec): 34293.6600\n",
      "Ep. 4146 done, reward: -5.0, running_reward: -5.3657, time (sec): 34318.2352\n",
      "Ep. 4148 done, reward: -12.0, running_reward: -5.3393, time (sec): 34342.2159\n",
      "Ep. 4150 done, reward: -9.0, running_reward: -5.4319, time (sec): 34364.7600\n",
      "Ep. 4152 done, reward: -7.0, running_reward: -5.3542, time (sec): 34388.1571\n",
      "Ep. 4154 done, reward: -4.0, running_reward: -5.4362, time (sec): 34411.8738\n",
      "Ep. 4156 done, reward: -5.0, running_reward: -5.3087, time (sec): 34435.7727\n",
      "Ep. 4158 done, reward: 3.0, running_reward: -5.0840, time (sec): 34459.8710\n",
      "Ep. 4160 done, reward: 11.0, running_reward: -4.8827, time (sec): 34483.3775\n",
      "Ep. 4162 done, reward: -6.0, running_reward: -4.7564, time (sec): 34506.2078\n",
      "Ep. 4164 done, reward: -8.0, running_reward: -4.7517, time (sec): 34530.2036\n",
      "Ep. 4166 done, reward: -11.0, running_reward: -4.7572, time (sec): 34556.6944\n",
      "Ep. 4168 done, reward: -4.0, running_reward: -4.8609, time (sec): 34580.9120\n",
      "Ep. 4170 done, reward: 1.0, running_reward: -4.7641, time (sec): 34607.6194\n",
      "Ep. 4172 done, reward: -4.0, running_reward: -4.8380, time (sec): 34630.2508\n",
      "Ep. 4174 done, reward: -11.0, running_reward: -4.9210, time (sec): 34654.3751\n",
      "Ep. 4176 done, reward: 1.0, running_reward: -4.7537, time (sec): 34678.4180\n",
      "Ep. 4178 done, reward: -3.0, running_reward: -4.8178, time (sec): 34700.5970\n",
      "Ep. 4180 done, reward: -13.0, running_reward: -4.8816, time (sec): 34724.3837\n",
      "Ep. 4182 done, reward: 2.0, running_reward: -4.7348, time (sec): 34748.9552\n",
      "Ep. 4184 done, reward: -11.0, running_reward: -4.8397, time (sec): 34771.8373\n",
      "Ep. 4186 done, reward: 1.0, running_reward: -4.8027, time (sec): 34795.2839\n",
      "Ep. 4188 done, reward: -6.0, running_reward: -4.7176, time (sec): 34821.6232\n",
      "Ep. 4190 done, reward: -11.0, running_reward: -4.7832, time (sec): 34844.7792\n",
      "Ep. 4192 done, reward: -3.0, running_reward: -4.8170, time (sec): 34877.7889\n",
      "Ep. 4194 done, reward: -15.0, running_reward: -4.8613, time (sec): 34907.3295\n",
      "Ep. 4196 done, reward: -3.0, running_reward: -4.9232, time (sec): 34942.3026\n",
      "Ep. 4198 done, reward: 3.0, running_reward: -4.8843, time (sec): 34978.6710\n",
      "Ep. 4200 done, reward: -9.0, running_reward: -4.9167, time (sec): 35013.4828\n",
      "Ep. 4202 done, reward: -11.0, running_reward: -4.9388, time (sec): 35046.3397\n",
      "Ep. 4204 done, reward: 1.0, running_reward: -4.8701, time (sec): 35075.3482\n",
      "Ep. 4206 done, reward: -3.0, running_reward: -4.8329, time (sec): 35103.8032\n",
      "Ep. 4208 done, reward: -7.0, running_reward: -4.9552, time (sec): 35127.9148\n",
      "Ep. 4210 done, reward: 7.0, running_reward: -4.7569, time (sec): 35154.6640\n",
      "Ep. 4212 done, reward: -5.0, running_reward: -4.7420, time (sec): 35175.8490\n",
      "Ep. 4214 done, reward: -7.0, running_reward: -4.6483, time (sec): 35204.2067\n",
      "Ep. 4216 done, reward: -8.0, running_reward: -4.6952, time (sec): 35226.4414\n",
      "Ep. 4218 done, reward: -6.0, running_reward: -4.6717, time (sec): 35251.5312\n",
      "Ep. 4220 done, reward: 1.0, running_reward: -4.5984, time (sec): 35280.9987\n",
      "Ep. 4222 done, reward: -3.0, running_reward: -4.6161, time (sec): 35310.6585\n",
      "Ep. 4224 done, reward: 2.0, running_reward: -4.5636, time (sec): 35336.6882\n",
      "Ep. 4226 done, reward: -13.0, running_reward: -4.7018, time (sec): 35359.7809\n",
      "Ep. 4228 done, reward: -5.0, running_reward: -4.6879, time (sec): 35389.9942\n",
      "Ep. 4230 done, reward: -3.0, running_reward: -4.7534, time (sec): 35420.8373\n",
      "Ep. 4232 done, reward: -7.0, running_reward: -4.8278, time (sec): 35462.8116\n",
      "Ep. 4234 done, reward: -2.0, running_reward: -4.6527, time (sec): 35504.1565\n",
      "Ep. 4236 done, reward: -5.0, running_reward: -4.5210, time (sec): 35532.8055\n",
      "Ep. 4238 done, reward: -5.0, running_reward: -4.5899, time (sec): 35564.2436\n",
      "Ep. 4240 done, reward: -12.0, running_reward: -4.5889, time (sec): 35607.3419\n",
      "Ep. 4242 done, reward: -2.0, running_reward: -4.4879, time (sec): 35653.6482\n",
      "Ep. 4244 done, reward: -5.0, running_reward: -4.3892, time (sec): 35692.2321\n",
      "Ep. 4246 done, reward: -5.0, running_reward: -4.3617, time (sec): 35741.5442\n",
      "Ep. 4248 done, reward: -14.0, running_reward: -4.4644, time (sec): 35789.9737\n",
      "Ep. 4250 done, reward: -9.0, running_reward: -4.5448, time (sec): 35829.4219\n",
      "Ep. 4252 done, reward: -6.0, running_reward: -4.5044, time (sec): 35865.4982\n",
      "Ep. 4254 done, reward: -5.0, running_reward: -4.5341, time (sec): 35904.5590\n",
      "Ep. 4256 done, reward: -8.0, running_reward: -4.5734, time (sec): 35955.7180\n",
      "Ep. 4258 done, reward: -2.0, running_reward: -4.6113, time (sec): 36008.0341\n",
      "Ep. 4260 done, reward: -4.0, running_reward: -4.5001, time (sec): 36050.1179\n",
      "Ep. 4262 done, reward: 3.0, running_reward: -4.4201, time (sec): 36097.3053\n",
      "Ep. 4264 done, reward: -7.0, running_reward: -4.4616, time (sec): 36141.2855\n",
      "Ep. 4266 done, reward: 1.0, running_reward: -4.4519, time (sec): 36189.6315\n",
      "Ep. 4268 done, reward: -3.0, running_reward: -4.4824, time (sec): 36237.4153\n",
      "Ep. 4270 done, reward: -9.0, running_reward: -4.4931, time (sec): 36292.6472\n",
      "Ep. 4272 done, reward: -4.0, running_reward: -4.4734, time (sec): 36336.3786\n",
      "Ep. 4274 done, reward: 2.0, running_reward: -4.4634, time (sec): 36383.7947\n",
      "Ep. 4276 done, reward: 2.0, running_reward: -4.3744, time (sec): 36438.2566\n",
      "Ep. 4278 done, reward: -5.0, running_reward: -4.4462, time (sec): 36488.5681\n",
      "Ep. 4280 done, reward: -6.0, running_reward: -4.4771, time (sec): 36537.1776\n",
      "Ep. 4282 done, reward: 12.0, running_reward: -4.2383, time (sec): 36581.6663\n",
      "Ep. 4284 done, reward: -9.0, running_reward: -4.2242, time (sec): 36630.5731\n",
      "Ep. 4286 done, reward: -8.0, running_reward: -4.2597, time (sec): 36670.3194\n",
      "Ep. 4288 done, reward: -5.0, running_reward: -4.3735, time (sec): 36713.0463\n",
      "Ep. 4290 done, reward: -8.0, running_reward: -4.3961, time (sec): 36750.0925\n",
      "Ep. 4292 done, reward: -6.0, running_reward: -4.4181, time (sec): 36788.9175\n",
      "Ep. 4294 done, reward: -4.0, running_reward: -4.2910, time (sec): 36830.5398\n",
      "Ep. 4296 done, reward: -7.0, running_reward: -4.2657, time (sec): 36887.5908\n",
      "Ep. 4298 done, reward: -10.0, running_reward: -4.2313, time (sec): 36931.0499\n",
      "Ep. 4300 done, reward: -10.0, running_reward: -4.2372, time (sec): 36973.6704\n",
      "Ep. 4302 done, reward: -9.0, running_reward: -4.3419, time (sec): 37009.2932\n",
      "Ep. 4304 done, reward: -7.0, running_reward: -4.3453, time (sec): 37049.5155\n",
      "Ep. 4306 done, reward: -7.0, running_reward: -4.3684, time (sec): 37080.3282\n",
      "Ep. 4308 done, reward: -4.0, running_reward: -4.3314, time (sec): 37114.6847\n",
      "Ep. 4310 done, reward: -15.0, running_reward: -4.5041, time (sec): 37143.8445\n",
      "Ep. 4312 done, reward: 6.0, running_reward: -4.4337, time (sec): 37187.3433\n",
      "Ep. 4314 done, reward: -9.0, running_reward: -4.4751, time (sec): 37226.2757\n",
      "Ep. 4316 done, reward: -11.0, running_reward: -4.5356, time (sec): 37266.9610\n",
      "Ep. 4318 done, reward: -13.0, running_reward: -4.6842, time (sec): 37309.2060\n",
      "Ep. 4320 done, reward: -1.0, running_reward: -4.6109, time (sec): 37354.0121\n",
      "Ep. 4322 done, reward: -1.0, running_reward: -4.6183, time (sec): 37386.8309\n",
      "Ep. 4324 done, reward: -5.0, running_reward: -4.6259, time (sec): 37433.9170\n",
      "Ep. 4326 done, reward: -15.0, running_reward: -4.6937, time (sec): 37496.0797\n",
      "Ep. 4328 done, reward: 5.0, running_reward: -4.5404, time (sec): 37555.9801\n",
      "Ep. 4330 done, reward: -9.0, running_reward: -4.6192, time (sec): 37614.1083\n",
      "Ep. 4332 done, reward: 2.0, running_reward: -4.5964, time (sec): 37650.0442\n",
      "Ep. 4334 done, reward: -7.0, running_reward: -4.6146, time (sec): 37694.4658\n",
      "Ep. 4336 done, reward: -2.0, running_reward: -4.4833, time (sec): 37748.2125\n",
      "Ep. 4338 done, reward: -5.0, running_reward: -4.5431, time (sec): 37786.1404\n",
      "Ep. 4340 done, reward: 3.0, running_reward: -4.4029, time (sec): 37825.0002\n",
      "Ep. 4342 done, reward: -5.0, running_reward: -4.5039, time (sec): 37860.1330\n",
      "Ep. 4344 done, reward: -2.0, running_reward: -4.4442, time (sec): 37899.9177\n",
      "Ep. 4346 done, reward: -12.0, running_reward: -4.5549, time (sec): 37936.1072\n",
      "Ep. 4348 done, reward: -9.0, running_reward: -4.5147, time (sec): 37974.9013\n",
      "Ep. 4350 done, reward: 5.0, running_reward: -4.4045, time (sec): 38009.9707\n",
      "Ep. 4352 done, reward: -10.0, running_reward: -4.4763, time (sec): 38044.7032\n",
      "Ep. 4354 done, reward: -4.0, running_reward: -4.4668, time (sec): 38090.0194\n",
      "Ep. 4356 done, reward: -4.0, running_reward: -4.5070, time (sec): 38128.5204\n",
      "Ep. 4358 done, reward: -6.0, running_reward: -4.4278, time (sec): 38165.6629\n",
      "Ep. 4360 done, reward: -5.0, running_reward: -4.3600, time (sec): 38201.8947\n",
      "Ep. 4362 done, reward: -6.0, running_reward: -4.4025, time (sec): 38239.2503\n",
      "Ep. 4364 done, reward: 8.0, running_reward: -4.3438, time (sec): 38273.4532\n",
      "Ep. 4366 done, reward: 3.0, running_reward: -4.2769, time (sec): 38311.6819\n",
      "Ep. 4368 done, reward: -10.0, running_reward: -4.2225, time (sec): 38344.3898\n",
      "Ep. 4370 done, reward: -11.0, running_reward: -4.3277, time (sec): 38380.9678\n",
      "Ep. 4372 done, reward: -6.0, running_reward: -4.3708, time (sec): 38419.4306\n",
      "Ep. 4374 done, reward: 6.0, running_reward: -4.2833, time (sec): 38455.1941\n",
      "Ep. 4376 done, reward: -6.0, running_reward: -4.2976, time (sec): 38490.4609\n",
      "Ep. 4378 done, reward: -5.0, running_reward: -4.2918, time (sec): 38529.6589\n",
      "Ep. 4380 done, reward: -8.0, running_reward: -4.2963, time (sec): 38565.9296\n",
      "Ep. 4382 done, reward: -10.0, running_reward: -4.3702, time (sec): 38602.7960\n",
      "Ep. 4384 done, reward: -17.0, running_reward: -4.5522, time (sec): 38640.3148\n",
      "Ep. 4386 done, reward: -2.0, running_reward: -4.5212, time (sec): 38684.0420\n",
      "Ep. 4388 done, reward: -8.0, running_reward: -4.5212, time (sec): 38718.9059\n",
      "Ep. 4390 done, reward: -4.0, running_reward: -4.4019, time (sec): 38741.7339\n",
      "Ep. 4392 done, reward: -2.0, running_reward: -4.3046, time (sec): 38766.0336\n",
      "Ep. 4394 done, reward: 5.0, running_reward: -4.2976, time (sec): 38800.5901\n",
      "Ep. 4396 done, reward: -7.0, running_reward: -4.4009, time (sec): 38827.8420\n",
      "Ep. 4398 done, reward: -10.0, running_reward: -4.4727, time (sec): 38857.3906\n",
      "Ep. 4400 done, reward: 5.0, running_reward: -4.3733, time (sec): 38887.1534\n",
      "Ep. 4402 done, reward: 7.0, running_reward: -4.3054, time (sec): 38913.8121\n",
      "Ep. 4404 done, reward: -8.0, running_reward: -4.3591, time (sec): 38940.0321\n",
      "Ep. 4406 done, reward: -9.0, running_reward: -4.5109, time (sec): 38963.9267\n",
      "Ep. 4408 done, reward: -2.0, running_reward: -4.5500, time (sec): 38990.9446\n",
      "Ep. 4410 done, reward: -7.0, running_reward: -4.5196, time (sec): 39015.8381\n",
      "Ep. 4412 done, reward: -3.0, running_reward: -4.5586, time (sec): 39040.9692\n",
      "Ep. 4414 done, reward: -6.0, running_reward: -4.6368, time (sec): 39064.0538\n",
      "Ep. 4416 done, reward: -11.0, running_reward: -4.7634, time (sec): 39086.0409\n",
      "Ep. 4418 done, reward: -9.0, running_reward: -4.8774, time (sec): 39107.7434\n",
      "Ep. 4420 done, reward: -8.0, running_reward: -4.8406, time (sec): 39133.1825\n",
      "Ep. 4422 done, reward: -11.0, running_reward: -4.8840, time (sec): 39160.6139\n",
      "Ep. 4424 done, reward: -2.0, running_reward: -4.7375, time (sec): 39186.5655\n",
      "Ep. 4426 done, reward: -5.0, running_reward: -4.6734, time (sec): 39211.6524\n",
      "Ep. 4428 done, reward: -9.0, running_reward: -4.7001, time (sec): 39235.0114\n",
      "Ep. 4430 done, reward: -2.0, running_reward: -4.7850, time (sec): 39256.4080\n",
      "Ep. 4432 done, reward: -10.0, running_reward: -4.8689, time (sec): 39279.2736\n",
      "Ep. 4434 done, reward: 3.0, running_reward: -4.8113, time (sec): 39304.3369\n",
      "Ep. 4436 done, reward: -9.0, running_reward: -4.8353, time (sec): 39343.5507\n",
      "Ep. 4438 done, reward: 2.0, running_reward: -4.7488, time (sec): 39374.4636\n",
      "Ep. 4440 done, reward: -6.0, running_reward: -4.7242, time (sec): 39406.0907\n",
      "Ep. 4442 done, reward: -9.0, running_reward: -4.7895, time (sec): 39439.6946\n",
      "Ep. 4444 done, reward: 7.0, running_reward: -4.6737, time (sec): 39476.6927\n",
      "Ep. 4446 done, reward: 3.0, running_reward: -4.6199, time (sec): 39501.2685\n",
      "Ep. 4448 done, reward: -13.0, running_reward: -4.7570, time (sec): 39523.1923\n",
      "Ep. 4450 done, reward: 7.0, running_reward: -4.6022, time (sec): 39557.7140\n",
      "Ep. 4452 done, reward: -8.0, running_reward: -4.6897, time (sec): 39586.2879\n",
      "Ep. 4454 done, reward: -7.0, running_reward: -4.7752, time (sec): 39607.6052\n",
      "Ep. 4456 done, reward: 6.0, running_reward: -4.7489, time (sec): 39635.5917\n",
      "Ep. 4458 done, reward: -7.0, running_reward: -4.8036, time (sec): 39666.3019\n",
      "Ep. 4460 done, reward: -6.0, running_reward: -4.8175, time (sec): 39699.7359\n",
      "Ep. 4462 done, reward: -10.0, running_reward: -4.8612, time (sec): 39727.8163\n",
      "Ep. 4464 done, reward: 7.0, running_reward: -4.7836, time (sec): 39750.8178\n",
      "Ep. 4466 done, reward: -13.0, running_reward: -4.8283, time (sec): 39774.1192\n",
      "Ep. 4468 done, reward: -9.0, running_reward: -4.8915, time (sec): 39799.6609\n",
      "Ep. 4470 done, reward: -1.0, running_reward: -4.8537, time (sec): 39827.6739\n",
      "Ep. 4472 done, reward: -5.0, running_reward: -4.8665, time (sec): 39850.8077\n",
      "Ep. 4474 done, reward: -7.0, running_reward: -4.8199, time (sec): 39878.2563\n",
      "Ep. 4476 done, reward: -6.0, running_reward: -4.7938, time (sec): 39905.0035\n",
      "Ep. 4478 done, reward: 2.0, running_reward: -4.6982, time (sec): 39939.8640\n",
      "Ep. 4480 done, reward: -9.0, running_reward: -4.7145, time (sec): 39965.3253\n",
      "Ep. 4482 done, reward: -7.0, running_reward: -4.7402, time (sec): 39988.1330\n",
      "Ep. 4484 done, reward: -7.0, running_reward: -4.7258, time (sec): 40014.1525\n",
      "Ep. 4486 done, reward: -12.0, running_reward: -4.8805, time (sec): 40035.3902\n",
      "Ep. 4488 done, reward: -9.0, running_reward: -4.9525, time (sec): 40062.0626\n",
      "Ep. 4490 done, reward: -5.0, running_reward: -4.9238, time (sec): 40090.0208\n",
      "Ep. 4492 done, reward: -1.0, running_reward: -4.8655, time (sec): 40114.6043\n",
      "Ep. 4494 done, reward: -10.0, running_reward: -4.9380, time (sec): 40140.4595\n",
      "Ep. 4496 done, reward: 2.0, running_reward: -4.8593, time (sec): 40167.3975\n",
      "Ep. 4498 done, reward: -1.0, running_reward: -4.8122, time (sec): 40197.1993\n",
      "Ep. 4500 done, reward: -6.0, running_reward: -4.7269, time (sec): 40227.3518\n",
      "Ep. 4502 done, reward: 2.0, running_reward: -4.5535, time (sec): 40260.7760\n",
      "Ep. 4504 done, reward: -4.0, running_reward: -4.5722, time (sec): 40289.5725\n",
      "Ep. 4506 done, reward: -1.0, running_reward: -4.4219, time (sec): 40324.1567\n",
      "Ep. 4508 done, reward: -13.0, running_reward: -4.5134, time (sec): 40349.6102\n",
      "Ep. 4510 done, reward: 9.0, running_reward: -4.4128, time (sec): 40372.7255\n",
      "Ep. 4512 done, reward: -5.0, running_reward: -4.3651, time (sec): 40402.5065\n",
      "Ep. 4514 done, reward: -9.0, running_reward: -4.3880, time (sec): 40426.5574\n",
      "Ep. 4516 done, reward: -13.0, running_reward: -4.5297, time (sec): 40450.1938\n",
      "Ep. 4518 done, reward: -9.0, running_reward: -4.5790, time (sec): 40477.8351\n",
      "Ep. 4520 done, reward: -11.0, running_reward: -4.6474, time (sec): 40500.0483\n",
      "Ep. 4522 done, reward: -6.0, running_reward: -4.7238, time (sec): 40523.3296\n",
      "Ep. 4524 done, reward: -6.0, running_reward: -4.6502, time (sec): 40550.1162\n",
      "Ep. 4526 done, reward: 10.0, running_reward: -4.4874, time (sec): 40575.3505\n",
      "Ep. 4528 done, reward: -1.0, running_reward: -4.4378, time (sec): 40601.9929\n",
      "Ep. 4530 done, reward: -10.0, running_reward: -4.5881, time (sec): 40621.9245\n",
      "Ep. 4532 done, reward: 8.0, running_reward: -4.4069, time (sec): 40647.5512\n",
      "Ep. 4534 done, reward: 8.0, running_reward: -4.2590, time (sec): 40675.3257\n",
      "Ep. 4536 done, reward: -1.0, running_reward: -4.2337, time (sec): 45421.4717\n",
      "Ep. 4538 done, reward: -5.0, running_reward: -4.1896, time (sec): 45453.6832\n",
      "Ep. 4540 done, reward: -8.0, running_reward: -4.1961, time (sec): 45481.3779\n",
      "Ep. 4542 done, reward: -3.0, running_reward: -4.2119, time (sec): 45506.3431\n",
      "Ep. 4544 done, reward: -7.0, running_reward: -4.3070, time (sec): 45532.0944\n",
      "Ep. 4546 done, reward: -3.0, running_reward: -4.2909, time (sec): 45556.2536\n",
      "Ep. 4548 done, reward: -11.0, running_reward: -4.3056, time (sec): 45581.5293\n",
      "Ep. 4550 done, reward: -7.0, running_reward: -4.2503, time (sec): 45608.6756\n",
      "Ep. 4552 done, reward: -4.0, running_reward: -4.2750, time (sec): 45636.2272\n",
      "Ep. 4554 done, reward: 11.0, running_reward: -3.9908, time (sec): 45654.3210\n",
      "Ep. 4556 done, reward: -2.0, running_reward: -3.8621, time (sec): 45679.0386\n",
      "Ep. 4558 done, reward: 5.0, running_reward: -3.8541, time (sec): 45700.2039\n",
      "Ep. 4560 done, reward: 10.0, running_reward: -3.6873, time (sec): 45722.0952\n",
      "Ep. 4562 done, reward: 3.0, running_reward: -3.6829, time (sec): 45744.7900\n",
      "Ep. 4564 done, reward: -4.0, running_reward: -3.6100, time (sec): 45772.5729\n",
      "Ep. 4566 done, reward: -9.0, running_reward: -3.7371, time (sec): 45795.4110\n",
      "Ep. 4568 done, reward: -9.0, running_reward: -3.8022, time (sec): 45819.9836\n",
      "Ep. 4570 done, reward: -1.0, running_reward: -3.8355, time (sec): 45844.8111\n",
      "Ep. 4572 done, reward: -3.0, running_reward: -3.7694, time (sec): 45869.2094\n",
      "Ep. 4574 done, reward: -7.0, running_reward: -3.8337, time (sec): 45891.7962\n",
      "Ep. 4576 done, reward: -10.0, running_reward: -3.8475, time (sec): 45918.6104\n",
      "Ep. 4578 done, reward: 9.0, running_reward: -3.7700, time (sec): 45940.5192\n",
      "Ep. 4580 done, reward: -1.0, running_reward: -3.6060, time (sec): 45965.1458\n",
      "Ep. 4582 done, reward: -1.0, running_reward: -3.6433, time (sec): 45992.7855\n",
      "Ep. 4584 done, reward: -3.0, running_reward: -3.6206, time (sec): 46019.4108\n",
      "Ep. 4586 done, reward: -10.0, running_reward: -3.7574, time (sec): 46040.2591\n",
      "Ep. 4588 done, reward: 1.0, running_reward: -3.7914, time (sec): 46065.7436\n",
      "Ep. 4590 done, reward: 7.0, running_reward: -3.7747, time (sec): 46087.9233\n",
      "Ep. 4592 done, reward: -1.0, running_reward: -3.7789, time (sec): 46114.1426\n",
      "Ep. 4594 done, reward: -7.0, running_reward: -3.8430, time (sec): 46136.1415\n",
      "Ep. 4596 done, reward: 4.0, running_reward: -3.7067, time (sec): 46160.2052\n",
      "Ep. 4598 done, reward: -11.0, running_reward: -3.8815, time (sec): 46180.1235\n",
      "Ep. 4600 done, reward: 3.0, running_reward: -3.7446, time (sec): 46207.5274\n",
      "Ep. 4602 done, reward: 1.0, running_reward: -3.6502, time (sec): 46233.1257\n",
      "Ep. 4604 done, reward: -9.0, running_reward: -3.6279, time (sec): 46257.1157\n",
      "Ep. 4606 done, reward: -1.0, running_reward: -3.6251, time (sec): 46285.8769\n",
      "Ep. 4608 done, reward: 7.0, running_reward: -3.5721, time (sec): 46311.7387\n",
      "Ep. 4610 done, reward: 10.0, running_reward: -3.3911, time (sec): 46337.6411\n",
      "Ep. 4612 done, reward: -7.0, running_reward: -3.5124, time (sec): 46360.0523\n",
      "Ep. 4614 done, reward: -6.0, running_reward: -3.5124, time (sec): 46390.2260\n",
      "Ep. 4616 done, reward: -8.0, running_reward: -3.5720, time (sec): 46414.8614\n",
      "Ep. 4618 done, reward: -7.0, running_reward: -3.6501, time (sec): 46443.0775\n",
      "Ep. 4620 done, reward: -2.0, running_reward: -3.7064, time (sec): 46472.4155\n",
      "Ep. 4622 done, reward: -8.0, running_reward: -3.7622, time (sec): 46499.0390\n",
      "Ep. 4624 done, reward: -1.0, running_reward: -3.5587, time (sec): 46524.5172\n",
      "Ep. 4626 done, reward: 3.0, running_reward: -3.4876, time (sec): 46556.3019\n",
      "Ep. 4628 done, reward: -1.0, running_reward: -3.3886, time (sec): 46591.9821\n",
      "Ep. 4630 done, reward: -3.0, running_reward: -3.4006, time (sec): 46616.4174\n",
      "Ep. 4632 done, reward: -15.0, running_reward: -3.5622, time (sec): 46637.2976\n",
      "Ep. 4634 done, reward: -8.0, running_reward: -3.5812, time (sec): 46667.6722\n",
      "Ep. 4636 done, reward: -4.0, running_reward: -3.5697, time (sec): 46706.2145\n",
      "Ep. 4638 done, reward: -3.0, running_reward: -3.5980, time (sec): 46742.0521\n",
      "Ep. 4640 done, reward: 7.0, running_reward: -3.5950, time (sec): 46776.8577\n",
      "Ep. 4642 done, reward: -8.0, running_reward: -3.6232, time (sec): 46813.8304\n",
      "Ep. 4644 done, reward: -6.0, running_reward: -3.6309, time (sec): 46840.7637\n",
      "Ep. 4646 done, reward: 3.0, running_reward: -3.5683, time (sec): 46881.9830\n",
      "Ep. 4648 done, reward: 3.0, running_reward: -3.5465, time (sec): 46916.7683\n",
      "Ep. 4650 done, reward: -6.0, running_reward: -3.4765, time (sec): 46944.0591\n",
      "Ep. 4652 done, reward: -6.0, running_reward: -3.5069, time (sec): 46968.4032\n",
      "Ep. 4654 done, reward: 2.0, running_reward: -3.4567, time (sec): 47005.9228\n",
      "Ep. 4656 done, reward: -4.0, running_reward: -3.4774, time (sec): 47041.8363\n",
      "Ep. 4658 done, reward: -9.0, running_reward: -3.5378, time (sec): 47075.5122\n",
      "Ep. 4660 done, reward: -6.0, running_reward: -3.5769, time (sec): 47114.2749\n",
      "Ep. 4662 done, reward: 2.0, running_reward: -3.5550, time (sec): 47152.2911\n",
      "Ep. 4664 done, reward: -16.0, running_reward: -3.6641, time (sec): 47194.7331\n",
      "Ep. 4666 done, reward: -15.0, running_reward: -3.6818, time (sec): 47235.0668\n",
      "Ep. 4668 done, reward: -6.0, running_reward: -3.7378, time (sec): 47268.5587\n",
      "Ep. 4670 done, reward: 4.0, running_reward: -3.7125, time (sec): 47295.7415\n",
      "Ep. 4672 done, reward: -2.0, running_reward: -3.6785, time (sec): 47327.4257\n",
      "Ep. 4674 done, reward: -2.0, running_reward: -3.6946, time (sec): 47362.5392\n",
      "Ep. 4676 done, reward: 9.0, running_reward: -3.6201, time (sec): 47400.8376\n",
      "Ep. 4678 done, reward: -1.0, running_reward: -3.6670, time (sec): 47435.2213\n",
      "Ep. 4680 done, reward: 1.0, running_reward: -3.5048, time (sec): 47467.0819\n",
      "Ep. 4682 done, reward: -8.0, running_reward: -3.5646, time (sec): 47491.9799\n",
      "Ep. 4684 done, reward: -1.0, running_reward: -3.5333, time (sec): 47523.7934\n",
      "Ep. 4686 done, reward: -1.0, running_reward: -3.4829, time (sec): 47561.4412\n",
      "Ep. 4688 done, reward: -2.0, running_reward: -3.3940, time (sec): 47591.7352\n",
      "Ep. 4690 done, reward: 10.0, running_reward: -3.2463, time (sec): 47617.4153\n",
      "Ep. 4692 done, reward: -13.0, running_reward: -3.4008, time (sec): 47641.3719\n",
      "Ep. 4694 done, reward: 4.0, running_reward: -3.2634, time (sec): 47675.4033\n",
      "Ep. 4696 done, reward: -6.0, running_reward: -3.1694, time (sec): 47697.5326\n",
      "Ep. 4698 done, reward: -12.0, running_reward: -3.2857, time (sec): 47721.6480\n",
      "Ep. 4700 done, reward: -7.0, running_reward: -3.3002, time (sec): 47745.7393\n",
      "Ep. 4702 done, reward: 6.0, running_reward: -3.2141, time (sec): 47769.5667\n",
      "Ep. 4704 done, reward: -11.0, running_reward: -3.1711, time (sec): 47790.8559\n",
      "Ep. 4706 done, reward: -4.0, running_reward: -3.2371, time (sec): 47816.4106\n",
      "Ep. 4708 done, reward: -3.0, running_reward: -3.2719, time (sec): 47841.9149\n",
      "Ep. 4710 done, reward: -2.0, running_reward: -3.2367, time (sec): 47874.3841\n",
      "Ep. 4712 done, reward: -10.0, running_reward: -3.2822, time (sec): 47899.8481\n",
      "Ep. 4714 done, reward: 3.0, running_reward: -3.2265, time (sec): 47927.4614\n",
      "Ep. 4716 done, reward: -13.0, running_reward: -3.2725, time (sec): 47953.0867\n",
      "Ep. 4718 done, reward: -4.0, running_reward: -3.3266, time (sec): 47984.2013\n",
      "Ep. 4720 done, reward: -13.0, running_reward: -3.3706, time (sec): 48015.8654\n",
      "Ep. 4722 done, reward: -5.0, running_reward: -3.3832, time (sec): 48052.5981\n",
      "Ep. 4724 done, reward: -5.0, running_reward: -3.3362, time (sec): 48089.1552\n",
      "Ep. 4726 done, reward: -6.0, running_reward: -3.4090, time (sec): 48120.6471\n",
      "Ep. 4728 done, reward: -5.0, running_reward: -3.4901, time (sec): 48153.7284\n",
      "Ep. 4730 done, reward: -9.0, running_reward: -3.4810, time (sec): 48188.4392\n",
      "Ep. 4732 done, reward: 2.0, running_reward: -3.3719, time (sec): 48226.0652\n",
      "Ep. 4734 done, reward: -2.0, running_reward: -3.3446, time (sec): 48259.1629\n",
      "Ep. 4736 done, reward: -11.0, running_reward: -3.4178, time (sec): 48287.2994\n",
      "Ep. 4738 done, reward: -7.0, running_reward: -3.4890, time (sec): 48323.2703\n",
      "Ep. 4740 done, reward: -7.0, running_reward: -3.5985, time (sec): 48351.7615\n",
      "Ep. 4742 done, reward: 5.0, running_reward: -3.5462, time (sec): 48382.3719\n",
      "Ep. 4744 done, reward: -13.0, running_reward: -3.7244, time (sec): 48412.2142\n",
      "Ep. 4746 done, reward: -9.0, running_reward: -3.6809, time (sec): 48442.5311\n",
      "Ep. 4748 done, reward: 1.0, running_reward: -3.5779, time (sec): 48477.9054\n",
      "Ep. 4750 done, reward: -7.0, running_reward: -3.6559, time (sec): 48511.1296\n",
      "Ep. 4752 done, reward: 8.0, running_reward: -3.3645, time (sec): 48537.9182\n",
      "Ep. 4754 done, reward: -12.0, running_reward: -3.5364, time (sec): 48566.4322\n",
      "Ep. 4756 done, reward: -9.0, running_reward: -3.5758, time (sec): 48599.0663\n",
      "Ep. 4758 done, reward: -3.0, running_reward: -3.5544, time (sec): 48630.7748\n",
      "Ep. 4760 done, reward: -5.0, running_reward: -3.5832, time (sec): 48662.7766\n",
      "Ep. 4762 done, reward: -6.0, running_reward: -3.6214, time (sec): 48698.9533\n",
      "Ep. 4764 done, reward: -13.0, running_reward: -3.6496, time (sec): 48728.0024\n",
      "Ep. 4766 done, reward: -13.0, running_reward: -3.7862, time (sec): 48761.5304\n",
      "Ep. 4768 done, reward: -10.0, running_reward: -3.7713, time (sec): 48793.7187\n",
      "Ep. 4770 done, reward: -6.0, running_reward: -3.9047, time (sec): 48825.5639\n",
      "Ep. 4772 done, reward: 2.0, running_reward: -3.9060, time (sec): 48859.9490\n",
      "Ep. 4774 done, reward: 7.0, running_reward: -3.8078, time (sec): 48894.6114\n",
      "Ep. 4776 done, reward: -3.0, running_reward: -3.7125, time (sec): 48923.3706\n",
      "Ep. 4778 done, reward: -3.0, running_reward: -3.6884, time (sec): 48955.4290\n",
      "Ep. 4780 done, reward: -1.0, running_reward: -3.6547, time (sec): 48997.1568\n",
      "Ep. 4782 done, reward: 4.0, running_reward: -3.5222, time (sec): 49034.9764\n",
      "Ep. 4784 done, reward: 6.0, running_reward: -3.4515, time (sec): 49066.5165\n",
      "Ep. 4786 done, reward: 7.0, running_reward: -3.3821, time (sec): 49091.5834\n",
      "Ep. 4788 done, reward: 2.0, running_reward: -3.3146, time (sec): 49118.9965\n",
      "Ep. 4790 done, reward: -4.0, running_reward: -3.2095, time (sec): 49151.7793\n",
      "Ep. 4792 done, reward: -6.0, running_reward: -3.2749, time (sec): 49184.3166\n",
      "Ep. 4794 done, reward: 1.0, running_reward: -3.1304, time (sec): 49210.9549\n",
      "Ep. 4796 done, reward: 4.0, running_reward: -2.9984, time (sec): 49245.2485\n",
      "Ep. 4798 done, reward: -1.0, running_reward: -2.9784, time (sec): 49273.3467\n",
      "Ep. 4800 done, reward: 4.0, running_reward: -2.9188, time (sec): 49308.4028\n",
      "Ep. 4802 done, reward: 5.0, running_reward: -2.8998, time (sec): 49339.4784\n",
      "Ep. 4804 done, reward: -9.0, running_reward: -2.8628, time (sec): 49373.6940\n",
      "Ep. 4806 done, reward: -9.0, running_reward: -2.9849, time (sec): 49404.2904\n",
      "Ep. 4808 done, reward: 1.0, running_reward: -2.9650, time (sec): 49439.6971\n",
      "Ep. 4810 done, reward: -14.0, running_reward: -3.0262, time (sec): 49470.8227\n",
      "Ep. 4812 done, reward: -7.0, running_reward: -3.0954, time (sec): 49505.4517\n",
      "Ep. 4814 done, reward: -9.0, running_reward: -3.1337, time (sec): 49529.0341\n",
      "Ep. 4816 done, reward: -10.0, running_reward: -3.0822, time (sec): 49553.0371\n",
      "Ep. 4818 done, reward: -5.0, running_reward: -3.1699, time (sec): 49575.9670\n",
      "Ep. 4820 done, reward: 15.0, running_reward: -3.0261, time (sec): 49597.3906\n",
      "Ep. 4822 done, reward: -3.0, running_reward: -2.9860, time (sec): 49624.7561\n",
      "Ep. 4824 done, reward: -4.0, running_reward: -3.0359, time (sec): 49652.3153\n",
      "Ep. 4826 done, reward: 5.0, running_reward: -3.0443, time (sec): 49685.0490\n",
      "Ep. 4828 done, reward: 11.0, running_reward: -2.9232, time (sec): 49711.7498\n",
      "Ep. 4830 done, reward: -8.0, running_reward: -2.9351, time (sec): 49753.8336\n",
      "Ep. 4832 done, reward: -4.0, running_reward: -2.9860, time (sec): 49791.4200\n",
      "Ep. 4834 done, reward: -10.0, running_reward: -3.0959, time (sec): 49825.7593\n",
      "Ep. 4836 done, reward: 3.0, running_reward: -2.9152, time (sec): 49859.6489\n",
      "Ep. 4838 done, reward: -8.0, running_reward: -2.8679, time (sec): 49891.4203\n",
      "Ep. 4840 done, reward: 1.0, running_reward: -2.7216, time (sec): 49926.4637\n",
      "Ep. 4842 done, reward: -4.0, running_reward: -2.7965, time (sec): 49958.4415\n",
      "Ep. 4844 done, reward: -8.0, running_reward: -2.8011, time (sec): 49987.9677\n",
      "Ep. 4846 done, reward: -10.0, running_reward: -2.9146, time (sec): 50021.9883\n",
      "Ep. 4848 done, reward: 7.0, running_reward: -2.8361, time (sec): 50057.2733\n",
      "Ep. 4850 done, reward: -5.0, running_reward: -2.9386, time (sec): 50080.3012\n",
      "Ep. 4852 done, reward: -3.0, running_reward: -2.9794, time (sec): 53799.2848\n",
      "Ep. 4854 done, reward: -9.0, running_reward: -3.0695, time (sec): 54544.1842\n",
      "Ep. 4856 done, reward: 1.0, running_reward: -3.0479, time (sec): 54578.8113\n",
      "Ep. 4858 done, reward: 5.0, running_reward: -2.9670, time (sec): 54604.0354\n",
      "Ep. 4860 done, reward: 2.0, running_reward: -2.9770, time (sec): 54628.2002\n",
      "Ep. 4862 done, reward: -9.0, running_reward: -3.0969, time (sec): 54652.1715\n",
      "Ep. 4864 done, reward: -3.0, running_reward: -3.0356, time (sec): 54678.7455\n",
      "Ep. 4866 done, reward: -2.0, running_reward: -3.0249, time (sec): 54708.0560\n",
      "Ep. 4868 done, reward: -9.0, running_reward: -3.1339, time (sec): 54732.0750\n",
      "Ep. 4870 done, reward: -2.0, running_reward: -3.1608, time (sec): 54758.5734\n",
      "Ep. 4872 done, reward: -7.0, running_reward: -3.1580, time (sec): 54787.5295\n",
      "Ep. 4874 done, reward: 4.0, running_reward: -3.1839, time (sec): 54812.4792\n",
      "Ep. 4876 done, reward: -3.0, running_reward: -3.2396, time (sec): 54847.4027\n",
      "Ep. 4878 done, reward: -1.0, running_reward: -3.1554, time (sec): 54872.5622\n",
      "Ep. 4880 done, reward: -6.0, running_reward: -3.1229, time (sec): 54908.5936\n",
      "Ep. 4882 done, reward: -13.0, running_reward: -3.1809, time (sec): 54932.4732\n",
      "Ep. 4884 done, reward: 2.0, running_reward: -3.2164, time (sec): 54958.9008\n",
      "Ep. 4886 done, reward: 3.0, running_reward: -3.2511, time (sec): 54985.4540\n",
      "Ep. 4888 done, reward: -7.0, running_reward: -3.3950, time (sec): 55006.8782\n",
      "Ep. 4890 done, reward: -16.0, running_reward: -3.5072, time (sec): 55031.0149\n",
      "Ep. 4892 done, reward: -1.0, running_reward: -3.5662, time (sec): 55055.0666\n",
      "Ep. 4894 done, reward: 6.0, running_reward: -3.4452, time (sec): 55081.8246\n",
      "Ep. 4896 done, reward: -8.0, running_reward: -3.5457, time (sec): 55105.2529\n",
      "Ep. 4898 done, reward: -6.0, running_reward: -3.6441, time (sec): 55130.6910\n",
      "Ep. 4900 done, reward: -11.0, running_reward: -3.7706, time (sec): 55151.7031\n",
      "Ep. 4902 done, reward: -6.0, running_reward: -3.7853, time (sec): 55176.4639\n",
      "Ep. 4904 done, reward: -15.0, running_reward: -3.8798, time (sec): 55203.7552\n",
      "Ep. 4906 done, reward: -10.0, running_reward: -3.9323, time (sec): 55231.1407\n",
      "Ep. 4908 done, reward: -8.0, running_reward: -3.9934, time (sec): 55262.0689\n",
      "Ep. 4910 done, reward: -6.0, running_reward: -3.9937, time (sec): 55296.3162\n",
      "Ep. 4912 done, reward: -2.0, running_reward: -4.0036, time (sec): 55323.0632\n",
      "Ep. 4914 done, reward: -3.0, running_reward: -3.9638, time (sec): 55358.9992\n",
      "Ep. 4916 done, reward: -11.0, running_reward: -4.0048, time (sec): 55390.8023\n",
      "Ep. 4918 done, reward: -1.0, running_reward: -4.0440, time (sec): 55423.6394\n",
      "Ep. 4920 done, reward: -11.0, running_reward: -4.0834, time (sec): 55453.7974\n",
      "Ep. 4922 done, reward: -7.0, running_reward: -3.9732, time (sec): 55480.7630\n",
      "Ep. 4924 done, reward: -13.0, running_reward: -4.0538, time (sec): 55510.4499\n",
      "Ep. 4926 done, reward: -3.0, running_reward: -3.9833, time (sec): 55541.2688\n",
      "Ep. 4928 done, reward: 10.0, running_reward: -3.8932, time (sec): 55564.3558\n",
      "Ep. 4930 done, reward: -11.0, running_reward: -3.9455, time (sec): 55595.0751\n",
      "Ep. 4932 done, reward: -7.0, running_reward: -4.0558, time (sec): 55621.8233\n",
      "Ep. 4934 done, reward: -4.0, running_reward: -4.0646, time (sec): 55646.9935\n",
      "Ep. 4936 done, reward: -7.0, running_reward: -4.1824, time (sec): 55671.2112\n",
      "Ep. 4938 done, reward: 9.0, running_reward: -4.0587, time (sec): 55699.5684\n",
      "Ep. 4940 done, reward: -10.0, running_reward: -4.1868, time (sec): 55722.4221\n",
      "Ep. 4942 done, reward: -7.0, running_reward: -4.2824, time (sec): 55749.4510\n",
      "Ep. 4944 done, reward: 5.0, running_reward: -4.2759, time (sec): 55774.8797\n",
      "Ep. 4946 done, reward: 2.0, running_reward: -4.2203, time (sec): 55801.7383\n",
      "Ep. 4948 done, reward: -1.0, running_reward: -4.1760, time (sec): 55835.1806\n",
      "Ep. 4950 done, reward: -8.0, running_reward: -4.1828, time (sec): 55865.1696\n",
      "Ep. 4952 done, reward: -11.0, running_reward: -4.2689, time (sec): 55896.3215\n",
      "Ep. 4954 done, reward: -7.0, running_reward: -4.3035, time (sec): 55924.5550\n",
      "Ep. 4956 done, reward: -15.0, running_reward: -4.4174, time (sec): 55949.7575\n",
      "Ep. 4958 done, reward: -3.0, running_reward: -4.4090, time (sec): 55981.4331\n",
      "Ep. 4960 done, reward: -7.0, running_reward: -4.4605, time (sec): 56007.6025\n",
      "Ep. 4962 done, reward: 9.0, running_reward: -4.3312, time (sec): 56041.7080\n",
      "Ep. 4964 done, reward: -9.0, running_reward: -4.3846, time (sec): 56067.9869\n",
      "Ep. 4966 done, reward: -1.0, running_reward: -4.3172, time (sec): 56097.8298\n",
      "Ep. 4968 done, reward: -1.0, running_reward: -4.2215, time (sec): 56130.0486\n",
      "Ep. 4970 done, reward: 5.0, running_reward: -4.0479, time (sec): 56155.4862\n",
      "Ep. 4972 done, reward: -2.0, running_reward: -4.0962, time (sec): 56183.3911\n",
      "Ep. 4974 done, reward: 1.0, running_reward: -4.1334, time (sec): 56212.2280\n",
      "Ep. 4976 done, reward: 4.0, running_reward: -4.0508, time (sec): 56242.2742\n",
      "Ep. 4978 done, reward: 4.0, running_reward: -3.9995, time (sec): 56269.8049\n",
      "Ep. 4980 done, reward: 1.0, running_reward: -3.8604, time (sec): 56302.2648\n",
      "Ep. 4982 done, reward: -3.0, running_reward: -3.7541, time (sec): 56332.0620\n",
      "Ep. 4984 done, reward: -5.0, running_reward: -3.6997, time (sec): 56358.7536\n",
      "Ep. 4986 done, reward: -11.0, running_reward: -3.7163, time (sec): 56379.9248\n",
      "Ep. 4988 done, reward: -13.0, running_reward: -3.8417, time (sec): 56405.4675\n",
      "Ep. 4990 done, reward: 6.0, running_reward: -3.7448, time (sec): 56429.4627\n",
      "Ep. 4992 done, reward: -9.0, running_reward: -3.8494, time (sec): 56455.2394\n",
      "Ep. 4994 done, reward: -8.0, running_reward: -3.8627, time (sec): 56486.4094\n",
      "Ep. 4996 done, reward: -6.0, running_reward: -3.8755, time (sec): 56515.0528\n",
      "Ep. 4998 done, reward: -3.0, running_reward: -3.8581, time (sec): 56542.7557\n",
      "Ep. 5000 done, reward: -1.0, running_reward: -3.6626, time (sec): 56567.3676\n",
      "Ep. 5002 done, reward: -7.0, running_reward: -3.6795, time (sec): 56597.2485\n",
      "Ep. 5004 done, reward: -10.0, running_reward: -3.7162, time (sec): 56623.1126\n",
      "Ep. 5006 done, reward: -2.0, running_reward: -3.7613, time (sec): 56648.7255\n",
      "Ep. 5008 done, reward: 4.0, running_reward: -3.6068, time (sec): 56672.4351\n",
      "Ep. 5010 done, reward: -9.0, running_reward: -3.6943, time (sec): 56695.7138\n",
      "Ep. 5012 done, reward: 1.0, running_reward: -3.7494, time (sec): 56720.0879\n",
      "Ep. 5014 done, reward: -1.0, running_reward: -3.7244, time (sec): 56744.7920\n",
      "Ep. 5016 done, reward: -1.0, running_reward: -3.6405, time (sec): 56770.3614\n",
      "Ep. 5018 done, reward: -4.0, running_reward: -3.6575, time (sec): 56797.4494\n",
      "Ep. 5020 done, reward: -4.0, running_reward: -3.7634, time (sec): 56822.1822\n",
      "Ep. 5022 done, reward: 2.0, running_reward: -3.6091, time (sec): 56864.1806\n",
      "Ep. 5024 done, reward: -9.0, running_reward: -3.7361, time (sec): 56891.5878\n",
      "Ep. 5026 done, reward: 8.0, running_reward: -3.5026, time (sec): 56919.3197\n",
      "Ep. 5028 done, reward: -1.0, running_reward: -3.5023, time (sec): 56955.4048\n",
      "Ep. 5030 done, reward: -5.0, running_reward: -3.5420, time (sec): 56985.2155\n",
      "Ep. 5032 done, reward: 9.0, running_reward: -3.4310, time (sec): 57009.3910\n",
      "Ep. 5034 done, reward: -10.0, running_reward: -3.4429, time (sec): 57034.5596\n",
      "Ep. 5036 done, reward: -4.0, running_reward: -3.4441, time (sec): 57060.6671\n",
      "Ep. 5038 done, reward: 8.0, running_reward: -3.4144, time (sec): 57079.8528\n",
      "Ep. 5040 done, reward: 3.0, running_reward: -3.3362, time (sec): 57108.9925\n",
      "Ep. 5042 done, reward: -11.0, running_reward: -3.5184, time (sec): 57131.5573\n",
      "Ep. 5044 done, reward: 2.0, running_reward: -3.4680, time (sec): 57164.3090\n",
      "Ep. 5046 done, reward: -11.0, running_reward: -3.5882, time (sec): 57191.6246\n",
      "Ep. 5048 done, reward: -13.0, running_reward: -3.5874, time (sec): 57216.2833\n",
      "Ep. 5050 done, reward: -6.0, running_reward: -3.5265, time (sec): 57246.9741\n",
      "Ep. 5052 done, reward: -6.0, running_reward: -3.5460, time (sec): 57280.4442\n",
      "Ep. 5054 done, reward: 7.0, running_reward: -3.3164, time (sec): 57310.1074\n",
      "Ep. 5056 done, reward: -8.0, running_reward: -3.2809, time (sec): 57337.7536\n",
      "Ep. 5058 done, reward: -2.0, running_reward: -3.3445, time (sec): 57367.3080\n",
      "Ep. 5060 done, reward: -2.0, running_reward: -3.2088, time (sec): 57397.0829\n",
      "Ep. 5062 done, reward: -5.0, running_reward: -3.1356, time (sec): 57426.0247\n",
      "Ep. 5064 done, reward: 10.0, running_reward: -3.0227, time (sec): 57457.4468\n",
      "Ep. 5066 done, reward: 2.0, running_reward: -2.9128, time (sec): 57496.5775\n",
      "Ep. 5068 done, reward: 6.0, running_reward: -2.8642, time (sec): 57528.2296\n",
      "Ep. 5070 done, reward: -5.0, running_reward: -2.8968, time (sec): 57557.3858\n",
      "Ep. 5072 done, reward: 8.0, running_reward: -2.8086, time (sec): 57584.8634\n",
      "Ep. 5074 done, reward: -4.0, running_reward: -2.8125, time (sec): 57622.8646\n",
      "Ep. 5076 done, reward: -4.0, running_reward: -2.7174, time (sec): 57659.1322\n",
      "Ep. 5078 done, reward: -3.0, running_reward: -2.7725, time (sec): 57695.1001\n",
      "Ep. 5080 done, reward: -4.0, running_reward: -2.6979, time (sec): 57728.0801\n",
      "Ep. 5082 done, reward: 2.0, running_reward: -2.5945, time (sec): 57767.5499\n",
      "Ep. 5084 done, reward: -3.0, running_reward: -2.5630, time (sec): 57798.5669\n",
      "Ep. 5086 done, reward: 4.0, running_reward: -2.5215, time (sec): 57825.3579\n",
      "Ep. 5088 done, reward: -6.0, running_reward: -2.5610, time (sec): 57853.3879\n",
      "Ep. 5090 done, reward: -8.0, running_reward: -2.5999, time (sec): 57878.3408\n",
      "Ep. 5092 done, reward: 3.0, running_reward: -2.5083, time (sec): 57907.7557\n",
      "Ep. 5094 done, reward: -12.0, running_reward: -2.5091, time (sec): 57932.9515\n",
      "Ep. 5096 done, reward: -4.0, running_reward: -2.4497, time (sec): 57960.2660\n",
      "Ep. 5098 done, reward: -8.0, running_reward: -2.4512, time (sec): 57990.0207\n",
      "Ep. 5100 done, reward: 5.0, running_reward: -2.4217, time (sec): 58019.5308\n",
      "Ep. 5102 done, reward: -3.0, running_reward: -2.4530, time (sec): 58049.9559\n",
      "Ep. 5104 done, reward: -11.0, running_reward: -2.3855, time (sec): 58072.2124\n",
      "Ep. 5106 done, reward: 1.0, running_reward: -2.3875, time (sec): 58102.4509\n",
      "Ep. 5108 done, reward: 2.0, running_reward: -2.2704, time (sec): 58130.8219\n",
      "Ep. 5110 done, reward: 2.0, running_reward: -2.3340, time (sec): 58157.0022\n",
      "Ep. 5112 done, reward: 2.0, running_reward: -2.3566, time (sec): 58185.0445\n",
      "Ep. 5114 done, reward: -10.0, running_reward: -2.3998, time (sec): 58209.4461\n",
      "Ep. 5116 done, reward: -11.0, running_reward: -2.4918, time (sec): 58232.2803\n",
      "Ep. 5118 done, reward: -4.0, running_reward: -2.5020, time (sec): 58264.9658\n",
      "Ep. 5120 done, reward: 4.0, running_reward: -2.4815, time (sec): 58290.0105\n",
      "Ep. 5122 done, reward: 1.0, running_reward: -2.4617, time (sec): 58319.5850\n",
      "Ep. 5124 done, reward: -5.0, running_reward: -2.3340, time (sec): 58343.7739\n",
      "Ep. 5126 done, reward: -9.0, running_reward: -2.3578, time (sec): 58372.5236\n",
      "Ep. 5128 done, reward: -5.0, running_reward: -2.4203, time (sec): 58406.1023\n",
      "Ep. 5130 done, reward: -9.0, running_reward: -2.4720, time (sec): 58432.3760\n",
      "Ep. 5132 done, reward: 2.0, running_reward: -2.5018, time (sec): 58462.6214\n",
      "Ep. 5134 done, reward: -6.0, running_reward: -2.5318, time (sec): 58491.9943\n",
      "Ep. 5136 done, reward: -10.0, running_reward: -2.6705, time (sec): 58517.5537\n",
      "Ep. 5138 done, reward: 1.0, running_reward: -2.6965, time (sec): 58542.9800\n",
      "Ep. 5140 done, reward: 1.0, running_reward: -2.6427, time (sec): 58574.1656\n",
      "Ep. 5142 done, reward: -3.0, running_reward: -2.6102, time (sec): 58611.7364\n",
      "Ep. 5144 done, reward: -1.0, running_reward: -2.6673, time (sec): 58640.0452\n",
      "Ep. 5146 done, reward: 7.0, running_reward: -2.6333, time (sec): 58664.7039\n",
      "Ep. 5148 done, reward: 7.0, running_reward: -2.6000, time (sec): 58689.6538\n",
      "Ep. 5150 done, reward: 4.0, running_reward: -2.5776, time (sec): 58717.1957\n",
      "Ep. 5152 done, reward: 7.0, running_reward: -2.5058, time (sec): 58744.5129\n",
      "Ep. 5154 done, reward: -11.0, running_reward: -2.5758, time (sec): 58779.0366\n",
      "Ep. 5156 done, reward: -2.0, running_reward: -2.5743, time (sec): 58807.7252\n",
      "Ep. 5158 done, reward: 9.0, running_reward: -2.4231, time (sec): 58831.2002\n",
      "Ep. 5160 done, reward: -7.0, running_reward: -2.4350, time (sec): 58856.7360\n",
      "Ep. 5162 done, reward: 5.0, running_reward: -2.4355, time (sec): 58878.5000\n",
      "Ep. 5164 done, reward: 10.0, running_reward: -2.3069, time (sec): 58903.2474\n",
      "Ep. 5166 done, reward: 12.0, running_reward: -2.1113, time (sec): 58926.4280\n",
      "Ep. 5168 done, reward: -4.0, running_reward: -2.0301, time (sec): 58950.8990\n",
      "Ep. 5170 done, reward: -9.0, running_reward: -2.0698, time (sec): 58978.4562\n",
      "Ep. 5172 done, reward: -12.0, running_reward: -2.1882, time (sec): 59003.9569\n",
      "Ep. 5174 done, reward: -11.0, running_reward: -2.2942, time (sec): 59032.2126\n",
      "Ep. 5176 done, reward: -3.0, running_reward: -2.3578, time (sec): 59061.7870\n",
      "Ep. 5178 done, reward: -3.0, running_reward: -2.4399, time (sec): 59095.2068\n",
      "Ep. 5180 done, reward: -9.0, running_reward: -2.5605, time (sec): 59118.8201\n",
      "Ep. 5182 done, reward: -10.0, running_reward: -2.6788, time (sec): 59142.5063\n",
      "Ep. 5184 done, reward: 12.0, running_reward: -2.5253, time (sec): 59168.7200\n",
      "Ep. 5186 done, reward: 6.0, running_reward: -2.4646, time (sec): 59192.4462\n",
      "Ep. 5188 done, reward: 4.0, running_reward: -2.3458, time (sec): 59215.7222\n",
      "Ep. 5190 done, reward: 2.0, running_reward: -2.3584, time (sec): 59241.5607\n",
      "Ep. 5192 done, reward: -9.0, running_reward: -2.3717, time (sec): 59267.4225\n",
      "Ep. 5194 done, reward: -3.0, running_reward: -2.2753, time (sec): 59293.2349\n",
      "Ep. 5196 done, reward: 4.0, running_reward: -2.1306, time (sec): 59321.2658\n",
      "Ep. 5198 done, reward: 4.0, running_reward: -2.1175, time (sec): 59351.7096\n",
      "Ep. 5200 done, reward: -8.0, running_reward: -2.2247, time (sec): 59386.0585\n",
      "Ep. 5202 done, reward: -2.0, running_reward: -2.2895, time (sec): 59418.0944\n",
      "Ep. 5204 done, reward: 2.0, running_reward: -2.3329, time (sec): 59448.6468\n",
      "Ep. 5206 done, reward: -2.0, running_reward: -2.2372, time (sec): 59474.2694\n",
      "Ep. 5208 done, reward: 2.0, running_reward: -2.2221, time (sec): 59504.7570\n",
      "Ep. 5210 done, reward: -5.0, running_reward: -2.3269, time (sec): 59530.1032\n",
      "Ep. 5212 done, reward: 7.0, running_reward: -2.2799, time (sec): 59555.2580\n",
      "Ep. 5214 done, reward: -15.0, running_reward: -2.3944, time (sec): 59581.0656\n",
      "Ep. 5216 done, reward: -3.0, running_reward: -2.4659, time (sec): 59610.9999\n",
      "Ep. 5218 done, reward: 8.0, running_reward: -2.3863, time (sec): 59633.6410\n",
      "Ep. 5220 done, reward: -5.0, running_reward: -2.3690, time (sec): 59663.1475\n",
      "Ep. 5222 done, reward: 5.0, running_reward: -2.2818, time (sec): 59691.2486\n",
      "Ep. 5224 done, reward: -6.0, running_reward: -2.2073, time (sec): 59727.0241\n",
      "Ep. 5226 done, reward: -1.0, running_reward: -2.2229, time (sec): 59755.4674\n",
      "Ep. 5228 done, reward: -1.0, running_reward: -2.2579, time (sec): 59782.6527\n",
      "Ep. 5230 done, reward: -3.0, running_reward: -2.2826, time (sec): 59811.8798\n",
      "Ep. 5232 done, reward: 2.0, running_reward: -2.2469, time (sec): 59837.5447\n",
      "Ep. 5234 done, reward: 3.0, running_reward: -2.2414, time (sec): 59871.7822\n",
      "Ep. 5236 done, reward: -5.0, running_reward: -2.3359, time (sec): 59897.8448\n",
      "Ep. 5238 done, reward: -3.0, running_reward: -2.3789, time (sec): 59925.0591\n",
      "Ep. 5240 done, reward: 1.0, running_reward: -2.2324, time (sec): 59954.9702\n",
      "Ep. 5242 done, reward: -2.0, running_reward: -2.2476, time (sec): 59985.7171\n",
      "Ep. 5244 done, reward: 2.0, running_reward: -2.2423, time (sec): 60016.0114\n",
      "Ep. 5246 done, reward: -13.0, running_reward: -2.4068, time (sec): 60039.2000\n",
      "Ep. 5248 done, reward: 4.0, running_reward: -2.2694, time (sec): 60065.7662\n",
      "Ep. 5250 done, reward: 8.0, running_reward: -2.2730, time (sec): 60088.3897\n",
      "Ep. 5252 done, reward: -8.0, running_reward: -2.2880, time (sec): 60114.3017\n",
      "Ep. 5254 done, reward: -1.0, running_reward: -2.3415, time (sec): 60143.1809\n",
      "Ep. 5256 done, reward: 1.0, running_reward: -2.3047, time (sec): 60176.4514\n",
      "Ep. 5258 done, reward: 5.0, running_reward: -2.2386, time (sec): 60206.3265\n",
      "Ep. 5260 done, reward: -1.0, running_reward: -2.2238, time (sec): 60232.8236\n",
      "Ep. 5262 done, reward: 5.0, running_reward: -2.1593, time (sec): 60256.7281\n",
      "Ep. 5264 done, reward: 2.0, running_reward: -2.0468, time (sec): 60281.1641\n",
      "Ep. 5266 done, reward: 4.0, running_reward: -2.0552, time (sec): 60303.7010\n",
      "Ep. 5268 done, reward: 6.0, running_reward: -1.9939, time (sec): 60328.2486\n",
      "Ep. 5270 done, reward: 6.0, running_reward: -1.8546, time (sec): 60354.1934\n",
      "Ep. 5272 done, reward: -3.0, running_reward: -1.8873, time (sec): 60381.1785\n",
      "Ep. 5274 done, reward: -2.0, running_reward: -1.8499, time (sec): 60405.1164\n",
      "Ep. 5276 done, reward: -3.0, running_reward: -1.7738, time (sec): 60430.8748\n",
      "Ep. 5278 done, reward: -1.0, running_reward: -1.7980, time (sec): 60456.6942\n",
      "Ep. 5280 done, reward: -2.0, running_reward: -1.8515, time (sec): 60485.9046\n",
      "Ep. 5282 done, reward: -3.0, running_reward: -1.7853, time (sec): 60509.6904\n",
      "Ep. 5284 done, reward: 7.0, running_reward: -1.7887, time (sec): 60532.4983\n",
      "Ep. 5286 done, reward: 10.0, running_reward: -1.7026, time (sec): 60555.6883\n",
      "Ep. 5288 done, reward: -7.0, running_reward: -1.7783, time (sec): 60580.7577\n",
      "Ep. 5290 done, reward: 5.0, running_reward: -1.6038, time (sec): 60607.4355\n",
      "Ep. 5292 done, reward: -2.0, running_reward: -1.6216, time (sec): 60637.7968\n",
      "Ep. 5294 done, reward: 2.0, running_reward: -1.6782, time (sec): 60662.2336\n",
      "Ep. 5296 done, reward: -7.0, running_reward: -1.8435, time (sec): 60685.4905\n",
      "Ep. 5298 done, reward: -4.0, running_reward: -1.7973, time (sec): 60711.6760\n",
      "Ep. 5300 done, reward: 4.0, running_reward: -1.7909, time (sec): 60735.4661\n",
      "Ep. 5302 done, reward: 3.0, running_reward: -1.6856, time (sec): 60763.0429\n",
      "Ep. 5304 done, reward: 10.0, running_reward: -1.5620, time (sec): 60790.4155\n",
      "Ep. 5306 done, reward: -2.0, running_reward: -1.4915, time (sec): 60823.0992\n",
      "Ep. 5308 done, reward: -3.0, running_reward: -1.5314, time (sec): 60850.6213\n",
      "Ep. 5310 done, reward: -1.0, running_reward: -1.5208, time (sec): 60876.6060\n",
      "Ep. 5312 done, reward: 6.0, running_reward: -1.5395, time (sec): 60901.0774\n",
      "Ep. 5314 done, reward: -2.0, running_reward: -1.5882, time (sec): 60927.9132\n",
      "Ep. 5316 done, reward: -6.0, running_reward: -1.7651, time (sec): 60951.6875\n",
      "Ep. 5318 done, reward: -9.0, running_reward: -1.8794, time (sec): 60976.9475\n",
      "Ep. 5320 done, reward: -12.0, running_reward: -1.9224, time (sec): 61004.1132\n",
      "Ep. 5322 done, reward: -10.0, running_reward: -1.9644, time (sec): 61031.8279\n",
      "Ep. 5324 done, reward: 2.0, running_reward: -1.9548, time (sec): 61061.6177\n",
      "Ep. 5326 done, reward: -1.0, running_reward: -1.9655, time (sec): 61095.2417\n",
      "Ep. 5328 done, reward: 3.0, running_reward: -1.9656, time (sec): 61122.9105\n",
      "Ep. 5330 done, reward: 8.0, running_reward: -1.8960, time (sec): 61148.9904\n",
      "Ep. 5332 done, reward: -2.0, running_reward: -1.7892, time (sec): 61184.2226\n",
      "Ep. 5334 done, reward: -4.0, running_reward: -1.7243, time (sec): 61211.9589\n",
      "Ep. 5336 done, reward: 3.0, running_reward: -1.5907, time (sec): 61236.5189\n",
      "Ep. 5338 done, reward: 1.0, running_reward: -1.5589, time (sec): 61275.4286\n",
      "Ep. 5340 done, reward: -5.0, running_reward: -1.6472, time (sec): 61304.0405\n",
      "Ep. 5342 done, reward: 5.0, running_reward: -1.5842, time (sec): 61335.0876\n",
      "Ep. 5344 done, reward: 4.0, running_reward: -1.5424, time (sec): 61361.7980\n",
      "Ep. 5346 done, reward: 4.0, running_reward: -1.3925, time (sec): 61388.2960\n",
      "Ep. 5348 done, reward: -8.0, running_reward: -1.4745, time (sec): 61417.3736\n",
      "Ep. 5350 done, reward: -10.0, running_reward: -1.5749, time (sec): 61445.3351\n",
      "Ep. 5352 done, reward: -9.0, running_reward: -1.5543, time (sec): 61469.8549\n",
      "Ep. 5354 done, reward: -7.0, running_reward: -1.6231, time (sec): 61501.1152\n",
      "Ep. 5356 done, reward: -3.0, running_reward: -1.6307, time (sec): 61528.0932\n",
      "Ep. 5358 done, reward: 1.0, running_reward: -1.6377, time (sec): 61556.0333\n",
      "Ep. 5360 done, reward: 8.0, running_reward: -1.4558, time (sec): 61577.7686\n",
      "Ep. 5362 done, reward: -11.0, running_reward: -1.6458, time (sec): 61601.7554\n",
      "Ep. 5364 done, reward: 6.0, running_reward: -1.4441, time (sec): 61623.6289\n",
      "Ep. 5366 done, reward: 4.0, running_reward: -1.4051, time (sec): 61657.1238\n",
      "Ep. 5368 done, reward: -4.0, running_reward: -1.3775, time (sec): 61684.6728\n",
      "Ep. 5370 done, reward: -2.0, running_reward: -1.2810, time (sec): 61712.5561\n",
      "Ep. 5372 done, reward: 1.0, running_reward: -1.2554, time (sec): 61741.3057\n",
      "Ep. 5374 done, reward: 9.0, running_reward: -1.2691, time (sec): 61764.6382\n",
      "Ep. 5376 done, reward: -4.0, running_reward: -1.2641, time (sec): 61791.8968\n",
      "Ep. 5378 done, reward: -8.0, running_reward: -1.2496, time (sec): 61820.2283\n",
      "Ep. 5380 done, reward: -11.0, running_reward: -1.3051, time (sec): 61845.6868\n",
      "Ep. 5382 done, reward: 12.0, running_reward: -1.1690, time (sec): 61870.7836\n",
      "Ep. 5384 done, reward: 1.0, running_reward: -1.0565, time (sec): 61898.7364\n",
      "Ep. 5386 done, reward: -3.0, running_reward: -0.9764, time (sec): 61924.5038\n",
      "Ep. 5388 done, reward: -3.0, running_reward: -1.0068, time (sec): 61959.8895\n",
      "Ep. 5390 done, reward: -4.0, running_reward: -0.9475, time (sec): 61984.2920\n",
      "Ep. 5392 done, reward: -8.0, running_reward: -1.1176, time (sec): 62010.1607\n",
      "Ep. 5394 done, reward: -8.0, running_reward: -1.2743, time (sec): 62037.4394\n",
      "Ep. 5396 done, reward: -2.0, running_reward: -1.3185, time (sec): 62064.2473\n",
      "Ep. 5398 done, reward: -2.0, running_reward: -1.3914, time (sec): 62087.8760\n",
      "Ep. 5400 done, reward: -2.0, running_reward: -1.3540, time (sec): 62117.6378\n",
      "Ep. 5402 done, reward: -14.0, running_reward: -1.4176, time (sec): 62143.2914\n",
      "Ep. 5404 done, reward: -14.0, running_reward: -1.6185, time (sec): 62166.4696\n",
      "Ep. 5406 done, reward: -10.0, running_reward: -1.6665, time (sec): 62194.1712\n",
      "Ep. 5408 done, reward: 4.0, running_reward: -1.7319, time (sec): 62217.8983\n",
      "Ep. 5410 done, reward: -8.0, running_reward: -1.8270, time (sec): 62247.7124\n",
      "Ep. 5412 done, reward: -1.0, running_reward: -1.8600, time (sec): 62271.7016\n",
      "Ep. 5414 done, reward: 3.0, running_reward: -1.7138, time (sec): 62295.8305\n",
      "Ep. 5416 done, reward: -5.0, running_reward: -1.7099, time (sec): 62324.1190\n",
      "Ep. 5418 done, reward: -3.0, running_reward: -1.7752, time (sec): 62356.1055\n",
      "Ep. 5420 done, reward: -12.0, running_reward: -1.9093, time (sec): 62379.8530\n",
      "Ep. 5422 done, reward: -4.0, running_reward: -2.0301, time (sec): 62405.1699\n",
      "Ep. 5424 done, reward: 3.0, running_reward: -1.9399, time (sec): 62434.7972\n",
      "Ep. 5426 done, reward: 12.0, running_reward: -1.7714, time (sec): 62459.0329\n",
      "Ep. 5428 done, reward: -1.0, running_reward: -1.7165, time (sec): 62486.1452\n",
      "Ep. 5430 done, reward: -11.0, running_reward: -1.7527, time (sec): 62510.6808\n",
      "Ep. 5432 done, reward: 6.0, running_reward: -1.7469, time (sec): 62532.8300\n",
      "Ep. 5434 done, reward: -3.0, running_reward: -1.7620, time (sec): 62557.9263\n",
      "Ep. 5436 done, reward: -3.0, running_reward: -1.7866, time (sec): 62587.9171\n",
      "Ep. 5438 done, reward: 2.0, running_reward: -1.7410, time (sec): 62615.9203\n",
      "Ep. 5440 done, reward: -7.0, running_reward: -1.7664, time (sec): 62645.8299\n",
      "Ep. 5442 done, reward: -3.0, running_reward: -1.8306, time (sec): 62672.6877\n",
      "Ep. 5444 done, reward: 13.0, running_reward: -1.7235, time (sec): 62695.9357\n",
      "Ep. 5446 done, reward: 2.0, running_reward: -1.6791, time (sec): 62728.5805\n",
      "Ep. 5448 done, reward: 2.0, running_reward: -1.6653, time (sec): 62755.4643\n",
      "Ep. 5450 done, reward: 5.0, running_reward: -1.6218, time (sec): 62789.8946\n",
      "Ep. 5452 done, reward: 5.0, running_reward: -1.5296, time (sec): 62823.6228\n",
      "Ep. 5454 done, reward: -5.0, running_reward: -1.6185, time (sec): 62856.2729\n",
      "Ep. 5456 done, reward: -2.0, running_reward: -1.5667, time (sec): 62889.0727\n",
      "Ep. 5458 done, reward: -5.0, running_reward: -1.6251, time (sec): 62915.2910\n",
      "Ep. 5460 done, reward: 8.0, running_reward: -1.4731, time (sec): 62941.9350\n",
      "Ep. 5462 done, reward: -2.0, running_reward: -1.4044, time (sec): 62974.9926\n",
      "Ep. 5464 done, reward: -6.0, running_reward: -1.4662, time (sec): 63007.7693\n",
      "Ep. 5466 done, reward: -3.0, running_reward: -1.4076, time (sec): 63039.2113\n",
      "Ep. 5468 done, reward: -3.0, running_reward: -1.4393, time (sec): 63068.4855\n",
      "Ep. 5470 done, reward: 1.0, running_reward: -1.3413, time (sec): 63098.2635\n",
      "Ep. 5472 done, reward: -6.0, running_reward: -1.4340, time (sec): 63125.0860\n",
      "Ep. 5474 done, reward: -9.0, running_reward: -1.4657, time (sec): 63151.5510\n",
      "Ep. 5476 done, reward: 3.0, running_reward: -1.3571, time (sec): 63179.1886\n",
      "Ep. 5478 done, reward: -1.0, running_reward: -1.3005, time (sec): 63212.6399\n",
      "Ep. 5480 done, reward: -13.0, running_reward: -1.3551, time (sec): 63236.1681\n",
      "Ep. 5482 done, reward: 7.0, running_reward: -1.2185, time (sec): 63265.1433\n",
      "Ep. 5484 done, reward: 3.0, running_reward: -0.9960, time (sec): 63288.6360\n",
      "Ep. 5486 done, reward: 2.0, running_reward: -0.9462, time (sec): 63319.0224\n",
      "Ep. 5488 done, reward: -1.0, running_reward: -0.8384, time (sec): 63343.2747\n",
      "Ep. 5490 done, reward: 3.0, running_reward: -0.7224, time (sec): 63374.3949\n",
      "Ep. 5492 done, reward: 9.0, running_reward: -0.6675, time (sec): 63401.0776\n",
      "Ep. 5494 done, reward: -6.0, running_reward: -0.8034, time (sec): 63428.0028\n",
      "Ep. 5496 done, reward: -2.0, running_reward: -0.7282, time (sec): 63456.9155\n",
      "Ep. 5498 done, reward: -7.0, running_reward: -0.7342, time (sec): 63483.7992\n",
      "Ep. 5500 done, reward: -9.0, running_reward: -0.8195, time (sec): 63513.2543\n",
      "Ep. 5502 done, reward: -9.0, running_reward: -0.9625, time (sec): 63537.8280\n",
      "Ep. 5504 done, reward: -4.0, running_reward: -1.0526, time (sec): 63567.7386\n",
      "Ep. 5506 done, reward: -11.0, running_reward: -1.0724, time (sec): 63591.6159\n",
      "Ep. 5508 done, reward: -3.0, running_reward: -1.0117, time (sec): 63625.1478\n",
      "Ep. 5510 done, reward: 5.0, running_reward: -0.9911, time (sec): 63652.7677\n",
      "Ep. 5512 done, reward: 2.0, running_reward: -1.0801, time (sec): 63680.2200\n",
      "Ep. 5514 done, reward: 2.0, running_reward: -1.0485, time (sec): 63706.3156\n",
      "Ep. 5516 done, reward: -2.0, running_reward: -1.0773, time (sec): 63735.3147\n",
      "Ep. 5518 done, reward: -5.0, running_reward: -1.1950, time (sec): 63762.9927\n",
      "Ep. 5520 done, reward: -2.0, running_reward: -1.3001, time (sec): 63788.3092\n",
      "Ep. 5522 done, reward: -15.0, running_reward: -1.5628, time (sec): 63808.8652\n",
      "Ep. 5524 done, reward: -1.0, running_reward: -1.6902, time (sec): 63835.2940\n",
      "Ep. 5526 done, reward: -12.0, running_reward: -1.6677, time (sec): 63857.4913\n",
      "Ep. 5528 done, reward: 1.0, running_reward: -1.6938, time (sec): 63886.7167\n",
      "Ep. 5530 done, reward: -3.0, running_reward: -1.7792, time (sec): 63913.2436\n",
      "Ep. 5532 done, reward: 3.0, running_reward: -1.7039, time (sec): 63942.1552\n",
      "Ep. 5534 done, reward: 7.0, running_reward: -1.6891, time (sec): 63964.6641\n",
      "Ep. 5536 done, reward: -3.0, running_reward: -1.6459, time (sec): 63989.1258\n",
      "Ep. 5538 done, reward: 2.0, running_reward: -1.5634, time (sec): 64012.9335\n",
      "Ep. 5540 done, reward: -1.0, running_reward: -1.5621, time (sec): 64041.8340\n",
      "Ep. 5542 done, reward: -1.0, running_reward: -1.6400, time (sec): 64066.1390\n",
      "Ep. 5544 done, reward: -11.0, running_reward: -1.6481, time (sec): 64089.5987\n",
      "Ep. 5546 done, reward: -7.0, running_reward: -1.6160, time (sec): 64114.6802\n",
      "Ep. 5548 done, reward: 1.0, running_reward: -1.6827, time (sec): 64142.5059\n",
      "Ep. 5550 done, reward: -13.0, running_reward: -1.7891, time (sec): 64167.1530\n",
      "Ep. 5552 done, reward: -1.0, running_reward: -1.8130, time (sec): 64194.2422\n",
      "Ep. 5554 done, reward: -4.0, running_reward: -1.8467, time (sec): 64222.4170\n",
      "Ep. 5556 done, reward: 4.0, running_reward: -1.7006, time (sec): 64246.7052\n",
      "Ep. 5558 done, reward: -5.0, running_reward: -1.7663, time (sec): 64280.5044\n",
      "Ep. 5560 done, reward: -3.0, running_reward: -1.7413, time (sec): 64307.6968\n",
      "Ep. 5562 done, reward: -1.0, running_reward: -1.7563, time (sec): 64333.1063\n",
      "Ep. 5564 done, reward: 2.0, running_reward: -1.7409, time (sec): 64362.8392\n",
      "Ep. 5566 done, reward: -15.0, running_reward: -1.8662, time (sec): 64386.8725\n",
      "Ep. 5568 done, reward: -10.0, running_reward: -1.9092, time (sec): 64411.0139\n",
      "Ep. 5570 done, reward: 2.0, running_reward: -1.8314, time (sec): 64438.8781\n",
      "Ep. 5572 done, reward: -5.0, running_reward: -1.8549, time (sec): 64466.6843\n",
      "Ep. 5574 done, reward: -1.0, running_reward: -1.8082, time (sec): 64493.0654\n",
      "Ep. 5576 done, reward: -2.0, running_reward: -1.8912, time (sec): 64520.8544\n",
      "Ep. 5578 done, reward: 9.0, running_reward: -1.8923, time (sec): 64542.8593\n",
      "Ep. 5580 done, reward: -8.0, running_reward: -1.9445, time (sec): 64570.2304\n",
      "Ep. 5582 done, reward: 7.0, running_reward: -1.7665, time (sec): 64595.0465\n",
      "Ep. 5584 done, reward: 1.0, running_reward: -1.8105, time (sec): 64619.7295\n",
      "Ep. 5586 done, reward: -2.0, running_reward: -1.6855, time (sec): 64643.6389\n",
      "Ep. 5588 done, reward: 5.0, running_reward: -1.4634, time (sec): 64662.6280\n",
      "Ep. 5590 done, reward: -8.0, running_reward: -1.5044, time (sec): 64685.7989\n",
      "Ep. 5592 done, reward: -15.0, running_reward: -1.5650, time (sec): 64710.5934\n",
      "Ep. 5594 done, reward: -12.0, running_reward: -1.6440, time (sec): 64734.5543\n",
      "Ep. 5596 done, reward: -11.0, running_reward: -1.7015, time (sec): 64761.1622\n",
      "Ep. 5598 done, reward: -5.0, running_reward: -1.7374, time (sec): 64790.6415\n",
      "Ep. 5600 done, reward: 13.0, running_reward: -1.5134, time (sec): 64810.6658\n",
      "Ep. 5602 done, reward: 1.0, running_reward: -1.5723, time (sec): 64836.9460\n",
      "Ep. 5604 done, reward: 3.0, running_reward: -1.4912, time (sec): 64864.4651\n",
      "Ep. 5606 done, reward: -5.0, running_reward: -1.6007, time (sec): 64888.8444\n",
      "Ep. 5608 done, reward: -2.0, running_reward: -1.4997, time (sec): 64914.0992\n",
      "Ep. 5610 done, reward: -5.0, running_reward: -1.5298, time (sec): 64941.7413\n",
      "Ep. 5612 done, reward: -1.0, running_reward: -1.5984, time (sec): 64968.0928\n",
      "Ep. 5614 done, reward: -2.0, running_reward: -1.5569, time (sec): 64995.6825\n",
      "Ep. 5616 done, reward: 3.0, running_reward: -1.5652, time (sec): 65017.7900\n",
      "Ep. 5618 done, reward: -3.0, running_reward: -1.5344, time (sec): 65045.7895\n",
      "Ep. 5620 done, reward: 1.0, running_reward: -1.5532, time (sec): 65073.9980\n",
      "Ep. 5622 done, reward: -4.0, running_reward: -1.5227, time (sec): 65100.5759\n",
      "Ep. 5624 done, reward: -1.0, running_reward: -1.4628, time (sec): 65128.6986\n",
      "Ep. 5626 done, reward: 4.0, running_reward: -1.3541, time (sec): 65156.8931\n",
      "Ep. 5628 done, reward: 1.0, running_reward: -1.2380, time (sec): 65180.7828\n",
      "Ep. 5630 done, reward: -5.0, running_reward: -1.2930, time (sec): 65207.1240\n",
      "Ep. 5632 done, reward: 7.0, running_reward: -1.2270, time (sec): 65233.6851\n",
      "Ep. 5634 done, reward: 2.0, running_reward: -1.2222, time (sec): 65258.6403\n",
      "Ep. 5636 done, reward: -11.0, running_reward: -1.4168, time (sec): 65279.7150\n",
      "Ep. 5638 done, reward: -3.0, running_reward: -1.3790, time (sec): 65305.8561\n",
      "Ep. 5640 done, reward: -3.0, running_reward: -1.3221, time (sec): 65331.2989\n",
      "Ep. 5642 done, reward: 4.0, running_reward: -1.2855, time (sec): 65356.8583\n",
      "Ep. 5644 done, reward: 10.0, running_reward: -1.2490, time (sec): 65379.2293\n",
      "Ep. 5646 done, reward: -9.0, running_reward: -1.3439, time (sec): 65401.3767\n",
      "Ep. 5648 done, reward: 9.0, running_reward: -1.1182, time (sec): 65421.0741\n",
      "Ep. 5650 done, reward: -3.0, running_reward: -1.1953, time (sec): 65448.3645\n",
      "Ep. 5652 done, reward: 13.0, running_reward: -1.0910, time (sec): 65472.3940\n",
      "Ep. 5654 done, reward: -4.0, running_reward: -1.1687, time (sec): 65502.0902\n",
      "Ep. 5656 done, reward: -6.0, running_reward: -1.3044, time (sec): 65526.0131\n",
      "Ep. 5658 done, reward: 1.0, running_reward: -1.2982, time (sec): 65550.6227\n",
      "Ep. 5660 done, reward: 3.0, running_reward: -1.3512, time (sec): 65574.6095\n",
      "Ep. 5662 done, reward: 2.0, running_reward: -1.3539, time (sec): 65603.9497\n",
      "Ep. 5664 done, reward: 5.0, running_reward: -1.2967, time (sec): 65630.7743\n",
      "Ep. 5666 done, reward: -3.0, running_reward: -1.1821, time (sec): 65653.8862\n",
      "Ep. 5668 done, reward: 11.0, running_reward: -1.0189, time (sec): 65677.9595\n",
      "Ep. 5670 done, reward: 2.0, running_reward: -0.8598, time (sec): 65701.3689\n",
      "Ep. 5672 done, reward: -9.0, running_reward: -0.9921, time (sec): 65726.8789\n",
      "Ep. 5674 done, reward: -1.0, running_reward: -0.9329, time (sec): 65756.6964\n",
      "Ep. 5676 done, reward: -7.0, running_reward: -1.0734, time (sec): 65780.6676\n",
      "Ep. 5678 done, reward: -2.0, running_reward: -1.1314, time (sec): 65811.1542\n",
      "Ep. 5680 done, reward: 11.0, running_reward: -0.9593, time (sec): 65836.6668\n",
      "Ep. 5682 done, reward: -7.0, running_reward: -1.0498, time (sec): 65861.9837\n",
      "Ep. 5684 done, reward: 7.0, running_reward: -0.9490, time (sec): 65887.9093\n",
      "Ep. 5686 done, reward: -6.0, running_reward: -1.0990, time (sec): 65910.2772\n",
      "Ep. 5688 done, reward: -7.0, running_reward: -1.2066, time (sec): 65934.3230\n",
      "Ep. 5690 done, reward: 15.0, running_reward: -1.1019, time (sec): 65954.5820\n",
      "Ep. 5692 done, reward: -10.0, running_reward: -1.1601, time (sec): 65982.3326\n",
      "Ep. 5694 done, reward: -7.0, running_reward: -1.2170, time (sec): 66008.0456\n",
      "Ep. 5696 done, reward: 1.0, running_reward: -1.2421, time (sec): 66036.0049\n",
      "Ep. 5698 done, reward: -2.0, running_reward: -1.2770, time (sec): 66064.8378\n",
      "Ep. 5700 done, reward: 2.0, running_reward: -1.2514, time (sec): 66095.7610\n",
      "Ep. 5702 done, reward: 4.0, running_reward: -1.2459, time (sec): 66120.4311\n",
      "Ep. 5704 done, reward: -12.0, running_reward: -1.3510, time (sec): 66143.7593\n",
      "Ep. 5706 done, reward: -1.0, running_reward: -1.4430, time (sec): 66169.8367\n",
      "Ep. 5708 done, reward: 3.0, running_reward: -1.3942, time (sec): 66198.4147\n",
      "Ep. 5710 done, reward: -4.0, running_reward: -1.4164, time (sec): 66223.1401\n",
      "Ep. 5712 done, reward: -8.0, running_reward: -1.5573, time (sec): 66247.4460\n",
      "Ep. 5714 done, reward: -15.0, running_reward: -1.7159, time (sec): 66270.0689\n",
      "Ep. 5716 done, reward: 7.0, running_reward: -1.6216, time (sec): 66297.1028\n",
      "Ep. 5718 done, reward: -1.0, running_reward: -1.7083, time (sec): 66321.4671\n",
      "Ep. 5720 done, reward: 5.0, running_reward: -1.7035, time (sec): 66344.2359\n",
      "Ep. 5722 done, reward: -11.0, running_reward: -1.6509, time (sec): 66362.6184\n",
      "Ep. 5724 done, reward: -2.0, running_reward: -1.7271, time (sec): 66390.1802\n",
      "Ep. 5726 done, reward: -11.0, running_reward: -1.8622, time (sec): 66414.9847\n",
      "Ep. 5728 done, reward: 1.0, running_reward: -1.8250, time (sec): 66443.6302\n",
      "Ep. 5730 done, reward: 1.0, running_reward: -1.6896, time (sec): 66469.2353\n",
      "Ep. 5732 done, reward: 3.0, running_reward: -1.5765, time (sec): 66495.5004\n",
      "Ep. 5734 done, reward: -5.0, running_reward: -1.6149, time (sec): 66525.9174\n",
      "Ep. 5736 done, reward: -5.0, running_reward: -1.7317, time (sec): 66550.2516\n",
      "Ep. 5738 done, reward: -1.0, running_reward: -1.7370, time (sec): 66577.2782\n",
      "Ep. 5740 done, reward: 1.0, running_reward: -1.6528, time (sec): 66602.7161\n",
      "Ep. 5742 done, reward: -10.0, running_reward: -1.7100, time (sec): 66631.9713\n",
      "Ep. 5744 done, reward: 6.0, running_reward: -1.6457, time (sec): 66658.9874\n",
      "Ep. 5746 done, reward: -4.0, running_reward: -1.6628, time (sec): 66689.1024\n",
      "Ep. 5748 done, reward: 4.0, running_reward: -1.5700, time (sec): 66714.9598\n",
      "Ep. 5750 done, reward: 12.0, running_reward: -1.5177, time (sec): 66737.9526\n",
      "Ep. 5752 done, reward: 4.0, running_reward: -1.4079, time (sec): 66764.6554\n",
      "Ep. 5754 done, reward: -3.0, running_reward: -1.2911, time (sec): 66790.9429\n",
      "Ep. 5756 done, reward: 1.0, running_reward: -1.2356, time (sec): 66819.5853\n",
      "Ep. 5758 done, reward: 7.0, running_reward: -1.2697, time (sec): 66841.5110\n",
      "Ep. 5760 done, reward: 8.0, running_reward: -1.2634, time (sec): 66866.9048\n",
      "Ep. 5762 done, reward: -3.0, running_reward: -1.4366, time (sec): 66885.5519\n",
      "Ep. 5764 done, reward: -11.0, running_reward: -1.4982, time (sec): 66907.3535\n",
      "Ep. 5766 done, reward: -5.0, running_reward: -1.4788, time (sec): 66933.1516\n",
      "Ep. 5768 done, reward: 4.0, running_reward: -1.4589, time (sec): 66961.4905\n",
      "Ep. 5770 done, reward: 11.0, running_reward: -1.4287, time (sec): 66984.0690\n",
      "Ep. 5772 done, reward: -8.0, running_reward: -1.4209, time (sec): 67006.0497\n",
      "Ep. 5774 done, reward: 5.0, running_reward: -1.4812, time (sec): 67030.2289\n",
      "Ep. 5776 done, reward: -1.0, running_reward: -1.4222, time (sec): 67058.5214\n",
      "Ep. 5778 done, reward: 5.0, running_reward: -1.3340, time (sec): 67088.5049\n",
      "Ep. 5780 done, reward: -12.0, running_reward: -1.4769, time (sec): 67114.5002\n",
      "Ep. 5782 done, reward: -5.0, running_reward: -1.5470, time (sec): 67142.5757\n",
      "Ep. 5784 done, reward: -5.0, running_reward: -1.5959, time (sec): 67169.4607\n",
      "Ep. 5786 done, reward: 11.0, running_reward: -1.5037, time (sec): 67194.6010\n",
      "Ep. 5788 done, reward: -9.0, running_reward: -1.6529, time (sec): 67222.0519\n",
      "Ep. 5790 done, reward: -5.0, running_reward: -1.5710, time (sec): 67248.0334\n",
      "Ep. 5792 done, reward: -7.0, running_reward: -1.6592, time (sec): 67272.7497\n",
      "Ep. 5794 done, reward: -5.0, running_reward: -1.5970, time (sec): 67297.2264\n",
      "Ep. 5796 done, reward: -3.0, running_reward: -1.6843, time (sec): 67322.2137\n",
      "Ep. 5798 done, reward: 6.0, running_reward: -1.6799, time (sec): 67347.7240\n",
      "Ep. 5800 done, reward: -3.0, running_reward: -1.6171, time (sec): 67374.1377\n",
      "Ep. 5802 done, reward: 3.0, running_reward: -1.6044, time (sec): 67396.9899\n",
      "Ep. 5804 done, reward: 5.0, running_reward: -1.6313, time (sec): 67420.6859\n",
      "Ep. 5806 done, reward: 2.0, running_reward: -1.5690, time (sec): 67448.7853\n",
      "Ep. 5808 done, reward: 1.0, running_reward: -1.5575, time (sec): 67475.9438\n",
      "Ep. 5810 done, reward: -1.0, running_reward: -1.5464, time (sec): 67505.0844\n",
      "Ep. 5812 done, reward: 3.0, running_reward: -1.4064, time (sec): 67533.8484\n",
      "Ep. 5814 done, reward: -4.0, running_reward: -1.4580, time (sec): 67562.3879\n",
      "Ep. 5816 done, reward: 9.0, running_reward: -1.3093, time (sec): 67585.5083\n",
      "Ep. 5818 done, reward: 1.0, running_reward: -1.3821, time (sec): 67609.2780\n",
      "Ep. 5820 done, reward: -9.0, running_reward: -1.4248, time (sec): 67634.7196\n",
      "Ep. 5822 done, reward: -8.0, running_reward: -1.3478, time (sec): 67656.0361\n",
      "Ep. 5824 done, reward: 3.0, running_reward: -1.3405, time (sec): 67688.2624\n",
      "Ep. 5826 done, reward: -1.0, running_reward: -1.2050, time (sec): 67713.6843\n",
      "Ep. 5828 done, reward: -6.0, running_reward: -1.2113, time (sec): 67741.1219\n",
      "Ep. 5830 done, reward: 2.0, running_reward: -1.2167, time (sec): 67768.1757\n",
      "Ep. 5832 done, reward: -1.0, running_reward: -1.2124, time (sec): 67792.6989\n",
      "Ep. 5834 done, reward: -2.0, running_reward: -1.1588, time (sec): 67816.8416\n",
      "Ep. 5836 done, reward: -1.0, running_reward: -1.0665, time (sec): 67845.7013\n",
      "Ep. 5838 done, reward: -8.0, running_reward: -1.1946, time (sec): 67868.7332\n",
      "Ep. 5840 done, reward: -1.0, running_reward: -1.2303, time (sec): 67894.8208\n",
      "Ep. 5842 done, reward: -3.0, running_reward: -1.2061, time (sec): 67921.3865\n",
      "Ep. 5844 done, reward: 1.0, running_reward: -1.2315, time (sec): 67950.0817\n",
      "Ep. 5846 done, reward: -9.0, running_reward: -1.2673, time (sec): 67974.1303\n",
      "Ep. 5848 done, reward: -3.0, running_reward: -1.3810, time (sec): 67998.5743\n",
      "Ep. 5850 done, reward: 8.0, running_reward: -1.2438, time (sec): 68021.5235\n",
      "Ep. 5852 done, reward: 11.0, running_reward: -1.1982, time (sec): 68045.1486\n",
      "Ep. 5854 done, reward: 7.0, running_reward: -0.9954, time (sec): 68066.0538\n",
      "Ep. 5856 done, reward: 6.0, running_reward: -0.9948, time (sec): 68090.0703\n",
      "Ep. 5858 done, reward: 8.0, running_reward: -1.0039, time (sec): 68115.2531\n",
      "Ep. 5860 done, reward: -7.0, running_reward: -0.9549, time (sec): 68136.6704\n",
      "Ep. 5862 done, reward: 8.0, running_reward: -0.7272, time (sec): 68157.0047\n",
      "Ep. 5864 done, reward: -12.0, running_reward: -0.7932, time (sec): 68180.7801\n",
      "Ep. 5866 done, reward: -9.0, running_reward: -0.8278, time (sec): 68203.5850\n",
      "Ep. 5868 done, reward: 1.0, running_reward: -0.8805, time (sec): 68228.5380\n",
      "Ep. 5870 done, reward: 9.0, running_reward: -0.7037, time (sec): 68251.3055\n",
      "Ep. 5872 done, reward: -3.0, running_reward: -0.7296, time (sec): 68280.0117\n",
      "Ep. 5874 done, reward: -9.0, running_reward: -0.7457, time (sec): 68299.3663\n",
      "Ep. 5876 done, reward: -7.0, running_reward: -0.8107, time (sec): 68328.1838\n",
      "Ep. 5878 done, reward: 11.0, running_reward: -0.7242, time (sec): 68358.8762\n",
      "Ep. 5880 done, reward: 9.0, running_reward: -0.6297, time (sec): 68388.7623\n",
      "Ep. 5882 done, reward: 8.0, running_reward: -0.6163, time (sec): 68411.1950\n",
      "Ep. 5884 done, reward: -3.0, running_reward: -0.5351, time (sec): 68438.0593\n",
      "Ep. 5886 done, reward: -9.0, running_reward: -0.7233, time (sec): 68457.6418\n",
      "Ep. 5888 done, reward: -5.0, running_reward: -0.9173, time (sec): 68482.1422\n",
      "Ep. 5890 done, reward: -1.0, running_reward: -1.0180, time (sec): 68510.6457\n",
      "Ep. 5892 done, reward: 6.0, running_reward: -0.9476, time (sec): 68542.5790\n",
      "Ep. 5894 done, reward: 15.0, running_reward: -0.8085, time (sec): 68566.1750\n",
      "Ep. 5896 done, reward: -5.0, running_reward: -0.8919, time (sec): 68594.0609\n",
      "Ep. 5898 done, reward: -7.0, running_reward: -0.9936, time (sec): 68619.4344\n",
      "Ep. 5900 done, reward: 3.0, running_reward: -0.9835, time (sec): 68647.2984\n",
      "Ep. 5902 done, reward: 13.0, running_reward: -0.7943, time (sec): 68669.9156\n",
      "Ep. 5904 done, reward: -4.0, running_reward: -0.8482, time (sec): 68697.9893\n",
      "Ep. 5906 done, reward: -7.0, running_reward: -0.8617, time (sec): 68721.5022\n",
      "Ep. 5908 done, reward: -7.0, running_reward: -0.8849, time (sec): 68747.5250\n",
      "Ep. 5910 done, reward: -3.0, running_reward: -0.9764, time (sec): 68773.7863\n",
      "Ep. 5912 done, reward: -2.0, running_reward: -0.9473, time (sec): 68804.4080\n",
      "Ep. 5914 done, reward: -5.0, running_reward: -0.9983, time (sec): 68829.8821\n",
      "Ep. 5916 done, reward: 6.0, running_reward: -0.9085, time (sec): 68853.1231\n",
      "Ep. 5918 done, reward: 14.0, running_reward: -0.8197, time (sec): 68873.6629\n",
      "Ep. 5920 done, reward: 7.0, running_reward: -0.7136, time (sec): 68898.3886\n",
      "Ep. 5922 done, reward: -7.0, running_reward: -0.6803, time (sec): 68924.6739\n",
      "Ep. 5924 done, reward: -7.0, running_reward: -0.7071, time (sec): 68950.1149\n",
      "Ep. 5926 done, reward: 8.0, running_reward: -0.6625, time (sec): 68973.3455\n",
      "Ep. 5928 done, reward: 7.0, running_reward: -0.6486, time (sec): 68996.8397\n",
      "Ep. 5930 done, reward: -4.0, running_reward: -0.6460, time (sec): 69024.7862\n",
      "Ep. 5932 done, reward: -3.0, running_reward: -0.5740, time (sec): 69046.1842\n",
      "Ep. 5934 done, reward: -3.0, running_reward: -0.6817, time (sec): 69070.4448\n",
      "Ep. 5936 done, reward: -5.0, running_reward: -0.6885, time (sec): 69102.6594\n",
      "Ep. 5938 done, reward: -3.0, running_reward: -0.6751, time (sec): 69133.0082\n",
      "Ep. 5940 done, reward: -7.0, running_reward: -0.8108, time (sec): 69154.2261\n",
      "Ep. 5942 done, reward: 3.0, running_reward: -0.7053, time (sec): 69177.0445\n",
      "Ep. 5944 done, reward: -4.0, running_reward: -0.7808, time (sec): 69203.1184\n",
      "Ep. 5946 done, reward: -12.0, running_reward: -0.7862, time (sec): 69224.2694\n",
      "Ep. 5948 done, reward: -14.0, running_reward: -1.0096, time (sec): 69246.7015\n",
      "Ep. 5950 done, reward: 3.0, running_reward: -1.0486, time (sec): 69270.9937\n",
      "Ep. 5952 done, reward: -10.0, running_reward: -1.1376, time (sec): 69300.0840\n",
      "Ep. 5954 done, reward: -13.0, running_reward: -1.2846, time (sec): 69323.7556\n",
      "Ep. 5956 done, reward: -13.0, running_reward: -1.4979, time (sec): 69348.6146\n",
      "Ep. 5958 done, reward: -2.0, running_reward: -1.4980, time (sec): 69377.0340\n",
      "Ep. 5960 done, reward: -1.0, running_reward: -1.6267, time (sec): 69402.9501\n",
      "Ep. 5962 done, reward: -5.0, running_reward: -1.6542, time (sec): 69430.3240\n",
      "Ep. 5964 done, reward: -7.0, running_reward: -1.7111, time (sec): 69456.7620\n",
      "Ep. 5966 done, reward: 1.0, running_reward: -1.8057, time (sec): 69477.9943\n",
      "Ep. 5968 done, reward: 14.0, running_reward: -1.7386, time (sec): 69496.2327\n",
      "Ep. 5970 done, reward: 3.0, running_reward: -1.5948, time (sec): 69521.5441\n",
      "Ep. 5972 done, reward: 6.0, running_reward: -1.5724, time (sec): 69545.9571\n",
      "Ep. 5974 done, reward: 12.0, running_reward: -1.4607, time (sec): 69569.6617\n",
      "Ep. 5976 done, reward: -4.0, running_reward: -1.3924, time (sec): 69594.4312\n",
      "Ep. 5978 done, reward: -5.0, running_reward: -1.3553, time (sec): 69616.9749\n",
      "Ep. 5980 done, reward: -11.0, running_reward: -1.4680, time (sec): 69644.3712\n",
      "Ep. 5982 done, reward: 6.0, running_reward: -1.4184, time (sec): 69672.0192\n",
      "Ep. 5984 done, reward: 4.0, running_reward: -1.2512, time (sec): 69692.4825\n",
      "Ep. 5986 done, reward: -6.0, running_reward: -1.3358, time (sec): 69718.6674\n",
      "Ep. 5988 done, reward: -11.0, running_reward: -1.4885, time (sec): 69744.4434\n",
      "Ep. 5990 done, reward: 5.0, running_reward: -1.4386, time (sec): 69773.5169\n",
      "Ep. 5992 done, reward: -8.0, running_reward: -1.4207, time (sec): 69797.3109\n",
      "Ep. 5994 done, reward: 4.0, running_reward: -1.4217, time (sec): 69823.5388\n",
      "Ep. 5996 done, reward: 3.0, running_reward: -1.4129, time (sec): 69852.1408\n",
      "Ep. 5998 done, reward: 3.0, running_reward: -1.4142, time (sec): 69876.7634\n",
      "Ep. 6000 done, reward: -13.0, running_reward: -1.4864, time (sec): 69900.8608\n",
      "Ep. 6002 done, reward: 6.0, running_reward: -1.4364, time (sec): 69927.7142\n",
      "Ep. 6004 done, reward: 5.0, running_reward: -1.3974, time (sec): 69956.4651\n",
      "Ep. 6006 done, reward: -10.0, running_reward: -1.5092, time (sec): 69983.5252\n",
      "Ep. 6008 done, reward: -3.0, running_reward: -1.5784, time (sec): 70010.1463\n",
      "Ep. 6010 done, reward: 5.0, running_reward: -1.5663, time (sec): 70036.5313\n",
      "Ep. 6012 done, reward: 5.0, running_reward: -1.4456, time (sec): 70060.5301\n",
      "Ep. 6014 done, reward: 1.0, running_reward: -1.4761, time (sec): 70088.9568\n",
      "Ep. 6016 done, reward: -7.0, running_reward: -1.5266, time (sec): 70116.4189\n",
      "Ep. 6018 done, reward: 5.0, running_reward: -1.4165, time (sec): 70142.5150\n",
      "Ep. 6020 done, reward: -6.0, running_reward: -1.5573, time (sec): 70170.3911\n",
      "Ep. 6022 done, reward: 3.0, running_reward: -1.4765, time (sec): 70193.5795\n",
      "Ep. 6024 done, reward: 8.0, running_reward: -1.3572, time (sec): 70220.1749\n",
      "Ep. 6026 done, reward: 3.0, running_reward: -1.4388, time (sec): 70244.9005\n",
      "Ep. 6028 done, reward: 13.0, running_reward: -1.3395, time (sec): 70268.0040\n",
      "Ep. 6030 done, reward: 3.0, running_reward: -1.3225, time (sec): 70295.3197\n",
      "Ep. 6032 done, reward: -6.0, running_reward: -1.3661, time (sec): 70323.6879\n",
      "Ep. 6034 done, reward: -4.0, running_reward: -1.3888, time (sec): 70354.4872\n",
      "Ep. 6036 done, reward: -5.0, running_reward: -1.5596, time (sec): 70378.5118\n",
      "Ep. 6038 done, reward: -6.0, running_reward: -1.6480, time (sec): 70401.5782\n",
      "Ep. 6040 done, reward: -7.0, running_reward: -1.7446, time (sec): 70430.1681\n",
      "Ep. 6042 done, reward: -3.0, running_reward: -1.7795, time (sec): 70466.9659\n",
      "Ep. 6044 done, reward: 4.0, running_reward: -1.6249, time (sec): 70500.2407\n",
      "Ep. 6046 done, reward: 1.0, running_reward: -1.6519, time (sec): 70529.5109\n",
      "Ep. 6048 done, reward: -7.0, running_reward: -1.7187, time (sec): 70564.8818\n",
      "Ep. 6050 done, reward: -6.0, running_reward: -1.7247, time (sec): 70593.3829\n",
      "Ep. 6052 done, reward: -5.0, running_reward: -1.7602, time (sec): 70622.9724\n",
      "Ep. 6054 done, reward: 8.0, running_reward: -1.7738, time (sec): 70647.7463\n",
      "Ep. 6056 done, reward: -11.0, running_reward: -1.7891, time (sec): 70673.2335\n",
      "Ep. 6058 done, reward: 7.0, running_reward: -1.8122, time (sec): 70693.9655\n",
      "Ep. 6060 done, reward: -1.0, running_reward: -1.7961, time (sec): 70723.1296\n",
      "Ep. 6062 done, reward: -6.0, running_reward: -1.8599, time (sec): 70754.2807\n",
      "Ep. 6064 done, reward: 5.0, running_reward: -1.7234, time (sec): 70781.3934\n",
      "Ep. 6066 done, reward: -1.0, running_reward: -1.7882, time (sec): 70810.3388\n",
      "Ep. 6068 done, reward: -11.0, running_reward: -1.8923, time (sec): 70833.3590\n",
      "Ep. 6070 done, reward: -6.0, running_reward: -1.9939, time (sec): 70860.3767\n",
      "Ep. 6072 done, reward: -1.0, running_reward: -1.9444, time (sec): 70892.0030\n",
      "Ep. 6074 done, reward: -7.0, running_reward: -2.0054, time (sec): 70916.2137\n",
      "Ep. 6076 done, reward: -1.0, running_reward: -2.1042, time (sec): 70940.7794\n",
      "Ep. 6078 done, reward: -8.0, running_reward: -2.2017, time (sec): 70966.3116\n",
      "Ep. 6080 done, reward: 4.0, running_reward: -2.1674, time (sec): 70990.3276\n",
      "Ep. 6082 done, reward: 6.0, running_reward: -2.0742, time (sec): 71017.0017\n",
      "Ep. 6084 done, reward: -6.0, running_reward: -2.2117, time (sec): 71044.4105\n",
      "Ep. 6086 done, reward: -4.0, running_reward: -2.2968, time (sec): 71071.7335\n",
      "Ep. 6088 done, reward: -3.0, running_reward: -2.2415, time (sec): 71097.6261\n",
      "Ep. 6090 done, reward: 7.0, running_reward: -2.0873, time (sec): 71125.5747\n",
      "Ep. 6092 done, reward: -6.0, running_reward: -2.0463, time (sec): 71155.4101\n",
      "Ep. 6094 done, reward: -3.0, running_reward: -2.0257, time (sec): 71192.3344\n",
      "Ep. 6096 done, reward: 6.0, running_reward: -1.8759, time (sec): 71222.6920\n",
      "Ep. 6098 done, reward: -9.0, running_reward: -1.8395, time (sec): 71250.4231\n",
      "Ep. 6100 done, reward: -6.0, running_reward: -1.8332, time (sec): 71283.3414\n",
      "Ep. 6102 done, reward: -9.0, running_reward: -1.8966, time (sec): 71317.8596\n",
      "Ep. 6104 done, reward: 5.0, running_reward: -1.8583, time (sec): 71345.6157\n",
      "Ep. 6106 done, reward: -6.0, running_reward: -1.9606, time (sec): 71373.6348\n",
      "Ep. 6108 done, reward: -3.0, running_reward: -1.9911, time (sec): 71403.5867\n",
      "Ep. 6110 done, reward: 3.0, running_reward: -1.8126, time (sec): 71430.3885\n",
      "Ep. 6112 done, reward: -10.0, running_reward: -1.8568, time (sec): 71456.3563\n",
      "Ep. 6114 done, reward: -11.0, running_reward: -1.9991, time (sec): 71477.8251\n",
      "Ep. 6116 done, reward: -6.0, running_reward: -2.1084, time (sec): 71501.3247\n",
      "Ep. 6118 done, reward: 8.0, running_reward: -2.0558, time (sec): 71529.1582\n",
      "Ep. 6120 done, reward: -5.0, running_reward: -2.1045, time (sec): 71567.6966\n",
      "Ep. 6122 done, reward: 6.0, running_reward: -2.1115, time (sec): 71591.7323\n",
      "Ep. 6124 done, reward: -5.0, running_reward: -2.0997, time (sec): 71620.0949\n",
      "Ep. 6126 done, reward: -3.0, running_reward: -2.0780, time (sec): 71652.5792\n",
      "Ep. 6128 done, reward: -7.0, running_reward: -2.0967, time (sec): 71677.9880\n",
      "Ep. 6130 done, reward: -12.0, running_reward: -2.1948, time (sec): 71705.3554\n",
      "Ep. 6132 done, reward: -3.0, running_reward: -2.2999, time (sec): 71731.6399\n",
      "Ep. 6134 done, reward: -3.0, running_reward: -2.3337, time (sec): 71758.4934\n",
      "Ep. 6136 done, reward: 3.0, running_reward: -2.3265, time (sec): 71784.3205\n",
      "Ep. 6138 done, reward: -1.0, running_reward: -2.3892, time (sec): 71811.3768\n",
      "Ep. 6140 done, reward: 3.0, running_reward: -2.3414, time (sec): 71833.3500\n",
      "Ep. 6142 done, reward: 7.0, running_reward: -2.2347, time (sec): 71857.4965\n",
      "Ep. 6144 done, reward: -1.0, running_reward: -2.2497, time (sec): 71885.4121\n",
      "Ep. 6146 done, reward: -7.0, running_reward: -2.2254, time (sec): 71908.5310\n",
      "Ep. 6148 done, reward: -12.0, running_reward: -2.4200, time (sec): 71925.9058\n",
      "Ep. 6150 done, reward: 2.0, running_reward: -2.4112, time (sec): 71949.9870\n",
      "Ep. 6152 done, reward: -11.0, running_reward: -2.3841, time (sec): 71969.6367\n",
      "Ep. 6154 done, reward: -5.0, running_reward: -2.3768, time (sec): 71997.0119\n",
      "Ep. 6156 done, reward: -5.0, running_reward: -2.3894, time (sec): 72019.6682\n",
      "Ep. 6158 done, reward: 11.0, running_reward: -2.2912, time (sec): 72042.0990\n",
      "Ep. 6160 done, reward: -11.0, running_reward: -2.3160, time (sec): 72062.8097\n",
      "Ep. 6162 done, reward: -2.0, running_reward: -2.3196, time (sec): 72091.8729\n",
      "Ep. 6164 done, reward: -13.0, running_reward: -2.4233, time (sec): 72119.4261\n",
      "Ep. 6166 done, reward: -11.0, running_reward: -2.5841, time (sec): 72140.7189\n",
      "Ep. 6168 done, reward: -6.0, running_reward: -2.7015, time (sec): 72166.2288\n",
      "Ep. 6170 done, reward: -8.0, running_reward: -2.7971, time (sec): 72190.4424\n",
      "Ep. 6172 done, reward: 6.0, running_reward: -2.7507, time (sec): 72215.2016\n",
      "Ep. 6174 done, reward: -4.0, running_reward: -2.7558, time (sec): 72243.8928\n",
      "Ep. 6176 done, reward: -11.0, running_reward: -2.9198, time (sec): 72269.5390\n",
      "Ep. 6178 done, reward: -8.0, running_reward: -2.8724, time (sec): 72298.7549\n",
      "Ep. 6180 done, reward: -12.0, running_reward: -3.0046, time (sec): 72331.9849\n",
      "Ep. 6182 done, reward: -1.0, running_reward: -2.9746, time (sec): 72363.0540\n",
      "Ep. 6184 done, reward: -6.0, running_reward: -2.9160, time (sec): 72393.0888\n",
      "Ep. 6186 done, reward: 4.0, running_reward: -2.8675, time (sec): 72420.4472\n",
      "Ep. 6188 done, reward: -7.0, running_reward: -2.9893, time (sec): 72444.0903\n",
      "Ep. 6190 done, reward: -2.0, running_reward: -3.0785, time (sec): 72471.1444\n",
      "Ep. 6192 done, reward: 1.0, running_reward: -3.0864, time (sec): 72504.9460\n",
      "Ep. 6194 done, reward: 6.0, running_reward: -2.9254, time (sec): 72533.2049\n",
      "Ep. 6196 done, reward: -1.0, running_reward: -2.9267, time (sec): 72564.2972\n",
      "Ep. 6198 done, reward: -3.0, running_reward: -2.8688, time (sec): 72593.0150\n",
      "Ep. 6200 done, reward: -6.0, running_reward: -2.9410, time (sec): 72627.1310\n",
      "Ep. 6202 done, reward: 9.0, running_reward: -2.8320, time (sec): 72654.9286\n",
      "Ep. 6204 done, reward: -4.0, running_reward: -2.7959, time (sec): 72681.8521\n",
      "Ep. 6206 done, reward: 3.0, running_reward: -2.8390, time (sec): 72709.4361\n",
      "Ep. 6208 done, reward: -12.0, running_reward: -2.9718, time (sec): 72734.0621\n",
      "Ep. 6210 done, reward: 4.0, running_reward: -2.8330, time (sec): 72761.0425\n",
      "Ep. 6212 done, reward: -4.0, running_reward: -2.8562, time (sec): 72787.9204\n",
      "Ep. 6214 done, reward: -3.0, running_reward: -2.8789, time (sec): 72815.4440\n",
      "Ep. 6216 done, reward: -5.0, running_reward: -2.8419, time (sec): 72844.7914\n",
      "Ep. 6218 done, reward: -6.0, running_reward: -2.8949, time (sec): 72870.5934\n",
      "Ep. 6220 done, reward: -7.0, running_reward: -2.9667, time (sec): 72897.2583\n",
      "Ep. 6222 done, reward: 1.0, running_reward: -2.9867, time (sec): 72923.9627\n",
      "Ep. 6224 done, reward: 6.0, running_reward: -2.9366, time (sec): 80144.3030\n",
      "Ep. 6226 done, reward: -6.0, running_reward: -3.0074, time (sec): 80177.9481\n",
      "Ep. 6228 done, reward: -7.0, running_reward: -3.0077, time (sec): 82388.6414\n",
      "Ep. 6230 done, reward: -7.0, running_reward: -3.0970, time (sec): 82501.0550\n",
      "Ep. 6232 done, reward: 5.0, running_reward: -3.0745, time (sec): 82537.2143\n",
      "Ep. 6234 done, reward: -8.0, running_reward: -3.1032, time (sec): 82568.8095\n",
      "Ep. 6236 done, reward: -6.0, running_reward: -3.0817, time (sec): 82598.9584\n",
      "Ep. 6238 done, reward: -3.0, running_reward: -3.0107, time (sec): 82624.8440\n",
      "Ep. 6240 done, reward: -7.0, running_reward: -3.1891, time (sec): 82647.8918\n",
      "Ep. 6242 done, reward: -4.0, running_reward: -3.2647, time (sec): 82676.6610\n",
      "Ep. 6244 done, reward: -5.0, running_reward: -3.3487, time (sec): 82702.7220\n",
      "Ep. 6246 done, reward: 6.0, running_reward: -3.0736, time (sec): 82727.1444\n",
      "Ep. 6248 done, reward: 2.0, running_reward: -3.0815, time (sec): 82752.6781\n",
      "Ep. 6250 done, reward: 6.0, running_reward: -2.9899, time (sec): 82780.1599\n",
      "Ep. 6252 done, reward: -13.0, running_reward: -2.9812, time (sec): 82803.6090\n",
      "Ep. 6254 done, reward: 3.0, running_reward: -2.8820, time (sec): 82829.1574\n",
      "Ep. 6256 done, reward: -4.0, running_reward: -2.8448, time (sec): 82854.1655\n",
      "Ep. 6258 done, reward: 13.0, running_reward: -2.6681, time (sec): 82878.4491\n",
      "Ep. 6260 done, reward: 1.0, running_reward: -2.5654, time (sec): 82906.2100\n",
      "Ep. 6262 done, reward: 4.0, running_reward: -2.4644, time (sec): 82933.4792\n",
      "Ep. 6264 done, reward: -2.0, running_reward: -2.3661, time (sec): 82959.9415\n",
      "Ep. 6266 done, reward: -7.0, running_reward: -2.4385, time (sec): 82984.2171\n",
      "Ep. 6268 done, reward: 9.0, running_reward: -2.3198, time (sec): 83006.9220\n",
      "Ep. 6270 done, reward: -3.0, running_reward: -2.4125, time (sec): 83033.7189\n",
      "Ep. 6272 done, reward: 3.0, running_reward: -2.4137, time (sec): 83059.7588\n",
      "Ep. 6274 done, reward: 2.0, running_reward: -2.2566, time (sec): 83082.6625\n",
      "Ep. 6276 done, reward: -4.0, running_reward: -2.3606, time (sec): 83110.3888\n",
      "Ep. 6278 done, reward: 2.0, running_reward: -2.2144, time (sec): 83136.9382\n",
      "Ep. 6280 done, reward: 1.0, running_reward: -2.1306, time (sec): 83166.2371\n",
      "Ep. 6282 done, reward: -5.0, running_reward: -2.0986, time (sec): 83197.4964\n",
      "Ep. 6284 done, reward: -3.0, running_reward: -2.1265, time (sec): 83229.1304\n",
      "Ep. 6286 done, reward: 4.0, running_reward: -1.9848, time (sec): 83254.9318\n",
      "Ep. 6288 done, reward: 6.0, running_reward: -1.9051, time (sec): 83287.6074\n",
      "Ep. 6290 done, reward: 10.0, running_reward: -1.7770, time (sec): 83311.2228\n",
      "Ep. 6292 done, reward: 10.0, running_reward: -1.5625, time (sec): 83333.8556\n",
      "Ep. 6294 done, reward: 1.0, running_reward: -1.5412, time (sec): 83365.2752\n",
      "Ep. 6296 done, reward: -6.0, running_reward: -1.6398, time (sec): 83395.6775\n",
      "Ep. 6298 done, reward: -6.0, running_reward: -1.7068, time (sec): 83426.3264\n",
      "Ep. 6300 done, reward: 6.0, running_reward: -1.5930, time (sec): 83456.7761\n",
      "Ep. 6302 done, reward: 7.0, running_reward: -1.5111, time (sec): 83485.6363\n",
      "Ep. 6304 done, reward: -1.0, running_reward: -1.5208, time (sec): 83515.2168\n",
      "Ep. 6306 done, reward: -4.0, running_reward: -1.5602, time (sec): 83540.8628\n",
      "Ep. 6308 done, reward: -5.0, running_reward: -1.6088, time (sec): 83569.0356\n",
      "Ep. 6310 done, reward: -6.0, running_reward: -1.7655, time (sec): 83606.2014\n",
      "Ep. 6312 done, reward: 7.0, running_reward: -1.6703, time (sec): 83635.0209\n",
      "Ep. 6314 done, reward: 1.0, running_reward: -1.7756, time (sec): 83662.3225\n",
      "Ep. 6316 done, reward: 11.0, running_reward: -1.5510, time (sec): 83690.8563\n",
      "Ep. 6318 done, reward: -4.0, running_reward: -1.6097, time (sec): 83720.2821\n",
      "Ep. 6320 done, reward: -5.0, running_reward: -1.6969, time (sec): 83747.7333\n",
      "Ep. 6322 done, reward: -3.0, running_reward: -1.7229, time (sec): 83782.0510\n",
      "Ep. 6324 done, reward: -13.0, running_reward: -1.7493, time (sec): 83812.2442\n",
      "Ep. 6326 done, reward: -10.0, running_reward: -1.8244, time (sec): 83847.3565\n",
      "Ep. 6328 done, reward: -3.0, running_reward: -1.9468, time (sec): 83874.9894\n",
      "Ep. 6330 done, reward: 11.0, running_reward: -1.6990, time (sec): 83898.3157\n",
      "Ep. 6332 done, reward: -1.0, running_reward: -1.6059, time (sec): 83936.3226\n",
      "Ep. 6334 done, reward: 8.0, running_reward: -1.5137, time (sec): 83977.8902\n",
      "Ep. 6336 done, reward: 8.0, running_reward: -1.4135, time (sec): 84010.3560\n",
      "Ep. 6338 done, reward: -10.0, running_reward: -1.5547, time (sec): 84041.9180\n",
      "Ep. 6340 done, reward: -15.0, running_reward: -1.7530, time (sec): 84073.6124\n",
      "Ep. 6342 done, reward: -3.0, running_reward: -1.6491, time (sec): 84096.7628\n",
      "Ep. 6344 done, reward: 4.0, running_reward: -1.6258, time (sec): 84131.5486\n",
      "Ep. 6346 done, reward: 4.0, running_reward: -1.4742, time (sec): 84170.0870\n",
      "Ep. 6348 done, reward: 1.0, running_reward: -1.4448, time (sec): 84208.0691\n",
      "Ep. 6350 done, reward: 8.0, running_reward: -1.4152, time (sec): 84238.8917\n",
      "Ep. 6352 done, reward: 4.0, running_reward: -1.4362, time (sec): 84272.6532\n",
      "Ep. 6354 done, reward: 10.0, running_reward: -1.3175, time (sec): 84315.6983\n",
      "Ep. 6356 done, reward: 5.0, running_reward: -1.1423, time (sec): 84344.0093\n",
      "Ep. 6358 done, reward: -1.0, running_reward: -1.0602, time (sec): 84381.1737\n",
      "Ep. 6360 done, reward: -9.0, running_reward: -1.1192, time (sec): 84413.3484\n",
      "Ep. 6362 done, reward: 3.0, running_reward: -0.9680, time (sec): 84444.5922\n",
      "Ep. 6364 done, reward: 2.0, running_reward: -0.8891, time (sec): 84476.3738\n",
      "Ep. 6366 done, reward: -11.0, running_reward: -1.0012, time (sec): 84506.1210\n",
      "Ep. 6368 done, reward: 3.0, running_reward: -1.0008, time (sec): 84537.1611\n",
      "Ep. 6370 done, reward: 4.0, running_reward: -0.8716, time (sec): 84561.6698\n",
      "Ep. 6372 done, reward: -10.0, running_reward: -0.9047, time (sec): 84593.0844\n",
      "Ep. 6374 done, reward: -1.0, running_reward: -0.8373, time (sec): 84622.6554\n",
      "Ep. 6376 done, reward: 5.0, running_reward: -0.7607, time (sec): 84654.6069\n",
      "Ep. 6378 done, reward: -3.0, running_reward: -0.8449, time (sec): 84687.5154\n",
      "Ep. 6380 done, reward: -1.0, running_reward: -0.9569, time (sec): 84717.1268\n",
      "Ep. 6382 done, reward: -8.0, running_reward: -1.0080, time (sec): 84744.3134\n",
      "Ep. 6384 done, reward: -2.0, running_reward: -0.9485, time (sec): 84776.2225\n",
      "Ep. 6386 done, reward: 1.0, running_reward: -0.9097, time (sec): 84807.6421\n",
      "Ep. 6388 done, reward: -6.0, running_reward: -1.0308, time (sec): 84836.6619\n",
      "Ep. 6390 done, reward: -14.0, running_reward: -1.1107, time (sec): 84861.5360\n",
      "Ep. 6392 done, reward: 9.0, running_reward: -0.9491, time (sec): 84892.5136\n",
      "Ep. 6394 done, reward: -11.0, running_reward: -0.9610, time (sec): 84925.9808\n",
      "Ep. 6396 done, reward: 1.0, running_reward: -1.0309, time (sec): 84965.2187\n",
      "Ep. 6398 done, reward: -9.0, running_reward: -1.1103, time (sec): 85001.0520\n",
      "Ep. 6400 done, reward: -6.0, running_reward: -1.1779, time (sec): 85029.5661\n",
      "Ep. 6402 done, reward: 6.0, running_reward: -1.0449, time (sec): 85060.4551\n",
      "Ep. 6404 done, reward: -7.0, running_reward: -1.1931, time (sec): 85089.1861\n",
      "Ep. 6406 done, reward: -6.0, running_reward: -1.2492, time (sec): 85118.7246\n",
      "Ep. 6408 done, reward: 12.0, running_reward: -1.0944, time (sec): 85146.6111\n",
      "Ep. 6410 done, reward: 2.0, running_reward: -1.1418, time (sec): 85180.5487\n",
      "Ep. 6412 done, reward: -15.0, running_reward: -1.3482, time (sec): 85203.1907\n",
      "Ep. 6414 done, reward: -3.0, running_reward: -1.5098, time (sec): 85226.4068\n",
      "Ep. 6416 done, reward: -3.0, running_reward: -1.3910, time (sec): 85256.1862\n",
      "Ep. 6418 done, reward: 6.0, running_reward: -1.2934, time (sec): 85288.3398\n",
      "Ep. 6420 done, reward: 2.0, running_reward: -1.2377, time (sec): 85322.1908\n",
      "Ep. 6422 done, reward: -2.0, running_reward: -1.3222, time (sec): 85351.2931\n",
      "Ep. 6424 done, reward: 3.0, running_reward: -1.3352, time (sec): 85381.6689\n",
      "Ep. 6426 done, reward: -5.0, running_reward: -1.3982, time (sec): 85409.4851\n",
      "Ep. 6428 done, reward: -3.0, running_reward: -1.4796, time (sec): 85443.1253\n",
      "Ep. 6430 done, reward: -8.0, running_reward: -1.6193, time (sec): 85475.9307\n",
      "Ep. 6432 done, reward: 5.0, running_reward: -1.5568, time (sec): 85517.1610\n",
      "Ep. 6434 done, reward: -8.0, running_reward: -1.7247, time (sec): 85549.4384\n",
      "Ep. 6436 done, reward: 5.0, running_reward: -1.6304, time (sec): 85589.2026\n",
      "Ep. 6438 done, reward: 4.0, running_reward: -1.6075, time (sec): 85628.2258\n",
      "Ep. 6440 done, reward: -6.0, running_reward: -1.6454, time (sec): 85663.5401\n",
      "Ep. 6442 done, reward: -4.0, running_reward: -1.6923, time (sec): 85699.0487\n",
      "Ep. 6444 done, reward: -5.0, running_reward: -1.7482, time (sec): 85729.5296\n",
      "Ep. 6446 done, reward: -3.0, running_reward: -1.7335, time (sec): 85770.3160\n",
      "Ep. 6448 done, reward: 9.0, running_reward: -1.6882, time (sec): 85796.1447\n",
      "Ep. 6450 done, reward: -3.0, running_reward: -1.7242, time (sec): 85832.6160\n",
      "Ep. 6452 done, reward: 2.0, running_reward: -1.7392, time (sec): 85868.6968\n",
      "Ep. 6454 done, reward: -7.0, running_reward: -1.7548, time (sec): 85904.1211\n",
      "Ep. 6456 done, reward: 8.0, running_reward: -1.6795, time (sec): 85937.1887\n",
      "Ep. 6458 done, reward: -1.0, running_reward: -1.8045, time (sec): 85968.9116\n",
      "Ep. 6460 done, reward: -5.0, running_reward: -1.8087, time (sec): 86001.8962\n",
      "Ep. 6462 done, reward: -3.0, running_reward: -1.8918, time (sec): 86031.5963\n",
      "Ep. 6464 done, reward: -7.0, running_reward: -2.0430, time (sec): 86056.1769\n",
      "Ep. 6466 done, reward: -3.0, running_reward: -2.1016, time (sec): 86081.1091\n",
      "Ep. 6468 done, reward: -6.0, running_reward: -2.1297, time (sec): 86110.3341\n",
      "Ep. 6470 done, reward: -1.0, running_reward: -2.0478, time (sec): 86135.8830\n",
      "Ep. 6472 done, reward: -4.0, running_reward: -2.0075, time (sec): 86161.8621\n",
      "Ep. 6474 done, reward: -7.0, running_reward: -2.0870, time (sec): 86186.9759\n",
      "Ep. 6476 done, reward: -4.0, running_reward: -2.1350, time (sec): 86212.0958\n",
      "Ep. 6478 done, reward: 8.0, running_reward: -2.0422, time (sec): 86244.7733\n",
      "Ep. 6480 done, reward: -6.0, running_reward: -2.0715, time (sec): 86283.5372\n",
      "Ep. 6482 done, reward: -7.0, running_reward: -2.1695, time (sec): 86319.2906\n",
      "Ep. 6484 done, reward: 4.0, running_reward: -2.0567, time (sec): 86358.2969\n",
      "Ep. 6486 done, reward: -3.0, running_reward: -2.1150, time (sec): 86401.8720\n",
      "Ep. 6488 done, reward: 2.0, running_reward: -2.1124, time (sec): 86443.9937\n",
      "Ep. 6490 done, reward: -6.0, running_reward: -2.2194, time (sec): 86486.4515\n",
      "Ep. 6492 done, reward: 4.0, running_reward: -2.2046, time (sec): 86527.1692\n",
      "Ep. 6494 done, reward: -1.0, running_reward: -2.2598, time (sec): 86569.8603\n",
      "Ep. 6496 done, reward: 1.0, running_reward: -2.2444, time (sec): 86614.0040\n",
      "Ep. 6498 done, reward: 1.0, running_reward: -2.2393, time (sec): 86649.0171\n",
      "Ep. 6500 done, reward: -4.0, running_reward: -2.1654, time (sec): 86690.4918\n",
      "Ep. 6502 done, reward: -6.0, running_reward: -2.2120, time (sec): 86725.4268\n",
      "Ep. 6504 done, reward: -9.0, running_reward: -2.2481, time (sec): 86754.2437\n",
      "Ep. 6506 done, reward: -7.0, running_reward: -2.3624, time (sec): 86783.4658\n",
      "Ep. 6508 done, reward: -5.0, running_reward: -2.3060, time (sec): 86817.5113\n",
      "Ep. 6510 done, reward: -1.0, running_reward: -2.3691, time (sec): 86857.4129\n",
      "Ep. 6512 done, reward: -4.0, running_reward: -2.3521, time (sec): 86892.9917\n",
      "Ep. 6514 done, reward: -5.0, running_reward: -2.3751, time (sec): 86927.3280\n",
      "Ep. 6516 done, reward: 13.0, running_reward: -2.2077, time (sec): 86956.9979\n",
      "Ep. 6518 done, reward: -8.0, running_reward: -2.2933, time (sec): 86984.5876\n",
      "Ep. 6520 done, reward: -1.0, running_reward: -2.2082, time (sec): 87019.8885\n",
      "Ep. 6522 done, reward: 4.0, running_reward: -2.0153, time (sec): 87044.5165\n",
      "Ep. 6524 done, reward: -17.0, running_reward: -2.1650, time (sec): 87069.3184\n",
      "Ep. 6526 done, reward: 8.0, running_reward: -2.1112, time (sec): 87097.1556\n",
      "Ep. 6528 done, reward: 2.0, running_reward: -2.0987, time (sec): 87138.7037\n",
      "Ep. 6530 done, reward: 2.0, running_reward: -1.9379, time (sec): 87162.7629\n",
      "Ep. 6532 done, reward: -1.0, running_reward: -1.8203, time (sec): 87190.2563\n",
      "Ep. 6534 done, reward: -1.0, running_reward: -1.7545, time (sec): 87218.2536\n",
      "Ep. 6536 done, reward: -1.0, running_reward: -1.7196, time (sec): 87254.3855\n",
      "Ep. 6538 done, reward: 2.0, running_reward: -1.7446, time (sec): 87281.8364\n",
      "Ep. 6540 done, reward: -3.0, running_reward: -1.6310, time (sec): 87320.5888\n",
      "Ep. 6542 done, reward: 5.0, running_reward: -1.5881, time (sec): 87360.5205\n",
      "Ep. 6544 done, reward: 10.0, running_reward: -1.4763, time (sec): 87389.1869\n",
      "Ep. 6546 done, reward: -4.0, running_reward: -1.3880, time (sec): 87424.5262\n",
      "Ep. 6548 done, reward: 3.0, running_reward: -1.3204, time (sec): 87463.0853\n",
      "Ep. 6550 done, reward: -9.0, running_reward: -1.3545, time (sec): 87495.2020\n",
      "Ep. 6552 done, reward: -13.0, running_reward: -1.4773, time (sec): 87523.8910\n",
      "Ep. 6554 done, reward: 9.0, running_reward: -1.4767, time (sec): 87549.3513\n",
      "Ep. 6556 done, reward: -10.0, running_reward: -1.5572, time (sec): 87576.9856\n",
      "Ep. 6558 done, reward: -2.0, running_reward: -1.5759, time (sec): 87609.8632\n",
      "Ep. 6560 done, reward: -1.0, running_reward: -1.6635, time (sec): 87635.3569\n",
      "Ep. 6562 done, reward: 14.0, running_reward: -1.5300, time (sec): 87658.6635\n",
      "Ep. 6564 done, reward: 11.0, running_reward: -1.3994, time (sec): 87686.3393\n",
      "Ep. 6566 done, reward: -15.0, running_reward: -1.4820, time (sec): 87709.2884\n",
      "Ep. 6568 done, reward: -7.0, running_reward: -1.5918, time (sec): 87737.4010\n",
      "Ep. 6570 done, reward: -1.0, running_reward: -1.6592, time (sec): 87764.9055\n",
      "Ep. 6572 done, reward: 2.0, running_reward: -1.7349, time (sec): 87797.2698\n",
      "Ep. 6574 done, reward: -7.0, running_reward: -1.8991, time (sec): 87821.9414\n",
      "Ep. 6576 done, reward: 1.0, running_reward: -1.8414, time (sec): 87856.8195\n",
      "Ep. 6578 done, reward: 9.0, running_reward: -1.6751, time (sec): 87883.2672\n",
      "Ep. 6580 done, reward: 3.0, running_reward: -1.6316, time (sec): 87915.6920\n",
      "Ep. 6582 done, reward: -9.0, running_reward: -1.6000, time (sec): 87936.7272\n",
      "Ep. 6584 done, reward: 6.0, running_reward: -1.5379, time (sec): 87959.6568\n",
      "Ep. 6586 done, reward: -5.0, running_reward: -1.5870, time (sec): 87989.1702\n",
      "Ep. 6588 done, reward: -10.0, running_reward: -1.5762, time (sec): 88012.8691\n",
      "Ep. 6590 done, reward: 2.0, running_reward: -1.4456, time (sec): 88041.4075\n",
      "Ep. 6592 done, reward: 1.0, running_reward: -1.4960, time (sec): 88070.9136\n",
      "Ep. 6594 done, reward: -5.0, running_reward: -1.5855, time (sec): 88098.4701\n",
      "Ep. 6596 done, reward: -4.0, running_reward: -1.6236, time (sec): 88128.6635\n",
      "Ep. 6598 done, reward: 1.0, running_reward: -1.6506, time (sec): 88158.6505\n",
      "Ep. 6600 done, reward: 2.0, running_reward: -1.6077, time (sec): 88187.8002\n",
      "Ep. 6602 done, reward: -13.0, running_reward: -1.8245, time (sec): 88208.3182\n",
      "Ep. 6604 done, reward: -2.0, running_reward: -1.8775, time (sec): 88233.5473\n",
      "Ep. 6606 done, reward: 2.0, running_reward: -1.7904, time (sec): 88257.9049\n",
      "Ep. 6608 done, reward: 8.0, running_reward: -1.6946, time (sec): 88299.0164\n",
      "Ep. 6610 done, reward: -7.0, running_reward: -1.8002, time (sec): 88331.5937\n",
      "Ep. 6612 done, reward: 7.0, running_reward: -1.8231, time (sec): 88361.3725\n",
      "Ep. 6614 done, reward: 5.0, running_reward: -1.7764, time (sec): 88389.4849\n",
      "Ep. 6616 done, reward: -3.0, running_reward: -1.7809, time (sec): 88423.1787\n",
      "Ep. 6618 done, reward: 2.0, running_reward: -1.7552, time (sec): 88455.9662\n",
      "Ep. 6620 done, reward: 7.0, running_reward: -1.6206, time (sec): 88487.1107\n",
      "Ep. 6622 done, reward: -3.0, running_reward: -1.6282, time (sec): 88522.7135\n",
      "Ep. 6624 done, reward: 3.0, running_reward: -1.6054, time (sec): 88549.5106\n",
      "Ep. 6626 done, reward: -7.0, running_reward: -1.5841, time (sec): 88587.8686\n",
      "Ep. 6628 done, reward: 1.0, running_reward: -1.5722, time (sec): 88622.1268\n",
      "Ep. 6630 done, reward: 3.0, running_reward: -1.5208, time (sec): 88656.7143\n",
      "Ep. 6632 done, reward: -1.0, running_reward: -1.4610, time (sec): 88687.6653\n",
      "Ep. 6634 done, reward: -2.0, running_reward: -1.3628, time (sec): 88719.5587\n",
      "Ep. 6636 done, reward: 4.0, running_reward: -1.2858, time (sec): 88749.0724\n",
      "Ep. 6638 done, reward: -1.0, running_reward: -1.2603, time (sec): 88791.1163\n",
      "Ep. 6640 done, reward: 6.0, running_reward: -1.2445, time (sec): 88819.2110\n",
      "Ep. 6642 done, reward: -1.0, running_reward: -1.1902, time (sec): 88850.0665\n",
      "Ep. 6644 done, reward: 1.0, running_reward: -1.1070, time (sec): 88877.0584\n",
      "Ep. 6646 done, reward: -6.0, running_reward: -1.1845, time (sec): 88915.2426\n",
      "Ep. 6648 done, reward: -5.0, running_reward: -1.2704, time (sec): 88948.8138\n",
      "Ep. 6650 done, reward: 4.0, running_reward: -1.1655, time (sec): 88978.6327\n",
      "Ep. 6652 done, reward: 7.0, running_reward: -1.1020, time (sec): 89015.9316\n",
      "Ep. 6654 done, reward: -10.0, running_reward: -1.1900, time (sec): 89048.3318\n",
      "Ep. 6656 done, reward: -5.0, running_reward: -1.2262, time (sec): 89083.3319\n",
      "Ep. 6658 done, reward: 6.0, running_reward: -1.0131, time (sec): 89108.7508\n",
      "Ep. 6660 done, reward: -3.0, running_reward: -1.1318, time (sec): 89132.9108\n",
      "Ep. 6662 done, reward: -2.0, running_reward: -1.0402, time (sec): 89157.7770\n",
      "Ep. 6664 done, reward: 6.0, running_reward: -1.0585, time (sec): 89184.1273\n",
      "Ep. 6666 done, reward: -11.0, running_reward: -1.0385, time (sec): 89207.9266\n",
      "Ep. 6668 done, reward: 1.0, running_reward: -1.0574, time (sec): 89239.3940\n",
      "Ep. 6670 done, reward: 7.0, running_reward: -0.9960, time (sec): 89266.1651\n",
      "Ep. 6672 done, reward: 9.0, running_reward: -0.9753, time (sec): 89289.2965\n",
      "Ep. 6674 done, reward: -10.0, running_reward: -1.0955, time (sec): 89315.2397\n",
      "Ep. 6676 done, reward: -2.0, running_reward: -1.0541, time (sec): 89338.3080\n",
      "Ep. 6678 done, reward: -1.0, running_reward: -1.1520, time (sec): 89361.4887\n",
      "Ep. 6680 done, reward: 5.0, running_reward: -1.1286, time (sec): 89386.2416\n",
      "Ep. 6682 done, reward: 8.0, running_reward: -1.0954, time (sec): 89411.5225\n",
      "Ep. 6684 done, reward: 4.0, running_reward: -0.9346, time (sec): 89434.2501\n",
      "Ep. 6686 done, reward: 4.0, running_reward: -0.9651, time (sec): 89459.0127\n",
      "Ep. 6688 done, reward: -2.0, running_reward: -0.8867, time (sec): 89484.2145\n",
      "Ep. 6690 done, reward: 9.0, running_reward: -0.6999, time (sec): 89508.0717\n",
      "Ep. 6692 done, reward: -4.0, running_reward: -0.7062, time (sec): 89542.5480\n",
      "Ep. 6694 done, reward: -7.0, running_reward: -0.7918, time (sec): 89571.9913\n",
      "Ep. 6696 done, reward: -5.0, running_reward: -0.7864, time (sec): 89600.5220\n",
      "Ep. 6698 done, reward: -13.0, running_reward: -0.9107, time (sec): 89642.9287\n",
      "Ep. 6700 done, reward: 11.0, running_reward: -0.8321, time (sec): 89677.6139\n",
      "Ep. 6702 done, reward: 3.0, running_reward: -0.6865, time (sec): 89717.3310\n",
      "Ep. 6704 done, reward: -8.0, running_reward: -0.7925, time (sec): 89757.4290\n",
      "Ep. 6706 done, reward: -3.0, running_reward: -0.7176, time (sec): 89799.1935\n",
      "Ep. 6708 done, reward: -2.0, running_reward: -0.8718, time (sec): 89834.8963\n",
      "Ep. 6710 done, reward: 5.0, running_reward: -0.7451, time (sec): 89875.4455\n",
      "Ep. 6712 done, reward: -3.0, running_reward: -0.6414, time (sec): 89914.4668\n",
      "Ep. 6714 done, reward: -1.0, running_reward: -0.6585, time (sec): 89965.3952\n",
      "Ep. 6716 done, reward: 4.0, running_reward: -0.6747, time (sec): 90007.6793\n",
      "Ep. 6718 done, reward: 5.0, running_reward: -0.5320, time (sec): 90046.8935\n",
      "Ep. 6720 done, reward: -7.0, running_reward: -0.6112, time (sec): 90104.7464\n",
      "Ep. 6722 done, reward: 8.0, running_reward: -0.4993, time (sec): 90144.8629\n",
      "Ep. 6724 done, reward: -1.0, running_reward: -0.4202, time (sec): 90188.6703\n",
      "Ep. 6726 done, reward: -7.0, running_reward: -0.4224, time (sec): 90231.8032\n",
      "Ep. 6728 done, reward: -8.0, running_reward: -0.4742, time (sec): 90272.3107\n",
      "Ep. 6730 done, reward: 6.0, running_reward: -0.3453, time (sec): 90298.6061\n",
      "Ep. 6732 done, reward: 11.0, running_reward: -0.2186, time (sec): 90325.4748\n",
      "Ep. 6734 done, reward: -1.0, running_reward: -0.1153, time (sec): 90349.8755\n",
      "Ep. 6736 done, reward: -11.0, running_reward: -0.2824, time (sec): 90374.0655\n",
      "Ep. 6738 done, reward: 8.0, running_reward: -0.2463, time (sec): 90401.5973\n",
      "Ep. 6740 done, reward: 5.0, running_reward: -0.1122, time (sec): 90428.6855\n",
      "Ep. 6742 done, reward: 8.0, running_reward: -0.0597, time (sec): 90454.9232\n",
      "Ep. 6744 done, reward: 2.0, running_reward: 0.0011, time (sec): 90487.2089\n",
      "Ep. 6746 done, reward: -5.0, running_reward: -0.0390, time (sec): 90515.9370\n",
      "Ep. 6748 done, reward: -5.0, running_reward: -0.1179, time (sec): 90540.3946\n",
      "Ep. 6750 done, reward: -3.0, running_reward: -0.2149, time (sec): 90564.1507\n",
      "Ep. 6752 done, reward: -6.0, running_reward: -0.3102, time (sec): 90589.2354\n",
      "Ep. 6754 done, reward: -13.0, running_reward: -0.4637, time (sec): 90615.0720\n",
      "Ep. 6756 done, reward: -2.0, running_reward: -0.5735, time (sec): 90639.5569\n",
      "Ep. 6758 done, reward: -11.0, running_reward: -0.6622, time (sec): 90659.6469\n",
      "Ep. 6760 done, reward: -3.0, running_reward: -0.6196, time (sec): 90688.5440\n",
      "Ep. 6762 done, reward: 11.0, running_reward: -0.3884, time (sec): 90710.0906\n",
      "Ep. 6764 done, reward: 2.0, running_reward: -0.3706, time (sec): 90737.8061\n",
      "Ep. 6766 done, reward: 3.0, running_reward: -0.3431, time (sec): 90766.6565\n",
      "Ep. 6768 done, reward: -3.0, running_reward: -0.4059, time (sec): 90797.5204\n",
      "Ep. 6770 done, reward: -7.0, running_reward: -0.4579, time (sec): 90824.9759\n",
      "Ep. 6772 done, reward: 10.0, running_reward: -0.2696, time (sec): 90847.5910\n",
      "Ep. 6774 done, reward: 6.0, running_reward: -0.1547, time (sec): 90873.4342\n",
      "Ep. 6776 done, reward: 13.0, running_reward: 0.0081, time (sec): 90896.3662\n",
      "Ep. 6778 done, reward: -1.0, running_reward: -0.0318, time (sec): 90925.3266\n",
      "Ep. 6780 done, reward: -3.0, running_reward: -0.0018, time (sec): 90951.4706\n",
      "Ep. 6782 done, reward: -1.0, running_reward: 0.0576, time (sec): 90976.0633\n",
      "Ep. 6784 done, reward: -6.0, running_reward: -0.0234, time (sec): 91001.4845\n",
      "Ep. 6786 done, reward: -7.0, running_reward: -0.1028, time (sec): 91025.9664\n",
      "Ep. 6788 done, reward: -5.0, running_reward: -0.1607, time (sec): 91049.5279\n",
      "Ep. 6790 done, reward: -1.0, running_reward: -0.1972, time (sec): 91081.9394\n",
      "Ep. 6792 done, reward: 7.0, running_reward: -0.1925, time (sec): 91103.7162\n",
      "Ep. 6794 done, reward: 6.0, running_reward: -0.1584, time (sec): 91130.4341\n",
      "Ep. 6796 done, reward: 5.0, running_reward: 0.0630, time (sec): 91151.6462\n",
      "Ep. 6798 done, reward: -2.0, running_reward: 0.1111, time (sec): 91175.5627\n",
      "Ep. 6800 done, reward: 3.0, running_reward: 0.2280, time (sec): 91199.9351\n",
      "Ep. 6802 done, reward: 1.0, running_reward: 0.2631, time (sec): 91228.8352\n",
      "Ep. 6804 done, reward: 10.0, running_reward: 0.3678, time (sec): 91252.3224\n",
      "Ep. 6806 done, reward: -3.0, running_reward: 0.4295, time (sec): 91277.1375\n",
      "Ep. 6808 done, reward: 8.0, running_reward: 0.5999, time (sec): 91296.4976\n",
      "Ep. 6810 done, reward: -4.0, running_reward: 0.4985, time (sec): 91319.6454\n",
      "Ep. 6812 done, reward: -5.0, running_reward: 0.4683, time (sec): 91345.4019\n",
      "Ep. 6814 done, reward: -1.0, running_reward: 0.4688, time (sec): 91371.1836\n",
      "Ep. 6816 done, reward: 11.0, running_reward: 0.7080, time (sec): 91392.9315\n",
      "Ep. 6818 done, reward: 10.0, running_reward: 0.7642, time (sec): 91414.8583\n",
      "Ep. 6820 done, reward: 1.0, running_reward: 0.8085, time (sec): 91438.8209\n",
      "Ep. 6822 done, reward: 6.0, running_reward: 0.8821, time (sec): 91465.0353\n",
      "Ep. 6824 done, reward: 13.0, running_reward: 1.0837, time (sec): 91486.7775\n",
      "Ep. 6826 done, reward: 6.0, running_reward: 1.0726, time (sec): 91508.2251\n",
      "Ep. 6828 done, reward: -10.0, running_reward: 0.9612, time (sec): 91532.6064\n",
      "Ep. 6830 done, reward: 6.0, running_reward: 0.9130, time (sec): 91555.0054\n",
      "Ep. 6832 done, reward: 3.0, running_reward: 0.9446, time (sec): 91587.2950\n",
      "Ep. 6834 done, reward: -1.0, running_reward: 1.0247, time (sec): 91612.1273\n",
      "Ep. 6836 done, reward: 6.0, running_reward: 1.0841, time (sec): 91636.3040\n",
      "Ep. 6838 done, reward: 4.0, running_reward: 1.1718, time (sec): 91659.1304\n",
      "Ep. 6840 done, reward: 5.0, running_reward: 1.1094, time (sec): 91683.6441\n",
      "Ep. 6842 done, reward: -7.0, running_reward: 1.0965, time (sec): 91705.7560\n",
      "Ep. 6844 done, reward: -4.0, running_reward: 1.0050, time (sec): 91734.5620\n",
      "Ep. 6846 done, reward: -4.0, running_reward: 1.0737, time (sec): 91756.6022\n",
      "Ep. 6848 done, reward: 2.0, running_reward: 1.0030, time (sec): 91783.8641\n",
      "Ep. 6850 done, reward: 3.0, running_reward: 0.9240, time (sec): 91809.5637\n",
      "Ep. 6852 done, reward: 11.0, running_reward: 1.0057, time (sec): 91830.8269\n",
      "Ep. 6854 done, reward: 7.0, running_reward: 1.1250, time (sec): 91852.1201\n",
      "Ep. 6856 done, reward: 4.0, running_reward: 1.1030, time (sec): 91877.1037\n",
      "Ep. 6858 done, reward: -5.0, running_reward: 1.0409, time (sec): 91904.7799\n",
      "Ep. 6860 done, reward: -2.0, running_reward: 1.1190, time (sec): 91928.9043\n",
      "Ep. 6862 done, reward: -4.0, running_reward: 1.0766, time (sec): 91957.9448\n",
      "Ep. 6864 done, reward: 6.0, running_reward: 1.0458, time (sec): 91982.2449\n",
      "Ep. 6866 done, reward: 5.0, running_reward: 1.2136, time (sec): 92002.7696\n",
      "Ep. 6868 done, reward: 9.0, running_reward: 1.1904, time (sec): 92027.5902\n",
      "Ep. 6870 done, reward: 3.0, running_reward: 1.1175, time (sec): 92053.5136\n",
      "Ep. 6872 done, reward: -5.0, running_reward: 1.0155, time (sec): 92081.2957\n",
      "Ep. 6874 done, reward: -6.0, running_reward: 0.8462, time (sec): 92105.0829\n",
      "Ep. 6876 done, reward: 4.0, running_reward: 0.8496, time (sec): 92129.9182\n",
      "Ep. 6878 done, reward: -3.0, running_reward: 0.7334, time (sec): 92159.2544\n",
      "Ep. 6880 done, reward: 14.0, running_reward: 0.9974, time (sec): 92180.3071\n",
      "Ep. 6882 done, reward: 10.0, running_reward: 1.0280, time (sec): 92206.9399\n",
      "Ep. 6884 done, reward: -8.0, running_reward: 0.8781, time (sec): 92241.7032\n",
      "Ep. 6886 done, reward: -8.0, running_reward: 0.8301, time (sec): 92270.7992\n",
      "Ep. 6888 done, reward: -2.0, running_reward: 0.6748, time (sec): 92302.2886\n",
      "Ep. 6890 done, reward: 4.0, running_reward: 0.7311, time (sec): 92338.0560\n",
      "Ep. 6892 done, reward: -7.0, running_reward: 0.5574, time (sec): 92373.2997\n",
      "Ep. 6894 done, reward: -3.0, running_reward: 0.4767, time (sec): 92400.7932\n",
      "Ep. 6896 done, reward: 4.0, running_reward: 0.4973, time (sec): 92426.0831\n",
      "Ep. 6898 done, reward: 8.0, running_reward: 0.5179, time (sec): 92451.6382\n",
      "Ep. 6900 done, reward: 1.0, running_reward: 0.5374, time (sec): 92483.1128\n",
      "Ep. 6902 done, reward: -3.0, running_reward: 0.5363, time (sec): 92507.7538\n",
      "Ep. 6904 done, reward: 7.0, running_reward: 0.7046, time (sec): 92533.3747\n",
      "Ep. 6906 done, reward: -3.0, running_reward: 0.6902, time (sec): 92565.0333\n",
      "Ep. 6908 done, reward: 9.0, running_reward: 0.7467, time (sec): 92594.8406\n",
      "Ep. 6910 done, reward: 11.0, running_reward: 0.7429, time (sec): 92617.2864\n",
      "Ep. 6912 done, reward: -15.0, running_reward: 0.6078, time (sec): 92642.8420\n",
      "Ep. 6914 done, reward: -3.0, running_reward: 0.6152, time (sec): 92680.2461\n",
      "Ep. 6916 done, reward: 3.0, running_reward: 0.6527, time (sec): 92709.4901\n",
      "Ep. 6918 done, reward: 7.0, running_reward: 0.6800, time (sec): 92736.9303\n",
      "Ep. 6920 done, reward: 1.0, running_reward: 0.6369, time (sec): 92767.6945\n",
      "Ep. 6922 done, reward: 9.0, running_reward: 0.7736, time (sec): 92800.4738\n",
      "Ep. 6924 done, reward: 8.0, running_reward: 0.9273, time (sec): 92826.4963\n",
      "Ep. 6926 done, reward: 3.0, running_reward: 1.0082, time (sec): 92856.6266\n",
      "Ep. 6928 done, reward: 4.0, running_reward: 1.1370, time (sec): 92880.2773\n",
      "Ep. 6930 done, reward: 3.0, running_reward: 1.1147, time (sec): 92909.4585\n",
      "Ep. 6932 done, reward: 8.0, running_reward: 1.2220, time (sec): 92935.2259\n",
      "Ep. 6934 done, reward: -3.0, running_reward: 1.2469, time (sec): 92961.6021\n",
      "Ep. 6936 done, reward: -1.0, running_reward: 1.1230, time (sec): 92985.1865\n",
      "Ep. 6938 done, reward: -16.0, running_reward: 1.0693, time (sec): 93003.5104\n",
      "Ep. 6940 done, reward: -14.0, running_reward: 0.9972, time (sec): 93033.3484\n",
      "Ep. 6942 done, reward: 2.0, running_reward: 1.0666, time (sec): 93067.0465\n",
      "Ep. 6944 done, reward: -6.0, running_reward: 0.8963, time (sec): 93094.3535\n",
      "Ep. 6946 done, reward: 7.0, running_reward: 1.0079, time (sec): 93119.5072\n",
      "Ep. 6948 done, reward: -4.0, running_reward: 0.9181, time (sec): 93148.1453\n",
      "Ep. 6950 done, reward: -5.0, running_reward: 0.8993, time (sec): 93174.8409\n",
      "Ep. 6952 done, reward: 11.0, running_reward: 0.9518, time (sec): 93196.8953\n",
      "Ep. 6954 done, reward: 10.0, running_reward: 1.1616, time (sec): 93216.2955\n",
      "Ep. 6956 done, reward: 9.0, running_reward: 1.1790, time (sec): 93237.3948\n",
      "Ep. 6958 done, reward: 3.0, running_reward: 1.2350, time (sec): 93262.7963\n",
      "Ep. 6960 done, reward: -11.0, running_reward: 1.0014, time (sec): 93284.8389\n",
      "Ep. 6962 done, reward: 13.0, running_reward: 1.2501, time (sec): 93301.7829\n",
      "Ep. 6964 done, reward: -2.0, running_reward: 1.3042, time (sec): 93326.6272\n",
      "Ep. 6966 done, reward: -3.0, running_reward: 1.3176, time (sec): 93356.1829\n",
      "Ep. 6968 done, reward: 7.0, running_reward: 1.4802, time (sec): 93381.2364\n",
      "Ep. 6970 done, reward: -5.0, running_reward: 1.4799, time (sec): 93404.7903\n",
      "Ep. 6972 done, reward: 7.0, running_reward: 1.4907, time (sec): 93432.5285\n",
      "Ep. 6974 done, reward: -5.0, running_reward: 1.4012, time (sec): 93457.7255\n",
      "Ep. 6976 done, reward: 8.0, running_reward: 1.4830, time (sec): 93482.9426\n",
      "Ep. 6978 done, reward: -6.0, running_reward: 1.3737, time (sec): 93510.6601\n",
      "Ep. 6980 done, reward: 5.0, running_reward: 1.2974, time (sec): 93531.2697\n",
      "Ep. 6982 done, reward: -1.0, running_reward: 1.3803, time (sec): 93554.5564\n",
      "Ep. 6984 done, reward: -7.0, running_reward: 1.4017, time (sec): 93578.8553\n",
      "Ep. 6986 done, reward: -3.0, running_reward: 1.3735, time (sec): 93606.3399\n",
      "Ep. 6988 done, reward: -8.0, running_reward: 1.1572, time (sec): 93630.5274\n",
      "Ep. 6990 done, reward: -3.0, running_reward: 1.1141, time (sec): 93657.3045\n",
      "Ep. 6992 done, reward: -7.0, running_reward: 1.0021, time (sec): 93683.0484\n",
      "Ep. 6994 done, reward: -6.0, running_reward: 1.0113, time (sec): 93706.3902\n",
      "Ep. 6996 done, reward: -3.0, running_reward: 1.0602, time (sec): 93730.1805\n",
      "Ep. 6998 done, reward: -5.0, running_reward: 1.0188, time (sec): 93758.3643\n",
      "Ep. 7000 done, reward: -15.0, running_reward: 0.8881, time (sec): 93779.1339\n",
      "Ep. 7002 done, reward: -7.0, running_reward: 0.6519, time (sec): 93801.1766\n",
      "Ep. 7004 done, reward: -4.0, running_reward: 0.7079, time (sec): 93822.6112\n",
      "Ep. 7006 done, reward: 7.0, running_reward: 0.7539, time (sec): 93846.6887\n",
      "Ep. 7008 done, reward: 3.0, running_reward: 0.7194, time (sec): 93871.6827\n",
      "Ep. 7010 done, reward: -3.0, running_reward: 0.7642, time (sec): 93895.2647\n",
      "Ep. 7012 done, reward: 4.0, running_reward: 0.7493, time (sec): 93924.1697\n",
      "Ep. 7014 done, reward: 8.0, running_reward: 0.8045, time (sec): 93950.7120\n",
      "Ep. 7016 done, reward: -3.0, running_reward: 0.7288, time (sec): 93980.2633\n",
      "Ep. 7018 done, reward: 2.0, running_reward: 0.7244, time (sec): 94007.0587\n",
      "Ep. 7020 done, reward: -1.0, running_reward: 0.7396, time (sec): 94033.6696\n",
      "Ep. 7022 done, reward: 12.0, running_reward: 0.8845, time (sec): 94057.2111\n",
      "Ep. 7024 done, reward: 4.0, running_reward: 0.8970, time (sec): 94083.7738\n",
      "Ep. 7026 done, reward: 7.0, running_reward: 0.9194, time (sec): 94111.0779\n",
      "Ep. 7028 done, reward: -7.0, running_reward: 0.8212, time (sec): 94138.9154\n",
      "Ep. 7030 done, reward: 8.0, running_reward: 0.9245, time (sec): 94161.3743\n",
      "Ep. 7032 done, reward: 13.0, running_reward: 1.0757, time (sec): 94183.7175\n",
      "Ep. 7034 done, reward: -9.0, running_reward: 0.9940, time (sec): 94210.7209\n",
      "Ep. 7036 done, reward: -5.0, running_reward: 0.9341, time (sec): 94240.2788\n",
      "Ep. 7038 done, reward: -5.0, running_reward: 0.9744, time (sec): 94261.6814\n",
      "Ep. 7040 done, reward: 1.0, running_reward: 0.8858, time (sec): 94286.5556\n",
      "Ep. 7042 done, reward: 6.0, running_reward: 0.9678, time (sec): 94313.1509\n",
      "Ep. 7044 done, reward: -3.0, running_reward: 0.8987, time (sec): 94343.1261\n",
      "Ep. 7046 done, reward: 7.0, running_reward: 0.8816, time (sec): 94369.4809\n",
      "Ep. 7048 done, reward: 5.0, running_reward: 0.9041, time (sec): 94393.6589\n",
      "Ep. 7050 done, reward: -10.0, running_reward: 0.8554, time (sec): 94416.9092\n",
      "Ep. 7052 done, reward: 5.0, running_reward: 0.8686, time (sec): 94442.6021\n",
      "Ep. 7054 done, reward: -1.0, running_reward: 0.7621, time (sec): 94467.2128\n",
      "Ep. 7056 done, reward: 8.0, running_reward: 0.8962, time (sec): 94489.8674\n",
      "Ep. 7058 done, reward: 6.0, running_reward: 1.1067, time (sec): 94512.1805\n",
      "Ep. 7060 done, reward: 5.0, running_reward: 1.0654, time (sec): 94538.4487\n",
      "Ep. 7062 done, reward: 5.0, running_reward: 1.0348, time (sec): 94566.0484\n",
      "Ep. 7064 done, reward: -2.0, running_reward: 1.1031, time (sec): 94592.5219\n",
      "Ep. 7066 done, reward: -7.0, running_reward: 1.1200, time (sec): 94614.4947\n",
      "Ep. 7068 done, reward: 5.0, running_reward: 1.1577, time (sec): 94640.4374\n",
      "Ep. 7070 done, reward: 13.0, running_reward: 1.2943, time (sec): 94661.2683\n",
      "Ep. 7072 done, reward: 7.0, running_reward: 1.2396, time (sec): 94683.6384\n",
      "Ep. 7074 done, reward: -4.0, running_reward: 1.1650, time (sec): 94712.0067\n",
      "Ep. 7076 done, reward: -5.0, running_reward: 1.1215, time (sec): 94736.0309\n",
      "Ep. 7078 done, reward: 2.0, running_reward: 1.0895, time (sec): 94763.3810\n",
      "Ep. 7080 done, reward: 3.0, running_reward: 1.1473, time (sec): 94788.0524\n",
      "Ep. 7082 done, reward: 5.0, running_reward: 1.2240, time (sec): 94815.4103\n",
      "Ep. 7084 done, reward: 6.0, running_reward: 1.2893, time (sec): 94839.0880\n",
      "Ep. 7086 done, reward: -1.0, running_reward: 1.2834, time (sec): 94867.5370\n",
      "Ep. 7088 done, reward: 9.0, running_reward: 1.3577, time (sec): 94890.8827\n",
      "Ep. 7090 done, reward: -7.0, running_reward: 1.3300, time (sec): 94917.0280\n",
      "Ep. 7092 done, reward: -5.0, running_reward: 1.3030, time (sec): 94943.5143\n",
      "Ep. 7094 done, reward: -1.0, running_reward: 1.2176, time (sec): 94970.3987\n",
      "Ep. 7096 done, reward: -5.0, running_reward: 1.1335, time (sec): 94995.6636\n",
      "Ep. 7098 done, reward: 8.0, running_reward: 1.1612, time (sec): 95023.1391\n",
      "Ep. 7100 done, reward: 2.0, running_reward: 1.1383, time (sec): 95052.3615\n",
      "Ep. 7102 done, reward: -1.0, running_reward: 1.0562, time (sec): 95078.8911\n",
      "Ep. 7104 done, reward: -1.0, running_reward: 0.9261, time (sec): 95100.9539\n",
      "Ep. 7106 done, reward: -3.0, running_reward: 0.8183, time (sec): 95126.2967\n",
      "Ep. 7108 done, reward: -2.0, running_reward: 0.7325, time (sec): 95155.0708\n",
      "Ep. 7110 done, reward: 7.0, running_reward: 0.7385, time (sec): 95177.9230\n",
      "Ep. 7112 done, reward: -8.0, running_reward: 0.7230, time (sec): 95199.0708\n",
      "Ep. 7114 done, reward: 5.0, running_reward: 0.6992, time (sec): 95226.7958\n",
      "Ep. 7116 done, reward: -1.0, running_reward: 0.5862, time (sec): 95252.3358\n",
      "Ep. 7118 done, reward: 5.0, running_reward: 0.6641, time (sec): 95276.1574\n",
      "Ep. 7120 done, reward: -8.0, running_reward: 0.4620, time (sec): 95299.7344\n",
      "Ep. 7122 done, reward: 3.0, running_reward: 0.4630, time (sec): 95324.9231\n",
      "Ep. 7124 done, reward: -6.0, running_reward: 0.4433, time (sec): 95349.3671\n",
      "Ep. 7126 done, reward: -5.0, running_reward: 0.5032, time (sec): 95375.6155\n",
      "Ep. 7128 done, reward: -2.0, running_reward: 0.5920, time (sec): 95401.8474\n",
      "Ep. 7130 done, reward: 10.0, running_reward: 0.6704, time (sec): 95424.6275\n",
      "Ep. 7132 done, reward: -2.0, running_reward: 0.4885, time (sec): 95447.8563\n",
      "Ep. 7134 done, reward: -7.0, running_reward: 0.4979, time (sec): 95468.5639\n",
      "Ep. 7136 done, reward: 5.0, running_reward: 0.5182, time (sec): 95496.1310\n",
      "Ep. 7138 done, reward: -8.0, running_reward: 0.4477, time (sec): 95524.2697\n",
      "Ep. 7140 done, reward: 2.0, running_reward: 0.5281, time (sec): 95547.4590\n",
      "Ep. 7142 done, reward: 8.0, running_reward: 0.6669, time (sec): 95572.8744\n",
      "Ep. 7144 done, reward: -1.0, running_reward: 0.6733, time (sec): 95600.0063\n",
      "Ep. 7146 done, reward: -1.0, running_reward: 0.5707, time (sec): 95629.1362\n",
      "Ep. 7148 done, reward: 8.0, running_reward: 0.6492, time (sec): 95652.3904\n",
      "Ep. 7150 done, reward: -1.0, running_reward: 0.6659, time (sec): 95682.4070\n",
      "Ep. 7152 done, reward: -2.0, running_reward: 0.5139, time (sec): 95706.9897\n",
      "Ep. 7154 done, reward: -3.0, running_reward: 0.4340, time (sec): 95733.4740\n",
      "Ep. 7156 done, reward: 8.0, running_reward: 0.5450, time (sec): 95758.5814\n",
      "Ep. 7158 done, reward: 13.0, running_reward: 0.6542, time (sec): 95780.2646\n",
      "Ep. 7160 done, reward: 6.0, running_reward: 0.7111, time (sec): 95806.5823\n",
      "Ep. 7162 done, reward: -7.0, running_reward: 0.6963, time (sec): 95832.4396\n",
      "Ep. 7164 done, reward: 1.0, running_reward: 0.6825, time (sec): 95855.6484\n",
      "Ep. 7166 done, reward: -3.0, running_reward: 0.5993, time (sec): 95880.1466\n",
      "Ep. 7168 done, reward: -1.0, running_reward: 0.7061, time (sec): 95904.7536\n",
      "Ep. 7170 done, reward: -10.0, running_reward: 0.5030, time (sec): 95930.0743\n",
      "Ep. 7172 done, reward: 10.0, running_reward: 0.5534, time (sec): 95953.5663\n",
      "Ep. 7174 done, reward: -15.0, running_reward: 0.4715, time (sec): 95973.7087\n",
      "Ep. 7176 done, reward: -2.0, running_reward: 0.4521, time (sec): 96005.2500\n",
      "Ep. 7178 done, reward: 4.0, running_reward: 0.5623, time (sec): 96030.4945\n",
      "Ep. 7180 done, reward: 2.0, running_reward: 0.5513, time (sec): 96058.6849\n",
      "Ep. 7182 done, reward: 11.0, running_reward: 0.5711, time (sec): 96082.4870\n",
      "Ep. 7184 done, reward: 1.0, running_reward: 0.5004, time (sec): 96106.7828\n",
      "Ep. 7186 done, reward: -1.0, running_reward: 0.4508, time (sec): 96135.4083\n",
      "Ep. 7188 done, reward: -17.0, running_reward: 0.2916, time (sec): 96160.6390\n",
      "Ep. 7190 done, reward: 9.0, running_reward: 0.3857, time (sec): 96183.1892\n",
      "Ep. 7192 done, reward: 9.0, running_reward: 0.4185, time (sec): 96207.5258\n",
      "Ep. 7194 done, reward: 7.0, running_reward: 0.5891, time (sec): 96230.3673\n",
      "Ep. 7196 done, reward: 8.0, running_reward: 0.6178, time (sec): 96257.1977\n",
      "Ep. 7198 done, reward: 4.0, running_reward: 0.7148, time (sec): 96280.1365\n",
      "Ep. 7200 done, reward: 7.0, running_reward: 0.7310, time (sec): 96305.0050\n",
      "Ep. 7202 done, reward: 8.0, running_reward: 0.8261, time (sec): 96330.8603\n",
      "Ep. 7204 done, reward: -2.0, running_reward: 0.8590, time (sec): 96352.3103\n",
      "Ep. 7206 done, reward: 2.0, running_reward: 0.8718, time (sec): 96381.2008\n",
      "Ep. 7208 done, reward: -11.0, running_reward: 0.7939, time (sec): 96404.8250\n",
      "Ep. 7210 done, reward: 8.0, running_reward: 0.7492, time (sec): 96428.4682\n",
      "Ep. 7212 done, reward: -1.0, running_reward: 0.7837, time (sec): 96456.1524\n",
      "Ep. 7214 done, reward: -1.0, running_reward: 0.7284, time (sec): 96485.9781\n",
      "Ep. 7216 done, reward: 9.0, running_reward: 0.7544, time (sec): 96506.4931\n",
      "Ep. 7218 done, reward: -7.0, running_reward: 0.7684, time (sec): 96529.6599\n",
      "Ep. 7220 done, reward: 2.0, running_reward: 0.8325, time (sec): 96554.9631\n",
      "Ep. 7222 done, reward: 1.0, running_reward: 1.0042, time (sec): 96575.8769\n",
      "Ep. 7224 done, reward: 1.0, running_reward: 0.9546, time (sec): 96607.4500\n",
      "Ep. 7226 done, reward: 3.0, running_reward: 0.8369, time (sec): 96628.2657\n",
      "Ep. 7228 done, reward: 15.0, running_reward: 0.8613, time (sec): 96645.8556\n",
      "Ep. 7230 done, reward: 1.0, running_reward: 0.8443, time (sec): 96673.9363\n",
      "Ep. 7232 done, reward: 4.0, running_reward: 0.7190, time (sec): 96695.4925\n",
      "Ep. 7234 done, reward: -4.0, running_reward: 0.6548, time (sec): 96720.4219\n",
      "Ep. 7236 done, reward: 7.0, running_reward: 0.6523, time (sec): 96744.6899\n",
      "Ep. 7238 done, reward: -3.0, running_reward: 0.5698, time (sec): 96768.7050\n",
      "Ep. 7240 done, reward: 9.0, running_reward: 0.5494, time (sec): 96789.5806\n",
      "Ep. 7242 done, reward: 14.0, running_reward: 0.6884, time (sec): 96813.5259\n",
      "Ep. 7244 done, reward: 4.0, running_reward: 0.7741, time (sec): 96833.7766\n",
      "Ep. 7246 done, reward: -5.0, running_reward: 0.5998, time (sec): 96855.7031\n",
      "Ep. 7248 done, reward: 1.0, running_reward: 0.6771, time (sec): 96882.1216\n",
      "Ep. 7250 done, reward: 15.0, running_reward: 0.9027, time (sec): 96899.9676\n",
      "Ep. 7252 done, reward: 2.0, running_reward: 1.0334, time (sec): 96922.9859\n",
      "Ep. 7254 done, reward: -2.0, running_reward: 1.0028, time (sec): 96952.0419\n",
      "Ep. 7256 done, reward: -5.0, running_reward: 0.8932, time (sec): 96977.9375\n",
      "Ep. 7258 done, reward: 8.0, running_reward: 0.9653, time (sec): 97004.1542\n",
      "Ep. 7260 done, reward: -6.0, running_reward: 0.9257, time (sec): 97030.9932\n",
      "Ep. 7262 done, reward: 8.0, running_reward: 1.0566, time (sec): 97056.3710\n",
      "Ep. 7264 done, reward: 2.0, running_reward: 1.1447, time (sec): 97080.5992\n",
      "Ep. 7266 done, reward: 3.0, running_reward: 1.1816, time (sec): 97107.5099\n",
      "Ep. 7268 done, reward: 6.0, running_reward: 1.1983, time (sec): 97135.8455\n",
      "Ep. 7270 done, reward: 3.0, running_reward: 1.1648, time (sec): 97164.0998\n",
      "Ep. 7272 done, reward: -10.0, running_reward: 1.1703, time (sec): 97186.3572\n",
      "Ep. 7274 done, reward: 6.0, running_reward: 1.2566, time (sec): 97210.7493\n",
      "Ep. 7276 done, reward: 5.0, running_reward: 1.3707, time (sec): 97233.5845\n",
      "Ep. 7278 done, reward: 1.0, running_reward: 1.2643, time (sec): 97257.7682\n",
      "Ep. 7280 done, reward: -4.0, running_reward: 1.2684, time (sec): 97283.9360\n",
      "Ep. 7282 done, reward: 1.0, running_reward: 1.2235, time (sec): 97311.4766\n",
      "Ep. 7284 done, reward: -5.0, running_reward: 1.2877, time (sec): 97333.8126\n",
      "Ep. 7286 done, reward: -13.0, running_reward: 1.0331, time (sec): 97357.2043\n",
      "Ep. 7288 done, reward: -7.0, running_reward: 0.8336, time (sec): 97381.1107\n",
      "Ep. 7290 done, reward: 4.0, running_reward: 0.9462, time (sec): 97402.7518\n",
      "Ep. 7292 done, reward: 7.0, running_reward: 0.9676, time (sec): 97428.6183\n",
      "Ep. 7294 done, reward: -13.0, running_reward: 0.7293, time (sec): 97448.7245\n",
      "Ep. 7296 done, reward: -10.0, running_reward: 0.6742, time (sec): 97472.7187\n",
      "Ep. 7298 done, reward: 8.0, running_reward: 0.6615, time (sec): 97497.3118\n",
      "Ep. 7300 done, reward: 6.0, running_reward: 0.7678, time (sec): 97521.5027\n",
      "Ep. 7302 done, reward: -2.0, running_reward: 0.6731, time (sec): 97546.4578\n",
      "Ep. 7304 done, reward: 5.0, running_reward: 0.7889, time (sec): 97569.4487\n",
      "Ep. 7306 done, reward: 1.0, running_reward: 0.7634, time (sec): 97599.9999\n",
      "Ep. 7308 done, reward: -6.0, running_reward: 0.5991, time (sec): 97628.5739\n",
      "Ep. 7310 done, reward: 6.0, running_reward: 0.6175, time (sec): 97656.0747\n",
      "Ep. 7312 done, reward: -2.0, running_reward: 0.5456, time (sec): 97684.9807\n",
      "Ep. 7314 done, reward: 6.0, running_reward: 0.5848, time (sec): 97710.0869\n",
      "Ep. 7316 done, reward: -7.0, running_reward: 0.5329, time (sec): 97736.7765\n",
      "Ep. 7318 done, reward: -3.0, running_reward: 0.5022, time (sec): 97762.9198\n",
      "Ep. 7320 done, reward: 10.0, running_reward: 0.5328, time (sec): 97790.6970\n",
      "Ep. 7322 done, reward: 3.0, running_reward: 0.5819, time (sec): 97818.8533\n",
      "Ep. 7324 done, reward: -4.0, running_reward: 0.6095, time (sec): 97842.8599\n",
      "Ep. 7326 done, reward: -1.0, running_reward: 0.6072, time (sec): 97869.4651\n",
      "Ep. 7328 done, reward: 6.0, running_reward: 0.6452, time (sec): 97897.8818\n",
      "Ep. 7330 done, reward: 4.0, running_reward: 0.6328, time (sec): 97926.4416\n",
      "Ep. 7332 done, reward: -10.0, running_reward: 0.4608, time (sec): 97948.9276\n",
      "Ep. 7334 done, reward: 7.0, running_reward: 0.4721, time (sec): 97975.0596\n",
      "Ep. 7336 done, reward: 1.0, running_reward: 0.4232, time (sec): 98002.9434\n",
      "Ep. 7338 done, reward: 5.0, running_reward: 0.5242, time (sec): 98027.1394\n",
      "Ep. 7340 done, reward: 8.0, running_reward: 0.5641, time (sec): 98051.8283\n",
      "Ep. 7342 done, reward: -1.0, running_reward: 0.5923, time (sec): 98081.8670\n",
      "Ep. 7344 done, reward: -4.0, running_reward: 0.5306, time (sec): 98109.0851\n",
      "Ep. 7346 done, reward: 5.0, running_reward: 0.5602, time (sec): 98134.5352\n",
      "Ep. 7348 done, reward: 2.0, running_reward: 0.6086, time (sec): 98159.9321\n",
      "Ep. 7350 done, reward: 7.0, running_reward: 0.5774, time (sec): 98183.6413\n",
      "Ep. 7352 done, reward: -4.0, running_reward: 0.5358, time (sec): 98211.4224\n",
      "Ep. 7354 done, reward: 1.0, running_reward: 0.6045, time (sec): 98235.5760\n",
      "Ep. 7356 done, reward: 5.0, running_reward: 0.6622, time (sec): 98263.8063\n",
      "Ep. 7358 done, reward: 12.0, running_reward: 0.7889, time (sec): 98289.5596\n",
      "Ep. 7360 done, reward: 2.0, running_reward: 0.8130, time (sec): 98316.9400\n",
      "Ep. 7362 done, reward: -2.0, running_reward: 0.7669, time (sec): 98342.9403\n",
      "Ep. 7364 done, reward: -3.0, running_reward: 0.7810, time (sec): 98367.1025\n",
      "Ep. 7366 done, reward: 4.0, running_reward: 0.7857, time (sec): 98393.3961\n",
      "Ep. 7368 done, reward: -14.0, running_reward: 0.5707, time (sec): 98417.3203\n",
      "Ep. 7370 done, reward: -3.0, running_reward: 0.5689, time (sec): 98446.5330\n",
      "Ep. 7372 done, reward: 9.0, running_reward: 0.6872, time (sec): 98468.4930\n",
      "Ep. 7374 done, reward: -5.0, running_reward: 0.6730, time (sec): 98494.5926\n",
      "Ep. 7376 done, reward: -1.0, running_reward: 0.6199, time (sec): 98519.9951\n",
      "Ep. 7378 done, reward: 1.0, running_reward: 0.5285, time (sec): 98545.7550\n",
      "Ep. 7380 done, reward: 10.0, running_reward: 0.5883, time (sec): 98568.9023\n",
      "Ep. 7382 done, reward: 3.0, running_reward: 0.5174, time (sec): 98591.9910\n",
      "Ep. 7384 done, reward: -4.0, running_reward: 0.4177, time (sec): 98618.5807\n",
      "Ep. 7386 done, reward: -5.0, running_reward: 0.4385, time (sec): 98646.0821\n",
      "Ep. 7388 done, reward: 2.0, running_reward: 0.4597, time (sec): 98677.1310\n",
      "Ep. 7390 done, reward: -9.0, running_reward: 0.3210, time (sec): 98704.9103\n",
      "Ep. 7392 done, reward: 8.0, running_reward: 0.5233, time (sec): 98726.2304\n",
      "Ep. 7394 done, reward: -11.0, running_reward: 0.4425, time (sec): 98750.4893\n",
      "Ep. 7396 done, reward: -3.0, running_reward: 0.4136, time (sec): 98778.5940\n",
      "Ep. 7398 done, reward: -5.0, running_reward: 0.2959, time (sec): 98804.9714\n",
      "Ep. 7400 done, reward: 7.0, running_reward: 0.3303, time (sec): 98829.9638\n",
      "Ep. 7402 done, reward: -5.0, running_reward: 0.3629, time (sec): 98855.1145\n",
      "Ep. 7404 done, reward: 6.0, running_reward: 0.4948, time (sec): 98883.1984\n",
      "Ep. 7406 done, reward: 3.0, running_reward: 0.5645, time (sec): 98908.7045\n",
      "Ep. 7408 done, reward: 9.0, running_reward: 0.5938, time (sec): 98932.3312\n",
      "Ep. 7410 done, reward: 11.0, running_reward: 0.7711, time (sec): 98954.6623\n",
      "Ep. 7412 done, reward: 10.0, running_reward: 0.9152, time (sec): 98978.6237\n",
      "Ep. 7414 done, reward: -2.0, running_reward: 0.9661, time (sec): 99003.3120\n",
      "Ep. 7416 done, reward: -1.0, running_reward: 1.0062, time (sec): 99031.2857\n",
      "Ep. 7418 done, reward: 8.0, running_reward: 1.0166, time (sec): 99054.6335\n",
      "Ep. 7420 done, reward: 8.0, running_reward: 0.9873, time (sec): 99078.0453\n",
      "Ep. 7422 done, reward: -3.0, running_reward: 1.0367, time (sec): 99101.2079\n",
      "Ep. 7424 done, reward: 13.0, running_reward: 1.1955, time (sec): 99123.0854\n",
      "Ep. 7426 done, reward: 2.0, running_reward: 1.2709, time (sec): 99149.0376\n",
      "Ep. 7428 done, reward: -3.0, running_reward: 1.2652, time (sec): 99176.8011\n",
      "Ep. 7430 done, reward: -1.0, running_reward: 1.2597, time (sec): 99205.0568\n",
      "Ep. 7432 done, reward: -1.0, running_reward: 1.1256, time (sec): 99229.4369\n",
      "Ep. 7434 done, reward: -13.0, running_reward: 1.0623, time (sec): 99252.4464\n",
      "Ep. 7436 done, reward: 5.0, running_reward: 1.0318, time (sec): 99279.3345\n",
      "Ep. 7438 done, reward: 8.0, running_reward: 1.0417, time (sec): 99304.4717\n",
      "Ep. 7440 done, reward: -2.0, running_reward: 0.9119, time (sec): 99335.7795\n",
      "Ep. 7442 done, reward: 9.0, running_reward: 1.0234, time (sec): 99357.9600\n",
      "Ep. 7444 done, reward: -4.0, running_reward: 0.9333, time (sec): 99385.4759\n",
      "Ep. 7446 done, reward: 8.0, running_reward: 0.9551, time (sec): 99410.5873\n",
      "Ep. 7448 done, reward: 10.0, running_reward: 1.0757, time (sec): 99431.8177\n",
      "Ep. 7450 done, reward: -6.0, running_reward: 1.0537, time (sec): 99457.0912\n",
      "Ep. 7452 done, reward: -1.0, running_reward: 1.1514, time (sec): 99480.5510\n",
      "Ep. 7454 done, reward: -13.0, running_reward: 1.0282, time (sec): 99504.6426\n",
      "Ep. 7456 done, reward: 10.0, running_reward: 1.0187, time (sec): 99526.8369\n",
      "Ep. 7458 done, reward: 7.0, running_reward: 1.0387, time (sec): 99551.4781\n",
      "Ep. 7460 done, reward: -2.0, running_reward: 1.0772, time (sec): 99574.8868\n",
      "Ep. 7462 done, reward: -3.0, running_reward: 1.1149, time (sec): 99598.8279\n",
      "Ep. 7464 done, reward: -8.0, running_reward: 1.0919, time (sec): 99623.3889\n",
      "Ep. 7466 done, reward: -9.0, running_reward: 0.9901, time (sec): 99649.3073\n",
      "Ep. 7468 done, reward: 7.0, running_reward: 1.0503, time (sec): 99671.9228\n",
      "Ep. 7470 done, reward: -7.0, running_reward: 0.9396, time (sec): 99698.0054\n",
      "Ep. 7472 done, reward: -7.0, running_reward: 0.8410, time (sec): 99722.9834\n",
      "Ep. 7474 done, reward: -9.0, running_reward: 0.6847, time (sec): 99746.5539\n",
      "Ep. 7476 done, reward: 2.0, running_reward: 0.7505, time (sec): 99773.0960\n",
      "Ep. 7478 done, reward: -4.0, running_reward: 0.7154, time (sec): 99802.7482\n",
      "Ep. 7480 done, reward: 1.0, running_reward: 0.8200, time (sec): 99829.6014\n",
      "Ep. 7482 done, reward: -4.0, running_reward: 0.7736, time (sec): 99852.8726\n",
      "Ep. 7484 done, reward: 3.0, running_reward: 0.7387, time (sec): 99878.8563\n",
      "Ep. 7486 done, reward: 8.0, running_reward: 0.7941, time (sec): 99907.7403\n",
      "Ep. 7488 done, reward: 8.0, running_reward: 0.9672, time (sec): 99930.6402\n",
      "Ep. 7490 done, reward: 3.0, running_reward: 1.0770, time (sec): 99955.1500\n",
      "Ep. 7492 done, reward: 8.0, running_reward: 1.1751, time (sec): 99979.0611\n",
      "Ep. 7494 done, reward: 2.0, running_reward: 1.2114, time (sec): 100008.3217\n",
      "Ep. 7496 done, reward: -5.0, running_reward: 1.0382, time (sec): 100033.9193\n",
      "Ep. 7498 done, reward: 3.0, running_reward: 1.1070, time (sec): 100060.5449\n",
      "Ep. 7500 done, reward: 4.0, running_reward: 1.1844, time (sec): 100085.1365\n",
      "Ep. 7502 done, reward: -9.0, running_reward: 1.1698, time (sec): 100108.5765\n",
      "Ep. 7504 done, reward: -6.0, running_reward: 1.0370, time (sec): 100138.2536\n",
      "Ep. 7506 done, reward: 8.0, running_reward: 1.1459, time (sec): 100163.9722\n",
      "Ep. 7508 done, reward: -5.0, running_reward: 1.2117, time (sec): 100186.7255\n",
      "Ep. 7510 done, reward: -4.0, running_reward: 1.2169, time (sec): 100210.3257\n",
      "Ep. 7512 done, reward: 1.0, running_reward: 1.2422, time (sec): 100237.1479\n",
      "Ep. 7514 done, reward: -2.0, running_reward: 1.1678, time (sec): 100263.4639\n",
      "Ep. 7516 done, reward: 3.0, running_reward: 1.1053, time (sec): 100287.8200\n",
      "Ep. 7518 done, reward: 5.0, running_reward: 1.2224, time (sec): 100310.8978\n",
      "Ep. 7520 done, reward: 7.0, running_reward: 1.3572, time (sec): 100335.1982\n",
      "Ep. 7522 done, reward: 11.0, running_reward: 1.4699, time (sec): 100356.3113\n",
      "Ep. 7524 done, reward: 8.0, running_reward: 1.5503, time (sec): 100380.6047\n",
      "Ep. 7526 done, reward: 2.0, running_reward: 1.4801, time (sec): 100406.4990\n",
      "Ep. 7528 done, reward: -10.0, running_reward: 1.3308, time (sec): 100431.8134\n",
      "Ep. 7530 done, reward: -4.0, running_reward: 1.2346, time (sec): 100457.6733\n",
      "Ep. 7532 done, reward: 7.0, running_reward: 1.3592, time (sec): 100479.1179\n",
      "Ep. 7534 done, reward: 8.0, running_reward: 1.4716, time (sec): 100503.3384\n",
      "Ep. 7536 done, reward: 6.0, running_reward: 1.5716, time (sec): 100526.9032\n",
      "Ep. 7538 done, reward: -5.0, running_reward: 1.3913, time (sec): 100550.6604\n",
      "Ep. 7540 done, reward: 5.0, running_reward: 1.3444, time (sec): 100574.9599\n",
      "Ep. 7542 done, reward: 11.0, running_reward: 1.4672, time (sec): 100598.6654\n",
      "Ep. 7544 done, reward: -9.0, running_reward: 1.4371, time (sec): 100619.9879\n",
      "Ep. 7546 done, reward: 13.0, running_reward: 1.4791, time (sec): 100641.0081\n",
      "Ep. 7548 done, reward: 1.0, running_reward: 1.4498, time (sec): 100672.4703\n",
      "Ep. 7550 done, reward: -7.0, running_reward: 1.3806, time (sec): 100698.5712\n",
      "Ep. 7552 done, reward: -8.0, running_reward: 1.3622, time (sec): 100721.6435\n",
      "Ep. 7554 done, reward: 14.0, running_reward: 1.5543, time (sec): 100742.0965\n",
      "Ep. 7556 done, reward: 10.0, running_reward: 1.6828, time (sec): 100765.1484\n",
      "Ep. 7558 done, reward: -6.0, running_reward: 1.5992, time (sec): 100792.6068\n",
      "Ep. 7560 done, reward: 2.0, running_reward: 1.5379, time (sec): 100820.6138\n",
      "Ep. 7562 done, reward: 1.0, running_reward: 1.6658, time (sec): 100845.6211\n",
      "Ep. 7564 done, reward: -5.0, running_reward: 1.5133, time (sec): 100868.6944\n",
      "Ep. 7566 done, reward: 5.0, running_reward: 1.5233, time (sec): 100898.3181\n",
      "Ep. 7568 done, reward: 4.0, running_reward: 1.5627, time (sec): 100922.5488\n",
      "Ep. 7570 done, reward: -9.0, running_reward: 1.4218, time (sec): 100947.5424\n",
      "Ep. 7572 done, reward: 5.0, running_reward: 1.4930, time (sec): 100973.2000\n",
      "Ep. 7574 done, reward: 4.0, running_reward: 1.4736, time (sec): 100998.9293\n",
      "Ep. 7576 done, reward: 8.0, running_reward: 1.4550, time (sec): 101024.3206\n",
      "Ep. 7578 done, reward: -7.0, running_reward: 1.2867, time (sec): 101050.3016\n",
      "Ep. 7580 done, reward: 3.0, running_reward: 1.2713, time (sec): 101078.3270\n",
      "Ep. 7582 done, reward: 10.0, running_reward: 1.3658, time (sec): 101103.3212\n",
      "Ep. 7584 done, reward: -4.0, running_reward: 1.3679, time (sec): 101130.5109\n",
      "Ep. 7586 done, reward: -5.0, running_reward: 1.4194, time (sec): 101154.3812\n",
      "Ep. 7588 done, reward: -3.0, running_reward: 1.3117, time (sec): 101179.4028\n",
      "Ep. 7590 done, reward: 5.0, running_reward: 1.2663, time (sec): 101205.4190\n",
      "Ep. 7592 done, reward: 13.0, running_reward: 1.3612, time (sec): 101230.6096\n",
      "Ep. 7594 done, reward: 3.0, running_reward: 1.3740, time (sec): 101259.0675\n",
      "Ep. 7596 done, reward: 2.0, running_reward: 1.3765, time (sec): 101287.5067\n",
      "Ep. 7598 done, reward: 2.0, running_reward: 1.3494, time (sec): 101316.7142\n",
      "Ep. 7600 done, reward: 4.0, running_reward: 1.3130, time (sec): 101344.6473\n",
      "Ep. 7602 done, reward: -7.0, running_reward: 1.2268, time (sec): 101371.4094\n",
      "Ep. 7604 done, reward: 5.0, running_reward: 1.3118, time (sec): 101391.0873\n",
      "Ep. 7606 done, reward: 7.0, running_reward: 1.4844, time (sec): 101411.0922\n",
      "Ep. 7608 done, reward: -3.0, running_reward: 1.5931, time (sec): 101431.2975\n",
      "Ep. 7610 done, reward: -5.0, running_reward: 1.4025, time (sec): 101454.3450\n",
      "Ep. 7612 done, reward: -4.0, running_reward: 1.3742, time (sec): 101477.4510\n",
      "Ep. 7614 done, reward: -5.0, running_reward: 1.2375, time (sec): 101500.4283\n",
      "Ep. 7616 done, reward: 3.0, running_reward: 1.2824, time (sec): 101526.8902\n",
      "Ep. 7618 done, reward: 7.0, running_reward: 1.4259, time (sec): 101548.2670\n",
      "Ep. 7620 done, reward: -10.0, running_reward: 1.2381, time (sec): 101574.9170\n",
      "Ep. 7622 done, reward: -3.0, running_reward: 1.1142, time (sec): 101600.5170\n",
      "Ep. 7624 done, reward: -3.0, running_reward: 1.0224, time (sec): 101629.4681\n",
      "Ep. 7626 done, reward: -7.0, running_reward: 1.0014, time (sec): 101655.7525\n",
      "Ep. 7628 done, reward: -7.0, running_reward: 0.8916, time (sec): 101684.8233\n",
      "Ep. 7630 done, reward: -9.0, running_reward: 0.8235, time (sec): 101711.2900\n",
      "Ep. 7632 done, reward: 1.0, running_reward: 0.8963, time (sec): 101736.3949\n",
      "Ep. 7634 done, reward: 2.0, running_reward: 0.9183, time (sec): 101761.4339\n",
      "Ep. 7636 done, reward: 14.0, running_reward: 1.0697, time (sec): 101782.5667\n",
      "Ep. 7638 done, reward: -1.0, running_reward: 1.1671, time (sec): 101810.2521\n",
      "Ep. 7640 done, reward: 2.0, running_reward: 1.1936, time (sec): 101837.3157\n",
      "Ep. 7642 done, reward: 5.0, running_reward: 1.1109, time (sec): 101858.3402\n",
      "Ep. 7644 done, reward: 1.0, running_reward: 1.1087, time (sec): 101885.1212\n",
      "Ep. 7646 done, reward: 5.0, running_reward: 1.1466, time (sec): 101911.4872\n",
      "Ep. 7648 done, reward: 8.0, running_reward: 1.2929, time (sec): 101933.8640\n",
      "Ep. 7650 done, reward: 11.0, running_reward: 1.4167, time (sec): 101958.6256\n",
      "Ep. 7652 done, reward: 4.0, running_reward: 1.3592, time (sec): 101982.0915\n",
      "Ep. 7654 done, reward: 13.0, running_reward: 1.4523, time (sec): 102009.4082\n",
      "Ep. 7656 done, reward: 1.0, running_reward: 1.4235, time (sec): 102037.0920\n",
      "Ep. 7658 done, reward: -1.0, running_reward: 1.3951, time (sec): 102060.7815\n",
      "Ep. 7660 done, reward: -10.0, running_reward: 1.3663, time (sec): 102085.2676\n",
      "Ep. 7662 done, reward: -7.0, running_reward: 1.3582, time (sec): 102110.9490\n",
      "Ep. 7664 done, reward: -7.0, running_reward: 1.2909, time (sec): 102139.0549\n",
      "Ep. 7666 done, reward: 11.0, running_reward: 1.4148, time (sec): 102161.6470\n",
      "Ep. 7668 done, reward: 6.0, running_reward: 1.3674, time (sec): 102188.1351\n",
      "Ep. 7670 done, reward: 3.0, running_reward: 1.3603, time (sec): 102218.2032\n",
      "Ep. 7672 done, reward: 4.0, running_reward: 1.5119, time (sec): 102239.7863\n",
      "Ep. 7674 done, reward: 2.0, running_reward: 1.4622, time (sec): 102267.5957\n",
      "Ep. 7676 done, reward: -5.0, running_reward: 1.2346, time (sec): 102290.5496\n",
      "Ep. 7678 done, reward: -5.0, running_reward: 1.1699, time (sec): 102319.1527\n",
      "Ep. 7680 done, reward: 4.0, running_reward: 1.2955, time (sec): 102342.7358\n",
      "Ep. 7682 done, reward: 9.0, running_reward: 1.3201, time (sec): 102367.7387\n",
      "Ep. 7684 done, reward: -5.0, running_reward: 1.2835, time (sec): 102392.7841\n",
      "Ep. 7686 done, reward: -6.0, running_reward: 1.2573, time (sec): 102418.9122\n",
      "Ep. 7688 done, reward: -3.0, running_reward: 1.2320, time (sec): 102449.6759\n",
      "Ep. 7690 done, reward: -11.0, running_reward: 1.1074, time (sec): 102473.1230\n",
      "Ep. 7692 done, reward: 6.0, running_reward: 1.2444, time (sec): 102496.4725\n",
      "Ep. 7694 done, reward: 8.0, running_reward: 1.2501, time (sec): 102522.7499\n",
      "Ep. 7696 done, reward: -11.0, running_reward: 1.2340, time (sec): 102544.8443\n",
      "Ep. 7698 done, reward: 6.0, running_reward: 1.1705, time (sec): 102568.9764\n",
      "Ep. 7700 done, reward: 5.0, running_reward: 1.2467, time (sec): 102592.3226\n",
      "Ep. 7702 done, reward: 8.0, running_reward: 1.3316, time (sec): 102614.4214\n",
      "Ep. 7704 done, reward: -9.0, running_reward: 1.2349, time (sec): 102637.0429\n",
      "Ep. 7706 done, reward: 12.0, running_reward: 1.3204, time (sec): 102662.5425\n",
      "Ep. 7708 done, reward: 4.0, running_reward: 1.3935, time (sec): 102688.7900\n",
      "Ep. 7710 done, reward: -2.0, running_reward: 1.4448, time (sec): 102714.6492\n",
      "Ep. 7712 done, reward: 8.0, running_reward: 1.4366, time (sec): 102742.1419\n",
      "Ep. 7714 done, reward: 3.0, running_reward: 1.5073, time (sec): 102765.3742\n",
      "Ep. 7716 done, reward: -9.0, running_reward: 1.4764, time (sec): 102787.8510\n",
      "Ep. 7718 done, reward: 9.0, running_reward: 1.5272, time (sec): 102816.8228\n",
      "Ep. 7720 done, reward: 7.0, running_reward: 1.5173, time (sec): 102842.6072\n",
      "Ep. 7722 done, reward: 9.0, running_reward: 1.4682, time (sec): 102861.7000\n",
      "Ep. 7724 done, reward: 17.0, running_reward: 1.5991, time (sec): 102882.7327\n",
      "Ep. 7726 done, reward: 11.0, running_reward: 1.8059, time (sec): 102903.5238\n",
      "Ep. 7728 done, reward: 6.0, running_reward: 1.8102, time (sec): 102927.2606\n",
      "Ep. 7730 done, reward: 6.0, running_reward: 1.7847, time (sec): 102951.5253\n",
      "Ep. 7732 done, reward: 11.0, running_reward: 1.8493, time (sec): 102975.6783\n",
      "Ep. 7734 done, reward: -3.0, running_reward: 1.8221, time (sec): 103007.1836\n",
      "Ep. 7736 done, reward: -2.0, running_reward: 1.6173, time (sec): 103031.3754\n",
      "Ep. 7738 done, reward: 6.0, running_reward: 1.7441, time (sec): 103056.4384\n",
      "Ep. 7740 done, reward: -9.0, running_reward: 1.6590, time (sec): 103078.9278\n",
      "Ep. 7742 done, reward: -2.0, running_reward: 1.7149, time (sec): 103100.1788\n",
      "Ep. 7744 done, reward: -9.0, running_reward: 1.6799, time (sec): 103122.0250\n",
      "Ep. 7746 done, reward: 5.0, running_reward: 1.7855, time (sec): 103144.0948\n",
      "Ep. 7748 done, reward: 6.0, running_reward: 1.8793, time (sec): 103166.8745\n",
      "Ep. 7750 done, reward: 1.0, running_reward: 1.8816, time (sec): 103198.2394\n",
      "Ep. 7752 done, reward: 3.0, running_reward: 1.9237, time (sec): 103226.7961\n",
      "Ep. 7754 done, reward: 3.0, running_reward: 2.0045, time (sec): 103251.9996\n",
      "Ep. 7756 done, reward: -2.0, running_reward: 1.8951, time (sec): 103277.6842\n",
      "Ep. 7758 done, reward: 6.0, running_reward: 1.8679, time (sec): 103303.2206\n",
      "Ep. 7760 done, reward: 4.0, running_reward: 1.8410, time (sec): 103327.9746\n",
      "Ep. 7762 done, reward: -1.0, running_reward: 1.8934, time (sec): 103350.7316\n",
      "Ep. 7764 done, reward: -13.0, running_reward: 1.7455, time (sec): 103377.3111\n",
      "Ep. 7766 done, reward: 2.0, running_reward: 1.6813, time (sec): 103403.2178\n",
      "Ep. 7768 done, reward: 3.0, running_reward: 1.6976, time (sec): 103431.6016\n",
      "Ep. 7770 done, reward: 7.0, running_reward: 1.7536, time (sec): 103457.0576\n",
      "Ep. 7772 done, reward: 7.0, running_reward: 1.8382, time (sec): 103479.7901\n",
      "Ep. 7774 done, reward: -1.0, running_reward: 1.8015, time (sec): 103505.7398\n",
      "Ep. 7776 done, reward: 8.0, running_reward: 1.7863, time (sec): 103530.7354\n",
      "Ep. 7778 done, reward: 3.0, running_reward: 1.8104, time (sec): 103557.0331\n",
      "Ep. 7780 done, reward: -3.0, running_reward: 1.7741, time (sec): 103580.7837\n",
      "Ep. 7782 done, reward: 11.0, running_reward: 1.7399, time (sec): 103602.4305\n",
      "Ep. 7784 done, reward: -3.0, running_reward: 1.6258, time (sec): 103631.1252\n",
      "Ep. 7786 done, reward: 9.0, running_reward: 1.7329, time (sec): 103655.0908\n",
      "Ep. 7788 done, reward: -2.0, running_reward: 1.7082, time (sec): 103681.4122\n",
      "Ep. 7790 done, reward: 2.0, running_reward: 1.7437, time (sec): 103706.2701\n",
      "Ep. 7792 done, reward: 10.0, running_reward: 1.7397, time (sec): 103732.1689\n",
      "Ep. 7794 done, reward: -3.0, running_reward: 1.6651, time (sec): 103763.8475\n",
      "Ep. 7796 done, reward: -6.0, running_reward: 1.5819, time (sec): 103788.6706\n",
      "Ep. 7798 done, reward: 6.0, running_reward: 1.5807, time (sec): 103813.2779\n",
      "Ep. 7800 done, reward: 7.0, running_reward: 1.6589, time (sec): 103840.6426\n",
      "Ep. 7802 done, reward: 4.0, running_reward: 1.5669, time (sec): 103865.5031\n",
      "Ep. 7804 done, reward: 6.0, running_reward: 1.6947, time (sec): 103889.0638\n",
      "Ep. 7806 done, reward: -4.0, running_reward: 1.6012, time (sec): 103916.1977\n",
      "Ep. 7808 done, reward: 5.0, running_reward: 1.5302, time (sec): 103941.2718\n",
      "Ep. 7810 done, reward: 7.0, running_reward: 1.4707, time (sec): 103967.7166\n",
      "Ep. 7812 done, reward: 7.0, running_reward: 1.5313, time (sec): 103990.1998\n",
      "Ep. 7814 done, reward: 12.0, running_reward: 1.5911, time (sec): 104015.8276\n",
      "Ep. 7816 done, reward: 5.0, running_reward: 1.5896, time (sec): 104045.3744\n",
      "Ep. 7818 done, reward: -1.0, running_reward: 1.5876, time (sec): 104073.4248\n",
      "Ep. 7820 done, reward: 8.0, running_reward: 1.5964, time (sec): 104099.4528\n",
      "Ep. 7822 done, reward: -5.0, running_reward: 1.5443, time (sec): 104125.6018\n",
      "Ep. 7824 done, reward: 2.0, running_reward: 1.5435, time (sec): 104155.7796\n",
      "Ep. 7826 done, reward: 1.0, running_reward: 1.5426, time (sec): 104184.1335\n",
      "Ep. 7828 done, reward: 4.0, running_reward: 1.4727, time (sec): 104206.4187\n",
      "Ep. 7830 done, reward: -1.0, running_reward: 1.4631, time (sec): 104235.8299\n",
      "Ep. 7832 done, reward: -9.0, running_reward: 1.3143, time (sec): 104262.0911\n",
      "Ep. 7834 done, reward: 5.0, running_reward: 1.3678, time (sec): 104288.5080\n",
      "Ep. 7836 done, reward: -1.0, running_reward: 1.4197, time (sec): 104313.2455\n",
      "Ep. 7838 done, reward: 5.0, running_reward: 1.3919, time (sec): 104340.1002\n",
      "Ep. 7840 done, reward: 2.0, running_reward: 1.4139, time (sec): 104370.5659\n",
      "Ep. 7842 done, reward: -5.0, running_reward: 1.2566, time (sec): 104396.5188\n",
      "Ep. 7844 done, reward: 5.0, running_reward: 1.2222, time (sec): 104425.5369\n",
      "Ep. 7846 done, reward: 13.0, running_reward: 1.2982, time (sec): 104446.8099\n",
      "Ep. 7848 done, reward: 10.0, running_reward: 1.3228, time (sec): 104470.4845\n",
      "Ep. 7850 done, reward: 4.0, running_reward: 1.3959, time (sec): 104496.3879\n",
      "Ep. 7852 done, reward: 2.0, running_reward: 1.4574, time (sec): 104520.8097\n",
      "Ep. 7854 done, reward: 5.0, running_reward: 1.4982, time (sec): 104547.2935\n",
      "Ep. 7856 done, reward: -5.0, running_reward: 1.3788, time (sec): 104578.1008\n",
      "Ep. 7858 done, reward: -14.0, running_reward: 1.1322, time (sec): 104604.5124\n",
      "Ep. 7860 done, reward: 6.0, running_reward: 1.2291, time (sec): 104626.5662\n",
      "Ep. 7862 done, reward: 5.0, running_reward: 1.1457, time (sec): 104649.8079\n",
      "Ep. 7864 done, reward: -9.0, running_reward: 0.9933, time (sec): 104677.7021\n",
      "Ep. 7866 done, reward: -5.0, running_reward: 0.9334, time (sec): 104706.6050\n",
      "Ep. 7868 done, reward: -3.0, running_reward: 0.8552, time (sec): 104734.0556\n",
      "Ep. 7870 done, reward: 7.0, running_reward: 0.8586, time (sec): 104761.5667\n",
      "Ep. 7872 done, reward: -6.0, running_reward: 0.8113, time (sec): 104789.1071\n",
      "Ep. 7874 done, reward: 2.0, running_reward: 0.7755, time (sec): 104817.8405\n",
      "Ep. 7876 done, reward: -7.0, running_reward: 0.7099, time (sec): 104845.5201\n",
      "Ep. 7878 done, reward: -4.0, running_reward: 0.7646, time (sec): 104871.5495\n",
      "Ep. 7880 done, reward: 16.0, running_reward: 0.9688, time (sec): 104892.1886\n",
      "Ep. 7882 done, reward: 7.0, running_reward: 1.0295, time (sec): 104917.9010\n",
      "Ep. 7884 done, reward: 1.0, running_reward: 0.9992, time (sec): 104947.3882\n",
      "Ep. 7886 done, reward: -3.0, running_reward: 0.9196, time (sec): 104976.1648\n",
      "Ep. 7888 done, reward: 1.0, running_reward: 0.8816, time (sec): 105004.6264\n",
      "Ep. 7890 done, reward: 1.0, running_reward: 0.9631, time (sec): 105028.2082\n",
      "Ep. 7892 done, reward: 4.0, running_reward: 0.9345, time (sec): 105058.2489\n",
      "Ep. 7894 done, reward: 4.0, running_reward: 0.9955, time (sec): 105086.3623\n",
      "Ep. 7896 done, reward: -2.0, running_reward: 0.8270, time (sec): 105110.6176\n",
      "Ep. 7898 done, reward: 16.0, running_reward: 1.0398, time (sec): 105131.5104\n",
      "Ep. 7900 done, reward: 5.0, running_reward: 1.0889, time (sec): 105159.2245\n",
      "Ep. 7902 done, reward: 6.0, running_reward: 1.0183, time (sec): 105182.7631\n",
      "Ep. 7904 done, reward: 7.0, running_reward: 1.0978, time (sec): 105206.7059\n",
      "Ep. 7906 done, reward: 11.0, running_reward: 1.2552, time (sec): 105228.9791\n",
      "Ep. 7908 done, reward: 7.0, running_reward: 1.3498, time (sec): 105255.8571\n",
      "Ep. 7910 done, reward: -7.0, running_reward: 1.3321, time (sec): 105283.0098\n",
      "Ep. 7912 done, reward: 2.0, running_reward: 1.2959, time (sec): 105312.5628\n",
      "Ep. 7914 done, reward: -4.0, running_reward: 1.2697, time (sec): 105339.0264\n",
      "Ep. 7916 done, reward: -2.0, running_reward: 1.2937, time (sec): 105368.0085\n",
      "Ep. 7918 done, reward: -5.0, running_reward: 1.2378, time (sec): 105396.9772\n",
      "Ep. 7920 done, reward: -2.0, running_reward: 1.2823, time (sec): 105420.7335\n",
      "Ep. 7922 done, reward: -1.0, running_reward: 1.3556, time (sec): 105444.7645\n",
      "Ep. 7924 done, reward: 1.0, running_reward: 1.2892, time (sec): 105475.8517\n",
      "Ep. 7926 done, reward: 3.0, running_reward: 1.4222, time (sec): 105497.3411\n",
      "Ep. 7928 done, reward: -13.0, running_reward: 1.2738, time (sec): 105525.7642\n",
      "Ep. 7930 done, reward: -6.0, running_reward: 1.2479, time (sec): 105552.1458\n",
      "Ep. 7932 done, reward: -2.0, running_reward: 1.3020, time (sec): 105579.7714\n",
      "Ep. 7934 done, reward: -2.0, running_reward: 1.2957, time (sec): 105604.9308\n",
      "Ep. 7936 done, reward: -3.0, running_reward: 1.3191, time (sec): 105629.0382\n",
      "Ep. 7938 done, reward: 1.0, running_reward: 1.3722, time (sec): 105654.4671\n",
      "Ep. 7940 done, reward: -7.0, running_reward: 1.2848, time (sec): 105679.8925\n",
      "Ep. 7942 done, reward: -1.0, running_reward: 1.2591, time (sec): 105708.5452\n",
      "Ep. 7944 done, reward: -4.0, running_reward: 1.2535, time (sec): 105735.1612\n",
      "Ep. 7946 done, reward: 6.0, running_reward: 1.3677, time (sec): 105760.9222\n",
      "Ep. 7948 done, reward: -4.0, running_reward: 1.2312, time (sec): 105787.1893\n",
      "Ep. 7950 done, reward: -5.0, running_reward: 1.1369, time (sec): 105809.6442\n",
      "Ep. 7952 done, reward: 6.0, running_reward: 1.0753, time (sec): 105834.1918\n",
      "Ep. 7954 done, reward: -5.0, running_reward: 0.9346, time (sec): 105860.9737\n",
      "Ep. 7956 done, reward: 5.0, running_reward: 0.9264, time (sec): 105888.6565\n",
      "Ep. 7958 done, reward: 4.0, running_reward: 0.8687, time (sec): 105914.7306\n",
      "Ep. 7960 done, reward: 3.0, running_reward: 0.9606, time (sec): 105938.1237\n",
      "Ep. 7962 done, reward: 2.0, running_reward: 0.8922, time (sec): 105964.5555\n",
      "Ep. 7964 done, reward: 4.0, running_reward: 0.8947, time (sec): 105992.0833\n",
      "Ep. 7966 done, reward: -3.0, running_reward: 1.0251, time (sec): 106011.9062\n",
      "Ep. 7968 done, reward: -5.0, running_reward: 0.9646, time (sec): 106040.8563\n",
      "Ep. 7970 done, reward: -8.0, running_reward: 0.8852, time (sec): 106067.9495\n",
      "Ep. 7972 done, reward: -1.0, running_reward: 0.8774, time (sec): 106095.6495\n",
      "Ep. 7974 done, reward: -1.0, running_reward: 0.9291, time (sec): 106122.2792\n",
      "Ep. 7976 done, reward: -5.0, running_reward: 0.9299, time (sec): 106147.2321\n",
      "Ep. 7978 done, reward: 1.0, running_reward: 0.9115, time (sec): 106171.7238\n",
      "Ep. 7980 done, reward: 11.0, running_reward: 1.0628, time (sec): 106194.0002\n",
      "Ep. 7982 done, reward: 12.0, running_reward: 1.1121, time (sec): 106218.8391\n",
      "Ep. 7984 done, reward: -13.0, running_reward: 1.0491, time (sec): 106241.6983\n",
      "Ep. 7986 done, reward: 10.0, running_reward: 1.1975, time (sec): 106266.5851\n",
      "Ep. 7988 done, reward: -7.0, running_reward: 1.2027, time (sec): 106286.3028\n",
      "Ep. 7990 done, reward: 3.0, running_reward: 1.2780, time (sec): 106311.2573\n",
      "Ep. 7992 done, reward: -11.0, running_reward: 1.2218, time (sec): 106337.2883\n",
      "Ep. 7994 done, reward: 2.0, running_reward: 1.2076, time (sec): 106369.8902\n",
      "Ep. 7996 done, reward: 8.0, running_reward: 1.3428, time (sec): 106391.2310\n",
      "Ep. 7998 done, reward: 4.0, running_reward: 1.3659, time (sec): 106417.4493\n",
      "Ep. 8000 done, reward: 3.0, running_reward: 1.4183, time (sec): 106443.6096\n",
      "Ep. 8002 done, reward: 5.0, running_reward: 1.4895, time (sec): 106466.6043\n",
      "Ep. 8004 done, reward: 10.0, running_reward: 1.5104, time (sec): 106488.2012\n",
      "Ep. 8006 done, reward: -2.0, running_reward: 1.3316, time (sec): 106512.4544\n",
      "Ep. 8008 done, reward: 4.0, running_reward: 1.4144, time (sec): 106534.0421\n",
      "Ep. 8010 done, reward: 3.0, running_reward: 1.4064, time (sec): 106562.8866\n",
      "Ep. 8012 done, reward: -1.0, running_reward: 1.3882, time (sec): 106586.1421\n",
      "Ep. 8014 done, reward: -15.0, running_reward: 1.3393, time (sec): 106604.4175\n",
      "Ep. 8016 done, reward: -1.0, running_reward: 1.3719, time (sec): 106630.5890\n",
      "Ep. 8018 done, reward: 1.0, running_reward: 1.4635, time (sec): 106655.8556\n",
      "Ep. 8020 done, reward: 4.0, running_reward: 1.3655, time (sec): 106679.6274\n",
      "Ep. 8022 done, reward: 13.0, running_reward: 1.4584, time (sec): 106702.8134\n",
      "Ep. 8024 done, reward: -2.0, running_reward: 1.4589, time (sec): 106731.4771\n",
      "Ep. 8026 done, reward: 2.0, running_reward: 1.5885, time (sec): 106755.1761\n",
      "Ep. 8028 done, reward: 15.0, running_reward: 1.6970, time (sec): 106778.0560\n",
      "Ep. 8030 done, reward: 6.0, running_reward: 1.6836, time (sec): 106800.2070\n",
      "Ep. 8032 done, reward: 4.0, running_reward: 1.6505, time (sec): 106823.6818\n",
      "Ep. 8034 done, reward: -8.0, running_reward: 1.4089, time (sec): 106846.9208\n",
      "Ep. 8036 done, reward: 3.0, running_reward: 1.3911, time (sec): 106872.4510\n",
      "Ep. 8038 done, reward: 3.0, running_reward: 1.3736, time (sec): 106897.0753\n",
      "Ep. 8040 done, reward: -6.0, running_reward: 1.3457, time (sec): 106918.1640\n",
      "Ep. 8042 done, reward: 2.0, running_reward: 1.3686, time (sec): 106945.0935\n",
      "Ep. 8044 done, reward: 8.0, running_reward: 1.4808, time (sec): 106970.0036\n",
      "Ep. 8046 done, reward: 1.0, running_reward: 1.5207, time (sec): 106993.0762\n",
      "Ep. 8048 done, reward: 9.0, running_reward: 1.4814, time (sec): 107015.0048\n",
      "Ep. 8050 done, reward: 2.0, running_reward: 1.5413, time (sec): 107044.0531\n",
      "Ep. 8052 done, reward: -4.0, running_reward: 1.5696, time (sec): 107066.8541\n",
      "Ep. 8054 done, reward: 6.0, running_reward: 1.6479, time (sec): 107093.2033\n",
      "Ep. 8056 done, reward: 6.0, running_reward: 1.7345, time (sec): 107117.8656\n",
      "Ep. 8058 done, reward: 3.0, running_reward: 1.6508, time (sec): 107142.4083\n",
      "Ep. 8060 done, reward: 4.0, running_reward: 1.5688, time (sec): 107164.4853\n",
      "Ep. 8062 done, reward: -12.0, running_reward: 1.5067, time (sec): 107187.8300\n",
      "Ep. 8064 done, reward: 6.0, running_reward: 1.6060, time (sec): 107214.2951\n",
      "Ep. 8066 done, reward: -6.0, running_reward: 1.4249, time (sec): 107238.7925\n",
      "Ep. 8068 done, reward: -4.0, running_reward: 1.4160, time (sec): 107262.6211\n",
      "Ep. 8070 done, reward: -2.0, running_reward: 1.4272, time (sec): 107290.2786\n",
      "Ep. 8072 done, reward: -7.0, running_reward: 1.2991, time (sec): 107317.6960\n",
      "Ep. 8074 done, reward: 9.0, running_reward: 1.4326, time (sec): 107337.6389\n",
      "Ep. 8076 done, reward: -8.0, running_reward: 1.4032, time (sec): 107363.4908\n",
      "Ep. 8078 done, reward: -5.0, running_reward: 1.3649, time (sec): 107391.6556\n",
      "Ep. 8080 done, reward: 5.0, running_reward: 1.3185, time (sec): 107418.7486\n",
      "Ep. 8082 done, reward: 5.0, running_reward: 1.2630, time (sec): 107444.8895\n",
      "Ep. 8084 done, reward: 2.0, running_reward: 1.3074, time (sec): 107470.3481\n",
      "Ep. 8086 done, reward: 6.0, running_reward: 1.4404, time (sec): 107490.6388\n",
      "Ep. 8088 done, reward: 5.0, running_reward: 1.5409, time (sec): 107515.8807\n",
      "Ep. 8090 done, reward: 8.0, running_reward: 1.6199, time (sec): 107542.5255\n",
      "Ep. 8092 done, reward: 8.0, running_reward: 1.6875, time (sec): 107567.6078\n",
      "Ep. 8094 done, reward: 11.0, running_reward: 1.7738, time (sec): 107589.8384\n",
      "Ep. 8096 done, reward: 13.0, running_reward: 1.9675, time (sec): 107610.4307\n",
      "Ep. 8098 done, reward: 3.0, running_reward: 1.8495, time (sec): 107636.8464\n",
      "Ep. 8100 done, reward: -9.0, running_reward: 1.7128, time (sec): 107665.3300\n",
      "Ep. 8102 done, reward: 8.0, running_reward: 1.6696, time (sec): 107685.6452\n",
      "Ep. 8104 done, reward: 9.0, running_reward: 1.8452, time (sec): 107708.2335\n",
      "Ep. 8106 done, reward: -7.0, running_reward: 1.6592, time (sec): 107733.1899\n",
      "Ep. 8108 done, reward: 2.0, running_reward: 1.7056, time (sec): 107762.8979\n",
      "Ep. 8110 done, reward: -2.0, running_reward: 1.5428, time (sec): 107790.1921\n",
      "Ep. 8112 done, reward: 11.0, running_reward: 1.5528, time (sec): 107814.0920\n",
      "Ep. 8114 done, reward: 5.0, running_reward: 1.5422, time (sec): 107841.4056\n",
      "Ep. 8116 done, reward: -3.0, running_reward: 1.5904, time (sec): 107864.5272\n",
      "Ep. 8118 done, reward: 8.0, running_reward: 1.7278, time (sec): 107885.2754\n",
      "Ep. 8120 done, reward: 9.0, running_reward: 1.8033, time (sec): 107909.1788\n",
      "Ep. 8122 done, reward: 1.0, running_reward: 1.8566, time (sec): 107934.3618\n",
      "Ep. 8124 done, reward: -2.0, running_reward: 1.9283, time (sec): 107957.2323\n",
      "Ep. 8126 done, reward: -3.0, running_reward: 1.8897, time (sec): 107983.0790\n",
      "Ep. 8128 done, reward: 4.0, running_reward: 1.9613, time (sec): 108005.6382\n",
      "Ep. 8130 done, reward: 3.0, running_reward: 1.9226, time (sec): 108031.7435\n",
      "Ep. 8132 done, reward: 2.0, running_reward: 1.8153, time (sec): 108057.6744\n",
      "Ep. 8134 done, reward: -2.0, running_reward: 1.7195, time (sec): 108083.8992\n",
      "Ep. 8136 done, reward: -4.0, running_reward: 1.6156, time (sec): 108114.3028\n",
      "Ep. 8138 done, reward: 5.0, running_reward: 1.6434, time (sec): 108140.2848\n",
      "Ep. 8140 done, reward: 10.0, running_reward: 1.7899, time (sec): 108161.1423\n",
      "Ep. 8142 done, reward: 10.0, running_reward: 1.7948, time (sec): 108181.1530\n",
      "Ep. 8144 done, reward: -3.0, running_reward: 1.8083, time (sec): 108208.8707\n",
      "Ep. 8146 done, reward: 7.0, running_reward: 1.7730, time (sec): 108231.0053\n",
      "Ep. 8148 done, reward: -1.0, running_reward: 1.8268, time (sec): 108256.9073\n",
      "Ep. 8150 done, reward: 12.0, running_reward: 1.8411, time (sec): 108277.1132\n",
      "Ep. 8152 done, reward: -8.0, running_reward: 1.7641, time (sec): 108305.7268\n",
      "Ep. 8154 done, reward: -5.0, running_reward: 1.7483, time (sec): 108332.2238\n",
      "Ep. 8156 done, reward: 10.0, running_reward: 1.7442, time (sec): 108356.5426\n",
      "Ep. 8158 done, reward: -1.0, running_reward: 1.7985, time (sec): 108382.6073\n",
      "Ep. 8160 done, reward: -6.0, running_reward: 1.6532, time (sec): 108407.6202\n",
      "Ep. 8162 done, reward: -3.0, running_reward: 1.5012, time (sec): 108433.0367\n",
      "Ep. 8164 done, reward: -3.0, running_reward: 1.4314, time (sec): 108461.7848\n",
      "Ep. 8166 done, reward: -1.0, running_reward: 1.4919, time (sec): 108483.6241\n",
      "Ep. 8168 done, reward: 7.0, running_reward: 1.6114, time (sec): 108503.8851\n",
      "Ep. 8170 done, reward: 3.0, running_reward: 1.5698, time (sec): 108532.6958\n",
      "Ep. 8172 done, reward: -5.0, running_reward: 1.4489, time (sec): 108560.0049\n",
      "Ep. 8174 done, reward: -7.0, running_reward: 1.3204, time (sec): 108584.0306\n",
      "Ep. 8176 done, reward: -3.0, running_reward: 1.2542, time (sec): 108610.6498\n",
      "Ep. 8178 done, reward: -3.0, running_reward: 1.3280, time (sec): 108634.0763\n",
      "Ep. 8180 done, reward: 1.0, running_reward: 1.2521, time (sec): 108662.6539\n",
      "Ep. 8182 done, reward: -1.0, running_reward: 1.1875, time (sec): 108692.2376\n",
      "Ep. 8184 done, reward: 1.0, running_reward: 1.2135, time (sec): 108715.9382\n",
      "Ep. 8186 done, reward: 8.0, running_reward: 1.3188, time (sec): 108738.6834\n",
      "Ep. 8188 done, reward: 11.0, running_reward: 1.4521, time (sec): 108763.2804\n",
      "Ep. 8190 done, reward: 13.0, running_reward: 1.6423, time (sec): 108785.8637\n",
      "Ep. 8192 done, reward: -4.0, running_reward: 1.7478, time (sec): 108807.7859\n",
      "Ep. 8194 done, reward: 7.0, running_reward: 1.7236, time (sec): 108831.2462\n",
      "Ep. 8196 done, reward: -1.0, running_reward: 1.6892, time (sec): 108859.7291\n",
      "Ep. 8198 done, reward: -5.0, running_reward: 1.6551, time (sec): 108886.9609\n",
      "Ep. 8200 done, reward: -5.0, running_reward: 1.5128, time (sec): 108913.8928\n",
      "Ep. 8202 done, reward: 1.0, running_reward: 1.3838, time (sec): 108942.8297\n",
      "Ep. 8204 done, reward: 6.0, running_reward: 1.5251, time (sec): 108964.8843\n",
      "Ep. 8206 done, reward: 4.0, running_reward: 1.7130, time (sec): 108987.5708\n",
      "Ep. 8208 done, reward: -3.0, running_reward: 1.6588, time (sec): 109012.6113\n",
      "Ep. 8210 done, reward: 5.0, running_reward: 1.7550, time (sec): 109039.8864\n",
      "Ep. 8212 done, reward: 8.0, running_reward: 1.7704, time (sec): 109063.0872\n",
      "Ep. 8214 done, reward: 11.0, running_reward: 1.8154, time (sec): 109084.1509\n",
      "Ep. 8216 done, reward: -5.0, running_reward: 1.7491, time (sec): 109113.6849\n",
      "Ep. 8218 done, reward: -3.0, running_reward: 1.7833, time (sec): 109137.8691\n",
      "Ep. 8220 done, reward: -7.0, running_reward: 1.7768, time (sec): 109162.6823\n",
      "Ep. 8222 done, reward: -9.0, running_reward: 1.5920, time (sec): 109190.9783\n",
      "Ep. 8224 done, reward: -3.0, running_reward: 1.6096, time (sec): 109215.2920\n",
      "Ep. 8226 done, reward: -16.0, running_reward: 1.5561, time (sec): 109232.3664\n",
      "Ep. 8228 done, reward: -8.0, running_reward: 1.5343, time (sec): 109254.6358\n",
      "Ep. 8230 done, reward: -10.0, running_reward: 1.3839, time (sec): 109286.2444\n",
      "Ep. 8232 done, reward: -1.0, running_reward: 1.3563, time (sec): 109318.1829\n",
      "Ep. 8234 done, reward: 10.0, running_reward: 1.4887, time (sec): 109338.2754\n",
      "Ep. 8236 done, reward: 8.0, running_reward: 1.6381, time (sec): 109358.6035\n",
      "Ep. 8238 done, reward: 2.0, running_reward: 1.7245, time (sec): 109380.9737\n",
      "Ep. 8240 done, reward: 11.0, running_reward: 1.8596, time (sec): 109403.7590\n",
      "Ep. 8242 done, reward: -1.0, running_reward: 1.8225, time (sec): 109433.7097\n",
      "Ep. 8244 done, reward: 11.0, running_reward: 1.8269, time (sec): 109457.4108\n",
      "Ep. 8246 done, reward: -10.0, running_reward: 1.7796, time (sec): 109483.6208\n",
      "Ep. 8248 done, reward: 10.0, running_reward: 1.8640, time (sec): 109510.4660\n",
      "Ep. 8250 done, reward: -7.0, running_reward: 1.7668, time (sec): 109538.7647\n",
      "Ep. 8252 done, reward: 5.0, running_reward: 1.7520, time (sec): 109561.0766\n",
      "Ep. 8254 done, reward: -4.0, running_reward: 1.7464, time (sec): 109584.1658\n",
      "Ep. 8256 done, reward: 7.0, running_reward: 1.7718, time (sec): 109610.8494\n",
      "Ep. 8258 done, reward: 6.0, running_reward: 1.8658, time (sec): 109637.8735\n",
      "Ep. 8260 done, reward: 7.0, running_reward: 1.9482, time (sec): 109664.8349\n",
      "Ep. 8262 done, reward: 7.0, running_reward: 1.9992, time (sec): 109692.5564\n",
      "Ep. 8264 done, reward: -3.0, running_reward: 1.9096, time (sec): 109721.9086\n",
      "Ep. 8266 done, reward: -3.0, running_reward: 1.8614, time (sec): 109750.4509\n",
      "Ep. 8268 done, reward: 1.0, running_reward: 1.7453, time (sec): 109774.3377\n",
      "Ep. 8270 done, reward: 5.0, running_reward: 1.6516, time (sec): 109798.4068\n",
      "Ep. 8272 done, reward: -3.0, running_reward: 1.5987, time (sec): 109827.0144\n",
      "Ep. 8274 done, reward: 9.0, running_reward: 1.6866, time (sec): 109851.0214\n",
      "Ep. 8276 done, reward: 4.0, running_reward: 1.7227, time (sec): 109878.4641\n",
      "Ep. 8278 done, reward: -5.0, running_reward: 1.5889, time (sec): 109903.7105\n",
      "Ep. 8280 done, reward: 8.0, running_reward: 1.6472, time (sec): 109927.5963\n",
      "Ep. 8282 done, reward: -7.0, running_reward: 1.5840, time (sec): 109950.3235\n",
      "Ep. 8284 done, reward: 8.0, running_reward: 1.7018, time (sec): 109971.8857\n",
      "Ep. 8286 done, reward: -5.0, running_reward: 1.6575, time (sec): 110002.5955\n",
      "Ep. 8288 done, reward: 9.0, running_reward: 1.7838, time (sec): 110022.9185\n",
      "Ep. 8290 done, reward: 2.0, running_reward: 1.8079, time (sec): 110050.1826\n",
      "Ep. 8292 done, reward: 2.0, running_reward: 1.9108, time (sec): 110071.8153\n",
      "Ep. 8294 done, reward: -1.0, running_reward: 1.8528, time (sec): 110101.0780\n",
      "Ep. 8296 done, reward: 11.0, running_reward: 1.8963, time (sec): 110121.7272\n",
      "Ep. 8298 done, reward: 4.0, running_reward: 1.9579, time (sec): 110144.8813\n",
      "Ep. 8300 done, reward: -3.0, running_reward: 1.9484, time (sec): 110172.7105\n",
      "Ep. 8302 done, reward: -4.0, running_reward: 1.7805, time (sec): 110197.8039\n",
      "Ep. 8304 done, reward: -9.0, running_reward: 1.6353, time (sec): 110221.2188\n",
      "Ep. 8306 done, reward: 5.0, running_reward: 1.7616, time (sec): 110243.2220\n",
      "Ep. 8308 done, reward: -7.0, running_reward: 1.6269, time (sec): 110269.9551\n",
      "Ep. 8310 done, reward: 8.0, running_reward: 1.5953, time (sec): 110294.1065\n",
      "Ep. 8312 done, reward: -1.0, running_reward: 1.6723, time (sec): 110319.8769\n",
      "Ep. 8314 done, reward: -1.0, running_reward: 1.6489, time (sec): 110347.7407\n",
      "Ep. 8316 done, reward: 3.0, running_reward: 1.6560, time (sec): 110374.9159\n",
      "Ep. 8318 done, reward: 3.0, running_reward: 1.6332, time (sec): 110402.3986\n",
      "Ep. 8320 done, reward: 7.0, running_reward: 1.7004, time (sec): 110425.5066\n",
      "Ep. 8322 done, reward: 9.0, running_reward: 1.7269, time (sec): 110449.6709\n",
      "Ep. 8324 done, reward: 1.0, running_reward: 1.6530, time (sec): 110479.6100\n",
      "Ep. 8326 done, reward: -5.0, running_reward: 1.6097, time (sec): 110503.6355\n",
      "Ep. 8328 done, reward: 2.0, running_reward: 1.5680, time (sec): 110533.4429\n",
      "Ep. 8330 done, reward: 7.0, running_reward: 1.6266, time (sec): 110559.4800\n",
      "Ep. 8332 done, reward: 4.0, running_reward: 1.7332, time (sec): 110583.1197\n",
      "Ep. 8334 done, reward: 2.0, running_reward: 1.6098, time (sec): 110608.8414\n",
      "Ep. 8336 done, reward: 8.0, running_reward: 1.6875, time (sec): 110633.6078\n",
      "Ep. 8338 done, reward: 3.0, running_reward: 1.7334, time (sec): 110659.4297\n",
      "Ep. 8340 done, reward: 4.0, running_reward: 1.8280, time (sec): 110681.5087\n",
      "Ep. 8342 done, reward: -5.0, running_reward: 1.7614, time (sec): 110707.7044\n",
      "Ep. 8344 done, reward: 12.0, running_reward: 1.8365, time (sec): 110731.6766\n",
      "Ep. 8346 done, reward: 6.0, running_reward: 1.9391, time (sec): 110753.4773\n",
      "Ep. 8348 done, reward: 1.0, running_reward: 1.9501, time (sec): 110780.8728\n",
      "Ep. 8350 done, reward: 6.0, running_reward: 1.9911, time (sec): 110810.2937\n",
      "Ep. 8352 done, reward: 11.0, running_reward: 2.1308, time (sec): 110828.9424\n",
      "Ep. 8354 done, reward: 7.0, running_reward: 2.2178, time (sec): 110853.8433\n",
      "Ep. 8356 done, reward: 14.0, running_reward: 2.3434, time (sec): 110876.4315\n",
      "Ep. 8358 done, reward: 2.0, running_reward: 2.2870, time (sec): 110904.6867\n",
      "Ep. 8360 done, reward: 5.0, running_reward: 2.2717, time (sec): 110932.6312\n",
      "Ep. 8362 done, reward: 6.0, running_reward: 2.2667, time (sec): 110960.6833\n",
      "Ep. 8364 done, reward: 6.0, running_reward: 2.3410, time (sec): 110986.1606\n",
      "Ep. 8366 done, reward: 1.0, running_reward: 2.3341, time (sec): 111013.9360\n",
      "Ep. 8368 done, reward: 8.0, running_reward: 2.4172, time (sec): 111040.0220\n",
      "Ep. 8370 done, reward: 5.0, running_reward: 2.5181, time (sec): 111064.6268\n",
      "Ep. 8372 done, reward: 8.0, running_reward: 2.6272, time (sec): 111085.9560\n",
      "Ep. 8374 done, reward: 1.0, running_reward: 2.7037, time (sec): 111109.8842\n",
      "Ep. 8376 done, reward: 9.0, running_reward: 2.7498, time (sec): 111136.1599\n",
      "Ep. 8378 done, reward: 10.0, running_reward: 2.8248, time (sec): 111162.2921\n",
      "Ep. 8380 done, reward: 3.0, running_reward: 2.7886, time (sec): 111188.9270\n",
      "Ep. 8382 done, reward: 4.0, running_reward: 2.7830, time (sec): 111218.6396\n",
      "Ep. 8384 done, reward: -3.0, running_reward: 2.7175, time (sec): 111246.5440\n",
      "Ep. 8386 done, reward: -1.0, running_reward: 2.6336, time (sec): 111273.1058\n",
      "Ep. 8388 done, reward: 12.0, running_reward: 2.7111, time (sec): 111296.4354\n",
      "Ep. 8390 done, reward: 10.0, running_reward: 2.8363, time (sec): 111316.5519\n",
      "Ep. 8392 done, reward: 2.0, running_reward: 2.8098, time (sec): 111346.8029\n",
      "Ep. 8394 done, reward: 5.0, running_reward: 2.7445, time (sec): 111374.7871\n",
      "Ep. 8396 done, reward: -3.0, running_reward: 2.7391, time (sec): 111399.3802\n",
      "Ep. 8398 done, reward: 6.0, running_reward: 2.8337, time (sec): 111420.1253\n",
      "Ep. 8400 done, reward: 9.0, running_reward: 2.7980, time (sec): 111444.9244\n",
      "Ep. 8402 done, reward: 2.0, running_reward: 2.7326, time (sec): 111470.9760\n",
      "Ep. 8404 done, reward: 5.0, running_reward: 2.7381, time (sec): 111496.7437\n",
      "Ep. 8406 done, reward: -6.0, running_reward: 2.6137, time (sec): 111526.3231\n",
      "Ep. 8408 done, reward: 5.0, running_reward: 2.5919, time (sec): 111555.6592\n",
      "Ep. 8410 done, reward: 7.0, running_reward: 2.6697, time (sec): 111580.4497\n",
      "Ep. 8412 done, reward: 11.0, running_reward: 2.7860, time (sec): 111602.6617\n",
      "Ep. 8414 done, reward: 11.0, running_reward: 2.9594, time (sec): 111622.7153\n",
      "Ep. 8416 done, reward: 7.0, running_reward: 3.0002, time (sec): 111646.1068\n",
      "Ep. 8418 done, reward: 4.0, running_reward: 2.9310, time (sec): 111674.3446\n",
      "Ep. 8420 done, reward: 8.0, running_reward: 2.9625, time (sec): 111699.6167\n",
      "Ep. 8422 done, reward: 1.0, running_reward: 2.9235, time (sec): 111730.4787\n",
      "Ep. 8424 done, reward: -3.0, running_reward: 2.9541, time (sec): 111752.8293\n",
      "Ep. 8426 done, reward: 4.0, running_reward: 3.0541, time (sec): 111774.9524\n",
      "Ep. 8428 done, reward: 4.0, running_reward: 3.0135, time (sec): 111803.4076\n",
      "Ep. 8430 done, reward: 7.0, running_reward: 3.0533, time (sec): 111824.8036\n",
      "Ep. 8432 done, reward: 13.0, running_reward: 3.0829, time (sec): 111846.0820\n",
      "Ep. 8434 done, reward: 5.0, running_reward: 3.1013, time (sec): 111871.3757\n",
      "Ep. 8436 done, reward: 6.0, running_reward: 3.1688, time (sec): 111898.0398\n",
      "Ep. 8438 done, reward: 11.0, running_reward: 3.3346, time (sec): 111918.3368\n",
      "Ep. 8440 done, reward: 7.0, running_reward: 3.4867, time (sec): 111939.2161\n",
      "Ep. 8442 done, reward: 6.0, running_reward: 3.4872, time (sec): 111964.8262\n",
      "Ep. 8444 done, reward: 7.0, running_reward: 3.4482, time (sec): 111990.0099\n",
      "Ep. 8446 done, reward: 8.0, running_reward: 3.5190, time (sec): 112013.6561\n",
      "Ep. 8448 done, reward: 7.0, running_reward: 3.6279, time (sec): 112036.3683\n",
      "Ep. 8450 done, reward: 8.0, running_reward: 3.6654, time (sec): 112064.8892\n",
      "Ep. 8452 done, reward: 9.0, running_reward: 3.7419, time (sec): 112089.0523\n",
      "Ep. 8454 done, reward: 7.0, running_reward: 3.7572, time (sec): 112114.4206\n",
      "Ep. 8456 done, reward: 5.0, running_reward: 3.7522, time (sec): 112142.9575\n",
      "Ep. 8458 done, reward: 1.0, running_reward: 3.6579, time (sec): 112175.0924\n",
      "Ep. 8460 done, reward: 2.0, running_reward: 3.5952, time (sec): 112200.7051\n",
      "Ep. 8462 done, reward: 2.0, running_reward: 3.6525, time (sec): 112223.5986\n",
      "Ep. 8464 done, reward: 9.0, running_reward: 3.6203, time (sec): 112251.8566\n",
      "Ep. 8466 done, reward: 11.0, running_reward: 3.6979, time (sec): 112274.7064\n",
      "Ep. 8468 done, reward: 3.0, running_reward: 3.6939, time (sec): 112303.6526\n",
      "Ep. 8470 done, reward: 3.0, running_reward: 3.6207, time (sec): 112329.6813\n",
      "Ep. 8472 done, reward: 2.0, running_reward: 3.6478, time (sec): 112353.9758\n",
      "Ep. 8474 done, reward: -10.0, running_reward: 3.4159, time (sec): 112375.0568\n",
      "Ep. 8476 done, reward: 7.0, running_reward: 3.4476, time (sec): 112401.7422\n",
      "Ep. 8478 done, reward: 11.0, running_reward: 3.5880, time (sec): 112426.5677\n",
      "Ep. 8480 done, reward: -6.0, running_reward: 3.5358, time (sec): 112451.1594\n",
      "Ep. 8482 done, reward: -3.0, running_reward: 3.5542, time (sec): 112474.3149\n",
      "Ep. 8484 done, reward: -13.0, running_reward: 3.3337, time (sec): 112499.8703\n",
      "Ep. 8486 done, reward: 4.0, running_reward: 3.3469, time (sec): 112524.1215\n",
      "Ep. 8488 done, reward: 11.0, running_reward: 3.3507, time (sec): 112545.7762\n",
      "Ep. 8490 done, reward: 2.0, running_reward: 3.3338, time (sec): 112573.4023\n",
      "Ep. 8492 done, reward: 9.0, running_reward: 3.4267, time (sec): 112598.2204\n",
      "Ep. 8494 done, reward: 6.0, running_reward: 3.3591, time (sec): 112623.4133\n",
      "Ep. 8496 done, reward: 7.0, running_reward: 3.4811, time (sec): 112646.2260\n",
      "Ep. 8498 done, reward: 2.0, running_reward: 3.4417, time (sec): 112678.4881\n",
      "Ep. 8500 done, reward: -4.0, running_reward: 3.3728, time (sec): 112705.3263\n",
      "Ep. 8502 done, reward: 2.0, running_reward: 3.2366, time (sec): 112733.5259\n",
      "Ep. 8504 done, reward: 3.0, running_reward: 3.2121, time (sec): 112761.5643\n",
      "Ep. 8506 done, reward: 5.0, running_reward: 3.1388, time (sec): 112786.8767\n",
      "Ep. 8508 done, reward: 5.0, running_reward: 3.1065, time (sec): 112813.5357\n",
      "Ep. 8510 done, reward: 4.0, running_reward: 3.0154, time (sec): 112838.1961\n",
      "Ep. 8512 done, reward: -2.0, running_reward: 2.9057, time (sec): 112868.3008\n",
      "Ep. 8514 done, reward: -5.0, running_reward: 2.8573, time (sec): 112891.9413\n",
      "Ep. 8516 done, reward: 9.0, running_reward: 2.8607, time (sec): 112919.3354\n",
      "Ep. 8518 done, reward: -1.0, running_reward: 2.7542, time (sec): 112948.2118\n",
      "Ep. 8520 done, reward: 12.0, running_reward: 2.7996, time (sec): 112973.1950\n",
      "Ep. 8522 done, reward: -5.0, running_reward: 2.7136, time (sec): 112998.9415\n",
      "Ep. 8524 done, reward: -1.0, running_reward: 2.5605, time (sec): 113023.4916\n",
      "Ep. 8526 done, reward: -5.0, running_reward: 2.4695, time (sec): 113053.0010\n",
      "Ep. 8528 done, reward: 2.0, running_reward: 2.4700, time (sec): 113080.0455\n",
      "Ep. 8530 done, reward: 6.0, running_reward: 2.4611, time (sec): 113103.7038\n",
      "Ep. 8532 done, reward: 7.0, running_reward: 2.3732, time (sec): 113129.1410\n",
      "Ep. 8534 done, reward: 3.0, running_reward: 2.4055, time (sec): 113156.7255\n",
      "Ep. 8536 done, reward: -9.0, running_reward: 2.2181, time (sec): 113184.7010\n",
      "Ep. 8538 done, reward: 7.0, running_reward: 2.2737, time (sec): 113208.1665\n",
      "Ep. 8540 done, reward: -1.0, running_reward: 2.1788, time (sec): 113235.1520\n",
      "Ep. 8542 done, reward: 2.0, running_reward: 2.1753, time (sec): 113264.0182\n",
      "Ep. 8544 done, reward: 7.0, running_reward: 2.2614, time (sec): 113288.8900\n",
      "Ep. 8546 done, reward: 8.0, running_reward: 2.2865, time (sec): 113315.4852\n",
      "Ep. 8548 done, reward: -4.0, running_reward: 2.2802, time (sec): 113341.1653\n",
      "Ep. 8550 done, reward: 1.0, running_reward: 2.2151, time (sec): 113367.8745\n",
      "Ep. 8552 done, reward: 4.0, running_reward: 2.2209, time (sec): 113393.5938\n",
      "Ep. 8554 done, reward: -1.0, running_reward: 2.1370, time (sec): 113423.0943\n",
      "Ep. 8556 done, reward: -7.0, running_reward: 2.1829, time (sec): 113446.0550\n",
      "Ep. 8558 done, reward: -3.0, running_reward: 2.0897, time (sec): 113473.0735\n",
      "Ep. 8560 done, reward: 5.0, running_reward: 1.9694, time (sec): 113498.6069\n",
      "Ep. 8562 done, reward: -4.0, running_reward: 1.7912, time (sec): 113525.0754\n",
      "Ep. 8564 done, reward: 6.0, running_reward: 1.8551, time (sec): 113550.5921\n",
      "Ep. 8566 done, reward: -11.0, running_reward: 1.6587, time (sec): 113576.3352\n",
      "Ep. 8568 done, reward: -2.0, running_reward: 1.7146, time (sec): 113600.7405\n",
      "Ep. 8570 done, reward: -3.0, running_reward: 1.6604, time (sec): 113630.8870\n",
      "Ep. 8572 done, reward: -6.0, running_reward: 1.5377, time (sec): 113662.3748\n",
      "Ep. 8574 done, reward: -5.0, running_reward: 1.5264, time (sec): 113688.1963\n",
      "Ep. 8576 done, reward: 1.0, running_reward: 1.5159, time (sec): 113719.8859\n",
      "Ep. 8578 done, reward: 5.0, running_reward: 1.5258, time (sec): 113752.2153\n",
      "Ep. 8580 done, reward: 10.0, running_reward: 1.5856, time (sec): 113775.3847\n",
      "Ep. 8582 done, reward: 8.0, running_reward: 1.6835, time (sec): 113796.7462\n",
      "Ep. 8584 done, reward: 13.0, running_reward: 1.8295, time (sec): 113820.8515\n",
      "Ep. 8586 done, reward: -2.0, running_reward: 1.7830, time (sec): 113848.5870\n",
      "Ep. 8588 done, reward: 4.0, running_reward: 1.8766, time (sec): 113875.9652\n",
      "Ep. 8590 done, reward: -4.0, running_reward: 1.7795, time (sec): 113902.4619\n",
      "Ep. 8592 done, reward: 7.0, running_reward: 1.8933, time (sec): 113926.8957\n",
      "Ep. 8594 done, reward: 6.0, running_reward: 1.8661, time (sec): 113952.6519\n",
      "Ep. 8596 done, reward: -3.0, running_reward: 1.8484, time (sec): 113980.6313\n",
      "Ep. 8598 done, reward: 4.0, running_reward: 1.9507, time (sec): 114002.0595\n",
      "Ep. 8600 done, reward: 2.0, running_reward: 1.9912, time (sec): 114029.4834\n",
      "Ep. 8602 done, reward: 3.0, running_reward: 2.0608, time (sec): 114051.5792\n",
      "Ep. 8604 done, reward: -6.0, running_reward: 1.9103, time (sec): 114076.2634\n",
      "Ep. 8606 done, reward: 4.0, running_reward: 2.0113, time (sec): 114098.6055\n",
      "Ep. 8608 done, reward: -10.0, running_reward: 1.9208, time (sec): 114120.9936\n",
      "Ep. 8610 done, reward: 12.0, running_reward: 1.9431, time (sec): 114143.7975\n",
      "Ep. 8612 done, reward: 10.0, running_reward: 2.0144, time (sec): 114169.0761\n",
      "Ep. 8614 done, reward: 10.0, running_reward: 2.0644, time (sec): 114190.1759\n",
      "Ep. 8616 done, reward: 6.0, running_reward: 2.0140, time (sec): 114214.0923\n",
      "Ep. 8618 done, reward: 1.0, running_reward: 2.0037, time (sec): 114243.4038\n",
      "Ep. 8620 done, reward: 8.0, running_reward: 2.0637, time (sec): 114271.7339\n",
      "Ep. 8622 done, reward: 1.0, running_reward: 2.0722, time (sec): 114299.7642\n",
      "Ep. 8624 done, reward: 14.0, running_reward: 2.2304, time (sec): 114321.4365\n",
      "Ep. 8626 done, reward: 10.0, running_reward: 2.3850, time (sec): 114343.3213\n",
      "Ep. 8628 done, reward: 4.0, running_reward: 2.4072, time (sec): 114368.6600\n",
      "Ep. 8630 done, reward: 6.0, running_reward: 2.3698, time (sec): 114396.9600\n",
      "Ep. 8632 done, reward: -8.0, running_reward: 2.2228, time (sec): 114425.0550\n",
      "Ep. 8634 done, reward: 2.0, running_reward: 2.1689, time (sec): 114451.0595\n",
      "Ep. 8636 done, reward: -3.0, running_reward: 2.1353, time (sec): 114475.8546\n",
      "Ep. 8638 done, reward: 2.0, running_reward: 2.1624, time (sec): 114500.8933\n",
      "Ep. 8640 done, reward: -1.0, running_reward: 2.1192, time (sec): 114531.1873\n",
      "Ep. 8642 done, reward: 14.0, running_reward: 2.2369, time (sec): 114560.5658\n",
      "Ep. 8644 done, reward: -11.0, running_reward: 2.0526, time (sec): 114587.3817\n",
      "Ep. 8646 done, reward: -7.0, running_reward: 2.0309, time (sec): 114612.5303\n",
      "Ep. 8648 done, reward: 7.0, running_reward: 2.0308, time (sec): 114639.4434\n",
      "Ep. 8650 done, reward: 1.0, running_reward: 2.0103, time (sec): 114667.6287\n",
      "Ep. 8652 done, reward: 4.0, running_reward: 2.0499, time (sec): 114693.8620\n",
      "Ep. 8654 done, reward: -2.0, running_reward: 1.8604, time (sec): 114718.8851\n",
      "Ep. 8656 done, reward: 5.0, running_reward: 1.9129, time (sec): 114743.9496\n",
      "Ep. 8658 done, reward: -11.0, running_reward: 1.7352, time (sec): 114770.4701\n",
      "Ep. 8660 done, reward: 6.0, running_reward: 1.7408, time (sec): 114797.2264\n",
      "Ep. 8662 done, reward: 5.0, running_reward: 1.6275, time (sec): 114822.9110\n",
      "Ep. 8664 done, reward: 2.0, running_reward: 1.7141, time (sec): 114846.0361\n",
      "Ep. 8666 done, reward: 15.0, running_reward: 1.9587, time (sec): 114864.0309\n",
      "Ep. 8668 done, reward: -1.0, running_reward: 2.0582, time (sec): 114887.8137\n",
      "Ep. 8670 done, reward: 3.0, running_reward: 1.9780, time (sec): 114916.3531\n",
      "Ep. 8672 done, reward: 2.0, running_reward: 1.8893, time (sec): 114944.0645\n",
      "Ep. 8674 done, reward: 13.0, running_reward: 2.0015, time (sec): 114967.4914\n",
      "Ep. 8676 done, reward: -3.0, running_reward: 2.0307, time (sec): 114992.1366\n",
      "Ep. 8678 done, reward: -5.0, running_reward: 1.8710, time (sec): 115020.6171\n",
      "Ep. 8680 done, reward: 12.0, running_reward: 2.0329, time (sec): 115043.7435\n",
      "Ep. 8682 done, reward: -4.0, running_reward: 1.9327, time (sec): 115073.1806\n",
      "Ep. 8684 done, reward: 5.0, running_reward: 1.9838, time (sec): 115099.3905\n",
      "Ep. 8686 done, reward: 6.0, running_reward: 2.1033, time (sec): 115124.9972\n",
      "Ep. 8688 done, reward: 11.0, running_reward: 2.1517, time (sec): 115151.7534\n",
      "Ep. 8690 done, reward: 7.0, running_reward: 2.1888, time (sec): 115177.6268\n",
      "Ep. 8692 done, reward: -3.0, running_reward: 2.0063, time (sec): 115207.2816\n",
      "Ep. 8694 done, reward: -1.0, running_reward: 1.9762, time (sec): 115235.4769\n",
      "Ep. 8696 done, reward: -2.0, running_reward: 1.8773, time (sec): 115262.3385\n",
      "Ep. 8698 done, reward: 7.0, running_reward: 1.9495, time (sec): 115291.5950\n",
      "Ep. 8700 done, reward: -3.0, running_reward: 1.9104, time (sec): 115319.9939\n",
      "Ep. 8702 done, reward: 1.0, running_reward: 1.8032, time (sec): 115346.4111\n",
      "Ep. 8704 done, reward: 11.0, running_reward: 1.9367, time (sec): 115369.1972\n",
      "Ep. 8706 done, reward: 2.0, running_reward: 1.8984, time (sec): 115396.3902\n",
      "Ep. 8708 done, reward: -4.0, running_reward: 1.8503, time (sec): 115423.9904\n",
      "Ep. 8710 done, reward: 7.0, running_reward: 1.9924, time (sec): 115447.9867\n",
      "Ep. 8712 done, reward: -6.0, running_reward: 1.9323, time (sec): 115473.9390\n",
      "Ep. 8714 done, reward: 6.0, running_reward: 1.9935, time (sec): 115502.1627\n",
      "Ep. 8716 done, reward: -5.0, running_reward: 1.8741, time (sec): 115527.1436\n",
      "Ep. 8718 done, reward: 5.0, running_reward: 1.9462, time (sec): 115554.8392\n",
      "Ep. 8720 done, reward: 6.0, running_reward: 1.9576, time (sec): 115580.7454\n",
      "Ep. 8722 done, reward: -10.0, running_reward: 1.7196, time (sec): 115604.2301\n",
      "Ep. 8724 done, reward: 3.0, running_reward: 1.6857, time (sec): 115632.2143\n",
      "Ep. 8726 done, reward: -5.0, running_reward: 1.6913, time (sec): 115656.0013\n",
      "Ep. 8728 done, reward: -6.0, running_reward: 1.4887, time (sec): 115677.9760\n",
      "Ep. 8730 done, reward: 10.0, running_reward: 1.5888, time (sec): 115700.3892\n",
      "Ep. 8732 done, reward: -5.0, running_reward: 1.5864, time (sec): 115724.1196\n",
      "Ep. 8734 done, reward: 6.0, running_reward: 1.7930, time (sec): 115743.2491\n",
      "Ep. 8736 done, reward: 11.0, running_reward: 1.8178, time (sec): 115767.0688\n",
      "Ep. 8738 done, reward: -5.0, running_reward: 1.6425, time (sec): 115790.4063\n",
      "Ep. 8740 done, reward: -2.0, running_reward: 1.5007, time (sec): 115817.0724\n",
      "Ep. 8742 done, reward: -1.0, running_reward: 1.5005, time (sec): 115843.4628\n",
      "Ep. 8744 done, reward: 9.0, running_reward: 1.5804, time (sec): 115869.2334\n",
      "Ep. 8746 done, reward: 6.0, running_reward: 1.5397, time (sec): 115896.4935\n",
      "Ep. 8748 done, reward: -9.0, running_reward: 1.3992, time (sec): 115923.7868\n",
      "Ep. 8750 done, reward: 1.0, running_reward: 1.4111, time (sec): 115947.8533\n",
      "Ep. 8752 done, reward: 4.0, running_reward: 1.4923, time (sec): 115976.9750\n",
      "Ep. 8754 done, reward: -2.0, running_reward: 1.5020, time (sec): 116003.0354\n",
      "Ep. 8756 done, reward: -6.0, running_reward: 1.4418, time (sec): 116025.6452\n",
      "Ep. 8758 done, reward: 1.0, running_reward: 1.4528, time (sec): 116051.2155\n",
      "Ep. 8760 done, reward: -6.0, running_reward: 1.4926, time (sec): 116074.2106\n",
      "Ep. 8762 done, reward: -3.0, running_reward: 1.5022, time (sec): 116100.3923\n",
      "Ep. 8764 done, reward: -9.0, running_reward: 1.4417, time (sec): 116124.7269\n",
      "Ep. 8766 done, reward: -5.0, running_reward: 1.3927, time (sec): 116148.3268\n",
      "Ep. 8768 done, reward: 2.0, running_reward: 1.4147, time (sec): 116181.9327\n",
      "Ep. 8770 done, reward: 7.0, running_reward: 1.4863, time (sec): 116208.2300\n",
      "Ep. 8772 done, reward: 2.0, running_reward: 1.5757, time (sec): 116231.4313\n",
      "Ep. 8774 done, reward: -11.0, running_reward: 1.4838, time (sec): 116253.4285\n",
      "Ep. 8776 done, reward: 10.0, running_reward: 1.5444, time (sec): 116279.7296\n",
      "Ep. 8778 done, reward: 6.0, running_reward: 1.5242, time (sec): 116302.7388\n",
      "Ep. 8780 done, reward: 4.0, running_reward: 1.4645, time (sec): 116326.5928\n",
      "Ep. 8782 done, reward: 1.0, running_reward: 1.4553, time (sec): 116357.6506\n",
      "Ep. 8784 done, reward: 4.0, running_reward: 1.4960, time (sec): 116383.2975\n",
      "Ep. 8786 done, reward: -11.0, running_reward: 1.3761, time (sec): 116409.5510\n",
      "Ep. 8788 done, reward: -3.0, running_reward: 1.4177, time (sec): 116433.1469\n",
      "Ep. 8790 done, reward: -6.0, running_reward: 1.3196, time (sec): 116461.4117\n",
      "Ep. 8792 done, reward: -3.0, running_reward: 1.2435, time (sec): 116488.5944\n",
      "Ep. 8794 done, reward: -8.0, running_reward: 1.0992, time (sec): 116516.4136\n",
      "Ep. 8796 done, reward: 3.0, running_reward: 1.1667, time (sec): 116544.4489\n",
      "Ep. 8798 done, reward: 1.0, running_reward: 1.1634, time (sec): 116570.6678\n",
      "Ep. 8800 done, reward: 8.0, running_reward: 1.2598, time (sec): 116595.8491\n",
      "Ep. 8802 done, reward: 6.0, running_reward: 1.2749, time (sec): 116621.0223\n",
      "Ep. 8804 done, reward: 5.0, running_reward: 1.2699, time (sec): 116647.7585\n",
      "Ep. 8806 done, reward: 11.0, running_reward: 1.2259, time (sec): 116669.0768\n",
      "Ep. 8808 done, reward: -1.0, running_reward: 1.2014, time (sec): 116697.1030\n",
      "Ep. 8810 done, reward: -2.0, running_reward: 1.2466, time (sec): 116719.8783\n",
      "Ep. 8812 done, reward: 9.0, running_reward: 1.3019, time (sec): 116745.0737\n",
      "Ep. 8814 done, reward: -15.0, running_reward: 1.1458, time (sec): 116772.4572\n",
      "Ep. 8816 done, reward: 7.0, running_reward: 1.2227, time (sec): 116796.2562\n",
      "Ep. 8818 done, reward: 1.0, running_reward: 1.1985, time (sec): 116826.6874\n",
      "Ep. 8820 done, reward: -9.0, running_reward: 1.1341, time (sec): 116851.8523\n",
      "Ep. 8822 done, reward: 1.0, running_reward: 1.1710, time (sec): 116878.7754\n",
      "Ep. 8824 done, reward: 5.0, running_reward: 1.2571, time (sec): 116907.5183\n",
      "Ep. 8826 done, reward: -7.0, running_reward: 1.1720, time (sec): 116936.9188\n",
      "Ep. 8828 done, reward: -2.0, running_reward: 1.1485, time (sec): 116966.1362\n",
      "Ep. 8830 done, reward: -9.0, running_reward: 1.1643, time (sec): 116988.6980\n",
      "Ep. 8832 done, reward: 8.0, running_reward: 1.1321, time (sec): 117012.7731\n",
      "Ep. 8834 done, reward: 1.0, running_reward: 1.1294, time (sec): 117040.7008\n",
      "Ep. 8836 done, reward: -5.0, running_reward: 1.1065, time (sec): 117066.2125\n",
      "Ep. 8838 done, reward: -6.0, running_reward: 0.9353, time (sec): 117090.1190\n",
      "Ep. 8840 done, reward: -2.0, running_reward: 0.7977, time (sec): 117113.8540\n",
      "Ep. 8842 done, reward: -7.0, running_reward: 0.6822, time (sec): 117141.6857\n",
      "Ep. 8844 done, reward: -1.0, running_reward: 0.7576, time (sec): 117167.3430\n",
      "Ep. 8846 done, reward: -2.0, running_reward: 0.8017, time (sec): 117192.1030\n",
      "Ep. 8848 done, reward: 6.0, running_reward: 0.7270, time (sec): 117216.5748\n",
      "Ep. 8850 done, reward: -5.0, running_reward: 0.6823, time (sec): 117245.7859\n",
      "Ep. 8852 done, reward: -5.0, running_reward: 0.6286, time (sec): 117273.2344\n",
      "Ep. 8854 done, reward: -12.0, running_reward: 0.4367, time (sec): 117297.3738\n",
      "Ep. 8856 done, reward: -7.0, running_reward: 0.3481, time (sec): 117325.9598\n",
      "Ep. 8858 done, reward: -1.0, running_reward: 0.2421, time (sec): 117354.9002\n",
      "Ep. 8860 done, reward: 9.0, running_reward: 0.3075, time (sec): 117382.1619\n",
      "Ep. 8862 done, reward: -5.0, running_reward: 0.2117, time (sec): 117407.1747\n",
      "Ep. 8864 done, reward: 2.0, running_reward: 0.2770, time (sec): 117437.2238\n",
      "Ep. 8866 done, reward: 2.0, running_reward: 0.2618, time (sec): 117466.6710\n",
      "Ep. 8868 done, reward: 7.0, running_reward: 0.2771, time (sec): 117495.4031\n",
      "Ep. 8870 done, reward: 2.0, running_reward: 0.3213, time (sec): 117524.7014\n",
      "Ep. 8872 done, reward: -3.0, running_reward: 0.1859, time (sec): 117552.6072\n",
      "Ep. 8874 done, reward: 9.0, running_reward: 0.3217, time (sec): 117576.1042\n",
      "Ep. 8876 done, reward: -7.0, running_reward: 0.3245, time (sec): 117602.8358\n",
      "Ep. 8878 done, reward: 7.0, running_reward: 0.2692, time (sec): 117625.0344\n",
      "Ep. 8880 done, reward: -10.0, running_reward: 0.1540, time (sec): 117648.9662\n",
      "Ep. 8882 done, reward: 8.0, running_reward: 0.3200, time (sec): 117670.5191\n",
      "Ep. 8884 done, reward: 7.0, running_reward: 0.3936, time (sec): 117698.5101\n",
      "Ep. 8886 done, reward: 5.0, running_reward: 0.3664, time (sec): 117722.4379\n",
      "Ep. 8888 done, reward: -6.0, running_reward: 0.2892, time (sec): 117750.8028\n",
      "Ep. 8890 done, reward: 9.0, running_reward: 0.4131, time (sec): 117774.7031\n",
      "Ep. 8892 done, reward: 11.0, running_reward: 0.6040, time (sec): 117795.3871\n",
      "Ep. 8894 done, reward: -9.0, running_reward: 0.4821, time (sec): 117820.5206\n",
      "Ep. 8896 done, reward: 1.0, running_reward: 0.4528, time (sec): 117846.7192\n",
      "Ep. 8898 done, reward: 5.0, running_reward: 0.5235, time (sec): 117874.2635\n",
      "Ep. 8900 done, reward: -7.0, running_reward: 0.5124, time (sec): 117899.6189\n",
      "Ep. 8902 done, reward: 8.0, running_reward: 0.6020, time (sec): 117926.6329\n",
      "Ep. 8904 done, reward: -1.0, running_reward: 0.7384, time (sec): 117949.5036\n",
      "Ep. 8906 done, reward: -6.0, running_reward: 0.5944, time (sec): 117976.2813\n",
      "Ep. 8908 done, reward: -5.0, running_reward: 0.5029, time (sec): 118007.9785\n",
      "Ep. 8910 done, reward: 7.0, running_reward: 0.6025, time (sec): 118032.8121\n",
      "Ep. 8912 done, reward: 10.0, running_reward: 0.8093, time (sec): 118053.1804\n",
      "Ep. 8914 done, reward: -5.0, running_reward: 0.6541, time (sec): 118079.2163\n",
      "Ep. 8916 done, reward: -5.0, running_reward: 0.6109, time (sec): 118104.4822\n",
      "Ep. 8918 done, reward: -5.0, running_reward: 0.6279, time (sec): 118128.3942\n",
      "Ep. 8920 done, reward: 10.0, running_reward: 0.8144, time (sec): 118149.3894\n",
      "Ep. 8922 done, reward: 7.0, running_reward: 0.7791, time (sec): 118170.9789\n",
      "Ep. 8924 done, reward: -2.0, running_reward: 0.8030, time (sec): 118197.8233\n",
      "Ep. 8926 done, reward: 10.0, running_reward: 0.9068, time (sec): 118226.8726\n",
      "Ep. 8928 done, reward: 4.0, running_reward: 1.0278, time (sec): 118250.1513\n",
      "Ep. 8930 done, reward: -1.0, running_reward: 1.0468, time (sec): 118278.3949\n",
      "Ep. 8932 done, reward: 7.0, running_reward: 1.1257, time (sec): 118302.1957\n",
      "Ep. 8934 done, reward: 14.0, running_reward: 1.2136, time (sec): 118326.7634\n",
      "Ep. 8936 done, reward: -2.0, running_reward: 1.1992, time (sec): 118353.8595\n",
      "Ep. 8938 done, reward: 1.0, running_reward: 1.2150, time (sec): 118382.9262\n",
      "Ep. 8940 done, reward: 6.0, running_reward: 1.2706, time (sec): 118407.5705\n",
      "Ep. 8942 done, reward: 8.0, running_reward: 1.3055, time (sec): 118433.3051\n",
      "Ep. 8944 done, reward: 6.0, running_reward: 1.2505, time (sec): 118457.8570\n",
      "Ep. 8946 done, reward: 3.0, running_reward: 1.2457, time (sec): 118486.3140\n",
      "Ep. 8948 done, reward: 11.0, running_reward: 1.3804, time (sec): 118509.3607\n",
      "Ep. 8950 done, reward: -3.0, running_reward: 1.4219, time (sec): 118532.7079\n",
      "Ep. 8952 done, reward: -1.0, running_reward: 1.4628, time (sec): 118560.4673\n",
      "Ep. 8954 done, reward: 5.0, running_reward: 1.4936, time (sec): 118585.0273\n",
      "Ep. 8956 done, reward: 3.0, running_reward: 1.5731, time (sec): 118608.9113\n",
      "Ep. 8958 done, reward: 5.0, running_reward: 1.5819, time (sec): 118639.6570\n",
      "Ep. 8960 done, reward: 6.0, running_reward: 1.6302, time (sec): 118665.2877\n",
      "Ep. 8962 done, reward: 8.0, running_reward: 1.6481, time (sec): 118690.7007\n",
      "Ep. 8964 done, reward: 12.0, running_reward: 1.7254, time (sec): 118718.4286\n",
      "Ep. 8966 done, reward: 4.0, running_reward: 1.7211, time (sec): 118745.8767\n",
      "Ep. 8968 done, reward: -10.0, running_reward: 1.7156, time (sec): 118766.6266\n",
      "Ep. 8970 done, reward: -5.0, running_reward: 1.7106, time (sec): 118790.8290\n",
      "Ep. 8972 done, reward: 6.0, running_reward: 1.6376, time (sec): 118816.2693\n",
      "Ep. 8974 done, reward: 6.0, running_reward: 1.7343, time (sec): 118840.3277\n",
      "Ep. 8976 done, reward: -1.0, running_reward: 1.8185, time (sec): 118865.0096\n",
      "Ep. 8978 done, reward: -6.0, running_reward: 1.7322, time (sec): 118895.0824\n",
      "Ep. 8980 done, reward: 1.0, running_reward: 1.6582, time (sec): 118922.4833\n",
      "Ep. 8982 done, reward: 5.0, running_reward: 1.7643, time (sec): 118945.0716\n",
      "Ep. 8984 done, reward: 3.0, running_reward: 1.8780, time (sec): 118968.0094\n",
      "Ep. 8986 done, reward: 10.0, running_reward: 1.9209, time (sec): 118992.8967\n",
      "Ep. 8988 done, reward: -7.0, running_reward: 1.9017, time (sec): 119020.1478\n",
      "Ep. 8990 done, reward: 16.0, running_reward: 2.1823, time (sec): 119034.7854\n",
      "Ep. 8992 done, reward: -3.0, running_reward: 2.1881, time (sec): 119059.2939\n",
      "Ep. 8994 done, reward: -5.0, running_reward: 2.2232, time (sec): 119081.5900\n",
      "Ep. 8996 done, reward: -3.0, running_reward: 2.0401, time (sec): 119108.7464\n",
      "Ep. 8998 done, reward: 1.0, running_reward: 1.9996, time (sec): 119138.6318\n",
      "Ep. 9000 done, reward: 7.0, running_reward: 2.0001, time (sec): 119165.0727\n",
      "Ep. 9002 done, reward: 1.0, running_reward: 2.0198, time (sec): 119191.6639\n",
      "Ep. 9004 done, reward: 8.0, running_reward: 2.0992, time (sec): 119218.5211\n",
      "Ep. 9006 done, reward: -14.0, running_reward: 1.9372, time (sec): 119245.2990\n",
      "Ep. 9008 done, reward: 11.0, running_reward: 2.0780, time (sec): 119268.7862\n",
      "Ep. 9010 done, reward: 6.0, running_reward: 2.2055, time (sec): 119291.4298\n",
      "Ep. 9012 done, reward: 8.0, running_reward: 2.2713, time (sec): 119317.6320\n",
      "Ep. 9014 done, reward: 3.0, running_reward: 2.3254, time (sec): 119345.7998\n",
      "Ep. 9016 done, reward: 8.0, running_reward: 2.4185, time (sec): 119368.8582\n",
      "Ep. 9018 done, reward: 7.0, running_reward: 2.4899, time (sec): 119391.9032\n",
      "Ep. 9020 done, reward: 7.0, running_reward: 2.5401, time (sec): 119414.4508\n",
      "Ep. 9022 done, reward: 8.0, running_reward: 2.6190, time (sec): 119442.3466\n",
      "Ep. 9024 done, reward: 11.0, running_reward: 2.7759, time (sec): 119461.6972\n",
      "Ep. 9026 done, reward: 10.0, running_reward: 2.8009, time (sec): 119485.0480\n",
      "Ep. 9028 done, reward: -6.0, running_reward: 2.6752, time (sec): 119514.5450\n",
      "Ep. 9030 done, reward: -1.0, running_reward: 2.5229, time (sec): 119544.7588\n",
      "Ep. 9032 done, reward: -2.0, running_reward: 2.4923, time (sec): 119574.2511\n",
      "Ep. 9034 done, reward: -8.0, running_reward: 2.2340, time (sec): 119602.9155\n",
      "Ep. 9036 done, reward: 2.0, running_reward: 2.1897, time (sec): 119629.2997\n",
      "Ep. 9038 done, reward: 3.0, running_reward: 2.1366, time (sec): 119659.0305\n",
      "Ep. 9040 done, reward: -4.0, running_reward: 1.9946, time (sec): 119687.7445\n",
      "Ep. 9042 done, reward: -3.0, running_reward: 2.0140, time (sec): 119711.7241\n",
      "Ep. 9044 done, reward: 2.0, running_reward: 2.0633, time (sec): 119736.9589\n",
      "Ep. 9046 done, reward: 15.0, running_reward: 2.2316, time (sec): 119758.0799\n",
      "Ep. 9048 done, reward: -1.0, running_reward: 2.2366, time (sec): 119785.3204\n",
      "Ep. 9050 done, reward: 4.0, running_reward: 2.2915, time (sec): 119808.3571\n",
      "Ep. 9052 done, reward: -3.0, running_reward: 2.1367, time (sec): 119835.5202\n",
      "Ep. 9054 done, reward: 10.0, running_reward: 2.2932, time (sec): 119858.5080\n",
      "Ep. 9056 done, reward: 1.0, running_reward: 2.3565, time (sec): 119884.2912\n",
      "Ep. 9058 done, reward: -6.0, running_reward: 2.1308, time (sec): 119911.0931\n",
      "Ep. 9060 done, reward: -9.0, running_reward: 2.0578, time (sec): 119936.8864\n",
      "Ep. 9062 done, reward: 4.0, running_reward: 2.1163, time (sec): 119963.7363\n",
      "Ep. 9064 done, reward: -9.0, running_reward: 1.8753, time (sec): 119989.3711\n",
      "Ep. 9066 done, reward: -3.0, running_reward: 1.7684, time (sec): 120014.7486\n",
      "Ep. 9068 done, reward: -9.0, running_reward: 1.6828, time (sec): 120041.2351\n",
      "Ep. 9070 done, reward: -12.0, running_reward: 1.4600, time (sec): 120067.4547\n",
      "Ep. 9072 done, reward: -1.0, running_reward: 1.4803, time (sec): 120094.8009\n",
      "Ep. 9074 done, reward: 3.0, running_reward: 1.5403, time (sec): 120119.5961\n",
      "Ep. 9076 done, reward: 7.0, running_reward: 1.4707, time (sec): 120140.9958\n",
      "Ep. 9078 done, reward: 11.0, running_reward: 1.5811, time (sec): 120163.9249\n",
      "Ep. 9080 done, reward: 11.0, running_reward: 1.5805, time (sec): 120186.0954\n",
      "Ep. 9082 done, reward: -15.0, running_reward: 1.4386, time (sec): 120213.3141\n",
      "Ep. 9084 done, reward: -7.0, running_reward: 1.3796, time (sec): 120237.1754\n",
      "Ep. 9086 done, reward: -9.0, running_reward: 1.3512, time (sec): 120262.4986\n",
      "Ep. 9088 done, reward: 1.0, running_reward: 1.3641, time (sec): 120289.9525\n",
      "Ep. 9090 done, reward: 1.0, running_reward: 1.2974, time (sec): 120316.4001\n",
      "Ep. 9092 done, reward: -8.0, running_reward: 1.2807, time (sec): 120340.5614\n",
      "Ep. 9094 done, reward: 3.0, running_reward: 1.1565, time (sec): 120366.2396\n",
      "Ep. 9096 done, reward: 3.0, running_reward: 1.2031, time (sec): 120392.7905\n",
      "Ep. 9098 done, reward: 8.0, running_reward: 1.1701, time (sec): 120415.8920\n",
      "Ep. 9100 done, reward: -7.0, running_reward: 1.1263, time (sec): 120442.4722\n",
      "Ep. 9102 done, reward: -5.0, running_reward: 1.1628, time (sec): 120465.5293\n",
      "Ep. 9104 done, reward: 4.0, running_reward: 1.3083, time (sec): 120488.9233\n",
      "Ep. 9106 done, reward: 1.0, running_reward: 1.4012, time (sec): 120515.9085\n",
      "Ep. 9108 done, reward: -1.0, running_reward: 1.2940, time (sec): 120544.8691\n",
      "Ep. 9110 done, reward: 10.0, running_reward: 1.3781, time (sec): 120570.4350\n",
      "Ep. 9112 done, reward: 7.0, running_reward: 1.4999, time (sec): 120596.8843\n",
      "Ep. 9114 done, reward: -5.0, running_reward: 1.3904, time (sec): 120626.5147\n",
      "Ep. 9116 done, reward: -5.0, running_reward: 1.2632, time (sec): 120653.3308\n",
      "Ep. 9118 done, reward: 8.0, running_reward: 1.3973, time (sec): 120679.6021\n",
      "Ep. 9120 done, reward: -5.0, running_reward: 1.2898, time (sec): 120708.1687\n",
      "Ep. 9122 done, reward: 13.0, running_reward: 1.4535, time (sec): 120731.2889\n",
      "Ep. 9124 done, reward: -1.0, running_reward: 1.3552, time (sec): 120761.7838\n",
      "Ep. 9126 done, reward: -7.0, running_reward: 1.3572, time (sec): 120784.6412\n",
      "Ep. 9128 done, reward: 9.0, running_reward: 1.4994, time (sec): 120807.2438\n",
      "Ep. 9130 done, reward: 3.0, running_reward: 1.4600, time (sec): 120844.0040\n",
      "Ep. 9132 done, reward: 4.0, running_reward: 1.4610, time (sec): 120869.7513\n",
      "Ep. 9134 done, reward: 14.0, running_reward: 1.6214, time (sec): 120890.1676\n",
      "Ep. 9136 done, reward: 3.0, running_reward: 1.6291, time (sec): 120916.6194\n",
      "Ep. 9138 done, reward: 6.0, running_reward: 1.7358, time (sec): 120940.3069\n",
      "Ep. 9140 done, reward: -15.0, running_reward: 1.6305, time (sec): 120962.8621\n",
      "Ep. 9142 done, reward: -4.0, running_reward: 1.6373, time (sec): 120991.0387\n",
      "Ep. 9144 done, reward: 1.0, running_reward: 1.6741, time (sec): 121020.9640\n",
      "Ep. 9146 done, reward: 1.0, running_reward: 1.7696, time (sec): 121046.9008\n",
      "Ep. 9148 done, reward: -5.0, running_reward: 1.7239, time (sec): 121073.5298\n",
      "Ep. 9150 done, reward: -7.0, running_reward: 1.5305, time (sec): 121097.6307\n",
      "Ep. 9152 done, reward: -1.0, running_reward: 1.5594, time (sec): 121121.6166\n",
      "Ep. 9154 done, reward: 1.0, running_reward: 1.5878, time (sec): 121147.1106\n",
      "Ep. 9156 done, reward: -13.0, running_reward: 1.4856, time (sec): 121170.4221\n",
      "Ep. 9158 done, reward: -4.0, running_reward: 1.3963, time (sec): 121197.8431\n",
      "Ep. 9160 done, reward: 1.0, running_reward: 1.3686, time (sec): 121230.4567\n",
      "Ep. 9162 done, reward: -1.0, running_reward: 1.4502, time (sec): 121253.0306\n",
      "Ep. 9164 done, reward: 6.0, running_reward: 1.3922, time (sec): 121277.6925\n",
      "Ep. 9166 done, reward: 4.0, running_reward: 1.3154, time (sec): 121305.8093\n",
      "Ep. 9168 done, reward: 3.0, running_reward: 1.2697, time (sec): 121333.6601\n",
      "Ep. 9170 done, reward: 12.0, running_reward: 1.3348, time (sec): 121357.2182\n",
      "Ep. 9172 done, reward: 1.0, running_reward: 1.3578, time (sec): 121385.0061\n",
      "Ep. 9174 done, reward: -1.0, running_reward: 1.3109, time (sec): 121412.9330\n",
      "Ep. 9176 done, reward: 8.0, running_reward: 1.2955, time (sec): 121440.0602\n",
      "Ep. 9178 done, reward: 7.0, running_reward: 1.3496, time (sec): 121466.8134\n",
      "Ep. 9180 done, reward: 3.0, running_reward: 1.2934, time (sec): 121491.8433\n",
      "Ep. 9182 done, reward: -6.0, running_reward: 1.2373, time (sec): 121521.8245\n",
      "Ep. 9184 done, reward: 5.0, running_reward: 1.2429, time (sec): 121550.1587\n",
      "Ep. 9186 done, reward: 8.0, running_reward: 1.3477, time (sec): 121575.8701\n",
      "Ep. 9188 done, reward: 12.0, running_reward: 1.4111, time (sec): 121599.9230\n",
      "Ep. 9190 done, reward: -1.0, running_reward: 1.3236, time (sec): 121625.6387\n",
      "Ep. 9192 done, reward: 1.0, running_reward: 1.2280, time (sec): 121658.1664\n",
      "Ep. 9194 done, reward: -11.0, running_reward: 1.1530, time (sec): 121679.2543\n",
      "Ep. 9196 done, reward: -13.0, running_reward: 1.1089, time (sec): 121701.1209\n",
      "Ep. 9198 done, reward: 10.0, running_reward: 1.2364, time (sec): 121725.0467\n",
      "Ep. 9200 done, reward: 13.0, running_reward: 1.2626, time (sec): 121745.8804\n",
      "Ep. 9202 done, reward: -8.0, running_reward: 1.1475, time (sec): 121772.1935\n",
      "Ep. 9204 done, reward: -2.0, running_reward: 1.0948, time (sec): 121797.7536\n",
      "Ep. 9206 done, reward: 7.0, running_reward: 1.1331, time (sec): 121825.8173\n",
      "Ep. 9208 done, reward: 2.0, running_reward: 1.1405, time (sec): 121855.1607\n",
      "Ep. 9210 done, reward: -1.0, running_reward: 1.0880, time (sec): 121885.3918\n",
      "Ep. 9212 done, reward: 6.0, running_reward: 1.1659, time (sec): 121912.4408\n",
      "Ep. 9214 done, reward: -10.0, running_reward: 1.0526, time (sec): 121938.0289\n",
      "Ep. 9216 done, reward: 4.0, running_reward: 1.1905, time (sec): 121962.3575\n",
      "Ep. 9218 done, reward: -9.0, running_reward: 0.9679, time (sec): 121987.3435\n",
      "Ep. 9220 done, reward: -2.0, running_reward: 0.9385, time (sec): 122016.0533\n",
      "Ep. 9222 done, reward: 1.0, running_reward: 0.9892, time (sec): 122045.3402\n",
      "Ep. 9224 done, reward: 5.0, running_reward: 1.0295, time (sec): 122076.0465\n",
      "Ep. 9226 done, reward: 5.0, running_reward: 1.0095, time (sec): 122100.8527\n",
      "Ep. 9228 done, reward: -3.0, running_reward: 1.0683, time (sec): 122123.6334\n",
      "Ep. 9230 done, reward: 2.0, running_reward: 1.1066, time (sec): 122151.8642\n",
      "Ep. 9232 done, reward: 2.0, running_reward: 1.1838, time (sec): 122176.1510\n",
      "Ep. 9234 done, reward: -6.0, running_reward: 1.1695, time (sec): 122204.3438\n",
      "Ep. 9236 done, reward: 10.0, running_reward: 1.2364, time (sec): 122229.4667\n",
      "Ep. 9238 done, reward: 12.0, running_reward: 1.4506, time (sec): 122249.4099\n",
      "Ep. 9240 done, reward: -9.0, running_reward: 1.3218, time (sec): 122277.3823\n",
      "Ep. 9242 done, reward: -4.0, running_reward: 1.2951, time (sec): 122304.4524\n",
      "Ep. 9244 done, reward: -13.0, running_reward: 1.2185, time (sec): 122323.6102\n",
      "Ep. 9246 done, reward: 4.0, running_reward: 1.2640, time (sec): 122351.2912\n",
      "Ep. 9248 done, reward: -7.0, running_reward: 1.1886, time (sec): 122378.5884\n",
      "Ep. 9250 done, reward: -10.0, running_reward: 1.1343, time (sec): 122405.0825\n",
      "Ep. 9252 done, reward: 8.0, running_reward: 1.2115, time (sec): 122432.4909\n",
      "Ep. 9254 done, reward: 10.0, running_reward: 1.3270, time (sec): 122455.2462\n",
      "Ep. 9256 done, reward: -1.0, running_reward: 1.2015, time (sec): 122479.2541\n",
      "Ep. 9258 done, reward: -7.0, running_reward: 1.0977, time (sec): 122506.3684\n",
      "Ep. 9260 done, reward: -7.0, running_reward: 1.1444, time (sec): 122529.0595\n",
      "Ep. 9262 done, reward: 4.0, running_reward: 1.2508, time (sec): 122554.1625\n",
      "Ep. 9264 done, reward: 1.0, running_reward: 1.3151, time (sec): 122581.1117\n",
      "Ep. 9266 done, reward: -1.0, running_reward: 1.3779, time (sec): 122607.2892\n",
      "Ep. 9268 done, reward: 7.0, running_reward: 1.4007, time (sec): 122635.2743\n",
      "Ep. 9270 done, reward: 9.0, running_reward: 1.4826, time (sec): 122658.9335\n",
      "Ep. 9272 done, reward: -5.0, running_reward: 1.5021, time (sec): 122686.2547\n",
      "Ep. 9274 done, reward: 2.0, running_reward: 1.5714, time (sec): 122712.3656\n",
      "Ep. 9276 done, reward: 4.0, running_reward: 1.5702, time (sec): 122743.1722\n",
      "Ep. 9278 done, reward: 2.0, running_reward: 1.5887, time (sec): 122773.7620\n",
      "Ep. 9280 done, reward: 1.0, running_reward: 1.6958, time (sec): 122800.9519\n",
      "Ep. 9282 done, reward: 7.0, running_reward: 1.7122, time (sec): 122829.1780\n",
      "Ep. 9284 done, reward: 1.0, running_reward: 1.6981, time (sec): 122860.1923\n",
      "Ep. 9286 done, reward: -1.0, running_reward: 1.6840, time (sec): 122891.5289\n",
      "Ep. 9288 done, reward: 2.0, running_reward: 1.6507, time (sec): 122922.8021\n",
      "Ep. 9290 done, reward: -12.0, running_reward: 1.4483, time (sec): 122951.6551\n",
      "Ep. 9292 done, reward: -1.0, running_reward: 1.5184, time (sec): 122975.2814\n",
      "Ep. 9294 done, reward: 7.0, running_reward: 1.6275, time (sec): 122999.1149\n",
      "Ep. 9296 done, reward: 3.0, running_reward: 1.6548, time (sec): 123029.0752\n",
      "Ep. 9298 done, reward: 10.0, running_reward: 1.7515, time (sec): 123055.3218\n",
      "Ep. 9300 done, reward: 6.0, running_reward: 1.8559, time (sec): 123076.6489\n",
      "Ep. 9302 done, reward: 6.0, running_reward: 1.9285, time (sec): 123101.2015\n",
      "Ep. 9304 done, reward: 4.0, running_reward: 1.9598, time (sec): 123128.1960\n",
      "Ep. 9306 done, reward: 5.0, running_reward: 2.0401, time (sec): 123152.2166\n",
      "Ep. 9308 done, reward: 8.0, running_reward: 2.2181, time (sec): 123172.4656\n",
      "Ep. 9310 done, reward: 7.0, running_reward: 2.2241, time (sec): 123200.6015\n",
      "Ep. 9312 done, reward: 10.0, running_reward: 2.3492, time (sec): 123224.1079\n",
      "Ep. 9314 done, reward: 8.0, running_reward: 2.3725, time (sec): 123254.0726\n",
      "Ep. 9316 done, reward: 9.0, running_reward: 2.4351, time (sec): 123278.6191\n",
      "Ep. 9318 done, reward: 7.0, running_reward: 2.5260, time (sec): 123305.0485\n",
      "Ep. 9320 done, reward: 2.0, running_reward: 2.5353, time (sec): 123333.3337\n",
      "Ep. 9322 done, reward: 3.0, running_reward: 2.5346, time (sec): 123363.5674\n",
      "Ep. 9324 done, reward: -3.0, running_reward: 2.5433, time (sec): 123388.4658\n",
      "Ep. 9326 done, reward: 8.0, running_reward: 2.4440, time (sec): 123407.0673\n",
      "Ep. 9328 done, reward: -4.0, running_reward: 2.2861, time (sec): 123433.9246\n",
      "Ep. 9330 done, reward: 12.0, running_reward: 2.4596, time (sec): 123455.9108\n",
      "Ep. 9332 done, reward: 5.0, running_reward: 2.4012, time (sec): 123484.9342\n",
      "Ep. 9334 done, reward: -1.0, running_reward: 2.4424, time (sec): 123509.5001\n",
      "Ep. 9336 done, reward: 1.0, running_reward: 2.3048, time (sec): 123536.8339\n",
      "Ep. 9338 done, reward: 5.0, running_reward: 2.2793, time (sec): 123563.9496\n",
      "Ep. 9340 done, reward: 11.0, running_reward: 2.3835, time (sec): 123587.9465\n",
      "Ep. 9342 done, reward: 4.0, running_reward: 2.2870, time (sec): 123612.7362\n",
      "Ep. 9344 done, reward: 14.0, running_reward: 2.3518, time (sec): 123639.6971\n",
      "Ep. 9346 done, reward: 5.0, running_reward: 2.2164, time (sec): 123663.7780\n",
      "Ep. 9348 done, reward: -1.0, running_reward: 2.0633, time (sec): 123689.9863\n",
      "Ep. 9350 done, reward: -1.0, running_reward: 2.0914, time (sec): 123713.2661\n",
      "Ep. 9352 done, reward: -2.0, running_reward: 2.0199, time (sec): 123742.7281\n",
      "Ep. 9354 done, reward: -6.0, running_reward: 1.9395, time (sec): 123771.6806\n",
      "Ep. 9356 done, reward: -9.0, running_reward: 1.8307, time (sec): 123795.4662\n",
      "Ep. 9358 done, reward: -6.0, running_reward: 1.8135, time (sec): 123818.9119\n",
      "Ep. 9360 done, reward: 4.0, running_reward: 1.8075, time (sec): 123848.2658\n",
      "Ep. 9362 done, reward: -4.0, running_reward: 1.7810, time (sec): 123876.9568\n",
      "Ep. 9364 done, reward: -5.0, running_reward: 1.7748, time (sec): 123900.3220\n",
      "Ep. 9366 done, reward: 1.0, running_reward: 1.7692, time (sec): 123927.1681\n",
      "Ep. 9368 done, reward: -1.0, running_reward: 1.7042, time (sec): 123956.2842\n",
      "Ep. 9370 done, reward: 12.0, running_reward: 1.7705, time (sec): 123979.3887\n",
      "Ep. 9372 done, reward: 10.0, running_reward: 1.8155, time (sec): 124006.0076\n",
      "Ep. 9374 done, reward: 9.0, running_reward: 1.9882, time (sec): 124029.3573\n",
      "Ep. 9376 done, reward: -1.0, running_reward: 1.9287, time (sec): 124059.0214\n",
      "Ep. 9378 done, reward: -1.0, running_reward: 1.9793, time (sec): 124083.5447\n",
      "Ep. 9380 done, reward: 7.0, running_reward: 2.0594, time (sec): 124107.0614\n",
      "Ep. 9382 done, reward: -4.0, running_reward: 1.8695, time (sec): 124134.3561\n",
      "Ep. 9384 done, reward: -4.0, running_reward: 1.8517, time (sec): 124160.6793\n",
      "Ep. 9386 done, reward: 8.0, running_reward: 1.9642, time (sec): 124184.9625\n",
      "Ep. 9388 done, reward: 7.0, running_reward: 1.9456, time (sec): 124213.4595\n",
      "Ep. 9390 done, reward: 4.0, running_reward: 1.9073, time (sec): 124239.9305\n",
      "Ep. 9392 done, reward: 4.0, running_reward: 1.8499, time (sec): 124269.0389\n",
      "Ep. 9394 done, reward: 12.0, running_reward: 2.0222, time (sec): 124290.1836\n",
      "Ep. 9396 done, reward: 7.0, running_reward: 1.9728, time (sec): 124312.2772\n",
      "Ep. 9398 done, reward: -10.0, running_reward: 1.7642, time (sec): 124338.1066\n",
      "Ep. 9400 done, reward: -4.0, running_reward: 1.6297, time (sec): 124366.9679\n",
      "Ep. 9402 done, reward: 7.0, running_reward: 1.6475, time (sec): 124390.1333\n",
      "Ep. 9404 done, reward: 10.0, running_reward: 1.7741, time (sec): 124417.2072\n",
      "Ep. 9406 done, reward: 8.0, running_reward: 1.8881, time (sec): 124438.4123\n",
      "Ep. 9408 done, reward: 1.0, running_reward: 1.8407, time (sec): 124467.1876\n",
      "Ep. 9410 done, reward: 5.0, running_reward: 1.9432, time (sec): 124490.6951\n",
      "Ep. 9412 done, reward: 10.0, running_reward: 1.9748, time (sec): 124518.1104\n",
      "Ep. 9414 done, reward: 8.0, running_reward: 2.1046, time (sec): 124541.4813\n",
      "Ep. 9416 done, reward: 3.0, running_reward: 2.1323, time (sec): 124571.1680\n",
      "Ep. 9418 done, reward: 4.0, running_reward: 2.2190, time (sec): 124595.8690\n",
      "Ep. 9420 done, reward: -6.0, running_reward: 2.1643, time (sec): 124620.1274\n",
      "Ep. 9422 done, reward: -1.0, running_reward: 2.0717, time (sec): 124649.4881\n",
      "Ep. 9424 done, reward: 10.0, running_reward: 2.0908, time (sec): 124673.7892\n",
      "Ep. 9426 done, reward: 4.0, running_reward: 2.1090, time (sec): 124703.8544\n",
      "Ep. 9428 done, reward: 10.0, running_reward: 2.2364, time (sec): 124727.7853\n",
      "Ep. 9430 done, reward: 3.0, running_reward: 2.2318, time (sec): 124753.2499\n",
      "Ep. 9432 done, reward: -7.0, running_reward: 2.0184, time (sec): 124778.0177\n",
      "Ep. 9434 done, reward: 19.0, running_reward: 2.2771, time (sec): 124793.9815\n",
      "Ep. 9436 done, reward: -1.0, running_reward: 2.2713, time (sec): 124820.8290\n",
      "Ep. 9438 done, reward: -1.0, running_reward: 2.1864, time (sec): 124849.4294\n",
      "Ep. 9440 done, reward: 12.0, running_reward: 2.2926, time (sec): 124871.6842\n",
      "Ep. 9442 done, reward: 11.0, running_reward: 2.4163, time (sec): 124894.2851\n",
      "Ep. 9444 done, reward: -6.0, running_reward: 2.3578, time (sec): 124919.1780\n",
      "Ep. 9446 done, reward: 1.0, running_reward: 2.3703, time (sec): 124946.6590\n",
      "Ep. 9448 done, reward: 1.0, running_reward: 2.3926, time (sec): 124972.1179\n",
      "Ep. 9450 done, reward: 9.0, running_reward: 2.3261, time (sec): 124995.4685\n",
      "Ep. 9452 done, reward: -1.0, running_reward: 2.3490, time (sec): 125021.4101\n",
      "Ep. 9454 done, reward: -8.0, running_reward: 2.2816, time (sec): 125048.2380\n",
      "Ep. 9456 done, reward: 5.0, running_reward: 2.2070, time (sec): 125078.6829\n",
      "Ep. 9458 done, reward: 5.0, running_reward: 2.3121, time (sec): 125102.0926\n",
      "Ep. 9460 done, reward: 14.0, running_reward: 2.3962, time (sec): 125128.2454\n",
      "Ep. 9462 done, reward: 1.0, running_reward: 2.2298, time (sec): 125150.9064\n",
      "Ep. 9464 done, reward: 8.0, running_reward: 2.3545, time (sec): 125172.5179\n",
      "Ep. 9466 done, reward: -3.0, running_reward: 2.3074, time (sec): 125196.8199\n",
      "Ep. 9468 done, reward: -1.0, running_reward: 2.2317, time (sec): 125224.0628\n",
      "Ep. 9470 done, reward: 3.0, running_reward: 2.2767, time (sec): 125247.4341\n",
      "Ep. 9472 done, reward: -1.0, running_reward: 2.2609, time (sec): 125279.0151\n",
      "Ep. 9474 done, reward: 5.0, running_reward: 2.1967, time (sec): 125303.7139\n",
      "Ep. 9476 done, reward: -1.0, running_reward: 2.0736, time (sec): 125334.3772\n",
      "Ep. 9478 done, reward: -4.0, running_reward: 2.0518, time (sec): 125360.6739\n",
      "Ep. 9480 done, reward: 7.0, running_reward: 2.1007, time (sec): 125386.8990\n",
      "Ep. 9482 done, reward: 7.0, running_reward: 2.2774, time (sec): 125411.3482\n",
      "Ep. 9484 done, reward: 6.0, running_reward: 2.3515, time (sec): 125432.6331\n",
      "Ep. 9486 done, reward: 2.0, running_reward: 2.3445, time (sec): 125461.8608\n",
      "Ep. 9488 done, reward: -3.0, running_reward: 2.3867, time (sec): 125486.1767\n",
      "Ep. 9490 done, reward: 3.0, running_reward: 2.4880, time (sec): 125510.6442\n",
      "Ep. 9492 done, reward: 8.0, running_reward: 2.5878, time (sec): 125536.2785\n",
      "Ep. 9494 done, reward: 13.0, running_reward: 2.7752, time (sec): 125557.0845\n",
      "Ep. 9496 done, reward: 4.0, running_reward: 2.7698, time (sec): 125583.0169\n",
      "Ep. 9498 done, reward: -4.0, running_reward: 2.7440, time (sec): 125608.1637\n",
      "Ep. 9500 done, reward: 8.0, running_reward: 2.9179, time (sec): 125626.6505\n",
      "Ep. 9502 done, reward: 6.0, running_reward: 2.8703, time (sec): 125653.6910\n",
      "Ep. 9504 done, reward: 9.0, running_reward: 2.9329, time (sec): 125676.4179\n",
      "Ep. 9506 done, reward: 10.0, running_reward: 2.9845, time (sec): 125702.1188\n",
      "Ep. 9508 done, reward: 14.0, running_reward: 3.0057, time (sec): 125726.1838\n",
      "Ep. 9510 done, reward: 5.0, running_reward: 3.0652, time (sec): 125751.5690\n",
      "Ep. 9512 done, reward: 1.0, running_reward: 2.9647, time (sec): 125780.8471\n",
      "Ep. 9514 done, reward: 12.0, running_reward: 3.0851, time (sec): 125803.0712\n",
      "Ep. 9516 done, reward: 12.0, running_reward: 3.0744, time (sec): 125828.3793\n",
      "Ep. 9518 done, reward: 1.0, running_reward: 3.1123, time (sec): 125856.0191\n",
      "Ep. 9520 done, reward: -3.0, running_reward: 3.0798, time (sec): 125886.1550\n",
      "Ep. 9522 done, reward: 6.0, running_reward: 3.1082, time (sec): 125912.0051\n",
      "Ep. 9524 done, reward: 10.0, running_reward: 3.0770, time (sec): 125934.7254\n",
      "Ep. 9526 done, reward: -4.0, running_reward: 2.9362, time (sec): 125963.3716\n",
      "Ep. 9528 done, reward: 3.0, running_reward: 2.7890, time (sec): 125991.2265\n",
      "Ep. 9530 done, reward: 9.0, running_reward: 2.7938, time (sec): 126015.3953\n",
      "Ep. 9532 done, reward: 2.0, running_reward: 2.8374, time (sec): 126040.2758\n",
      "Ep. 9534 done, reward: 6.0, running_reward: 2.8013, time (sec): 126066.7510\n",
      "Ep. 9536 done, reward: -2.0, running_reward: 2.6958, time (sec): 126095.4805\n",
      "Ep. 9538 done, reward: -2.0, running_reward: 2.6717, time (sec): 126124.1827\n",
      "Ep. 9540 done, reward: 4.0, running_reward: 2.7476, time (sec): 126146.8121\n",
      "Ep. 9542 done, reward: -10.0, running_reward: 2.6326, time (sec): 126169.6021\n",
      "Ep. 9544 done, reward: 1.0, running_reward: 2.6793, time (sec): 126195.4503\n",
      "Ep. 9546 done, reward: 10.0, running_reward: 2.7161, time (sec): 126221.6581\n",
      "Ep. 9548 done, reward: -12.0, running_reward: 2.5618, time (sec): 126244.4658\n",
      "Ep. 9550 done, reward: 8.0, running_reward: 2.6997, time (sec): 126268.3488\n",
      "Ep. 9552 done, reward: -4.0, running_reward: 2.7149, time (sec): 126289.0204\n",
      "Ep. 9554 done, reward: 8.0, running_reward: 2.7805, time (sec): 126315.7579\n",
      "Ep. 9556 done, reward: 13.0, running_reward: 2.9343, time (sec): 126337.3482\n",
      "Ep. 9558 done, reward: 16.0, running_reward: 3.1349, time (sec): 126357.1250\n",
      "Ep. 9560 done, reward: 2.0, running_reward: 3.1223, time (sec): 126382.3799\n",
      "Ep. 9562 done, reward: -1.0, running_reward: 3.0204, time (sec): 126411.9966\n",
      "Ep. 9564 done, reward: -6.0, running_reward: 2.9399, time (sec): 126440.6159\n",
      "Ep. 9566 done, reward: 7.0, running_reward: 2.9811, time (sec): 126469.5573\n",
      "Ep. 9568 done, reward: 3.0, running_reward: 2.8825, time (sec): 126497.4320\n",
      "Ep. 9570 done, reward: 9.0, running_reward: 2.8359, time (sec): 126521.1197\n",
      "Ep. 9572 done, reward: 4.0, running_reward: 2.9680, time (sec): 126541.6611\n",
      "Ep. 9574 done, reward: 14.0, running_reward: 3.0984, time (sec): 126565.0144\n",
      "Ep. 9576 done, reward: 7.0, running_reward: 3.1563, time (sec): 126591.8152\n",
      "Ep. 9578 done, reward: -11.0, running_reward: 3.0330, time (sec): 126617.0076\n",
      "Ep. 9580 done, reward: 1.0, running_reward: 3.0717, time (sec): 126640.6379\n",
      "Ep. 9582 done, reward: 5.0, running_reward: 3.0804, time (sec): 126668.0572\n",
      "Ep. 9584 done, reward: -6.0, running_reward: 2.8304, time (sec): 126693.5707\n",
      "Ep. 9586 done, reward: -5.0, running_reward: 2.8231, time (sec): 126716.4917\n",
      "Ep. 9588 done, reward: -2.0, running_reward: 2.8063, time (sec): 126745.8552\n",
      "Ep. 9590 done, reward: -1.0, running_reward: 2.6612, time (sec): 126772.7438\n",
      "Ep. 9592 done, reward: -8.0, running_reward: 2.5085, time (sec): 126798.9665\n",
      "Ep. 9594 done, reward: 8.0, running_reward: 2.6376, time (sec): 126821.0623\n",
      "Ep. 9596 done, reward: 8.0, running_reward: 2.7146, time (sec): 126845.0759\n",
      "Ep. 9598 done, reward: 1.0, running_reward: 2.6507, time (sec): 126878.6032\n",
      "Ep. 9600 done, reward: -11.0, running_reward: 2.6068, time (sec): 126901.3511\n",
      "Ep. 9602 done, reward: 7.0, running_reward: 2.6447, time (sec): 126927.5832\n",
      "Ep. 9604 done, reward: -8.0, running_reward: 2.5319, time (sec): 126955.2689\n",
      "Ep. 9606 done, reward: -3.0, running_reward: 2.4218, time (sec): 126983.4053\n",
      "Ep. 9608 done, reward: 1.0, running_reward: 2.4331, time (sec): 127010.8522\n",
      "Ep. 9610 done, reward: 1.0, running_reward: 2.4838, time (sec): 127035.7892\n",
      "Ep. 9612 done, reward: -8.0, running_reward: 2.4930, time (sec): 127059.0845\n",
      "Ep. 9614 done, reward: 13.0, running_reward: 2.5536, time (sec): 127086.4835\n",
      "Ep. 9616 done, reward: -8.0, running_reward: 2.4920, time (sec): 127112.6975\n",
      "Ep. 9618 done, reward: -1.0, running_reward: 2.4523, time (sec): 127144.1044\n",
      "Ep. 9620 done, reward: 12.0, running_reward: 2.5928, time (sec): 127164.7885\n",
      "Ep. 9622 done, reward: 5.0, running_reward: 2.6011, time (sec): 127192.0949\n",
      "Ep. 9624 done, reward: 1.0, running_reward: 2.5989, time (sec): 127222.3272\n",
      "Ep. 9626 done, reward: 6.0, running_reward: 2.4686, time (sec): 127246.2202\n",
      "Ep. 9628 done, reward: -7.0, running_reward: 2.3693, time (sec): 127278.4776\n",
      "Ep. 9630 done, reward: 1.0, running_reward: 2.3717, time (sec): 127304.4499\n",
      "Ep. 9632 done, reward: 3.0, running_reward: 2.4337, time (sec): 127329.3858\n",
      "Ep. 9634 done, reward: 1.0, running_reward: 2.4745, time (sec): 127354.6055\n",
      "Ep. 9636 done, reward: 2.0, running_reward: 2.3957, time (sec): 127382.8507\n",
      "Ep. 9638 done, reward: -15.0, running_reward: 2.2476, time (sec): 127409.2029\n",
      "Ep. 9640 done, reward: 8.0, running_reward: 2.3323, time (sec): 127433.3766\n",
      "Ep. 9642 done, reward: 15.0, running_reward: 2.5151, time (sec): 127454.1693\n",
      "Ep. 9644 done, reward: 3.0, running_reward: 2.5941, time (sec): 127476.0783\n",
      "Ep. 9646 done, reward: 3.0, running_reward: 2.5229, time (sec): 127505.4065\n",
      "Ep. 9648 done, reward: -9.0, running_reward: 2.4619, time (sec): 127527.1451\n",
      "Ep. 9650 done, reward: -2.0, running_reward: 2.3632, time (sec): 127559.9600\n",
      "Ep. 9652 done, reward: -11.0, running_reward: 2.2854, time (sec): 127583.8814\n",
      "Ep. 9654 done, reward: 10.0, running_reward: 2.3498, time (sec): 127614.7971\n",
      "Ep. 9656 done, reward: -1.0, running_reward: 2.3129, time (sec): 127647.2808\n",
      "Ep. 9658 done, reward: 2.0, running_reward: 2.3364, time (sec): 127678.2717\n",
      "Ep. 9660 done, reward: 11.0, running_reward: 2.3504, time (sec): 127703.4103\n",
      "Ep. 9662 done, reward: 5.0, running_reward: 2.3338, time (sec): 127732.4559\n",
      "Ep. 9664 done, reward: 1.0, running_reward: 2.2676, time (sec): 127763.7434\n",
      "Ep. 9666 done, reward: -1.0, running_reward: 2.2521, time (sec): 127789.1106\n",
      "Ep. 9668 done, reward: 9.0, running_reward: 2.2181, time (sec): 127813.5796\n",
      "Ep. 9670 done, reward: 5.0, running_reward: 2.2339, time (sec): 127842.7569\n",
      "Ep. 9672 done, reward: -9.0, running_reward: 2.1786, time (sec): 127865.0109\n",
      "Ep. 9674 done, reward: 4.0, running_reward: 2.1456, time (sec): 127891.6979\n",
      "Ep. 9676 done, reward: -3.0, running_reward: 2.0234, time (sec): 127916.2491\n",
      "Ep. 9678 done, reward: -3.0, running_reward: 2.0026, time (sec): 127943.3471\n",
      "Ep. 9680 done, reward: 8.0, running_reward: 2.0724, time (sec): 127968.6402\n",
      "Ep. 9682 done, reward: 3.0, running_reward: 2.1206, time (sec): 127996.0745\n",
      "Ep. 9684 done, reward: -2.0, running_reward: 1.9891, time (sec): 128022.8406\n",
      "Ep. 9686 done, reward: -1.0, running_reward: 2.0088, time (sec): 128049.3832\n",
      "Ep. 9688 done, reward: 13.0, running_reward: 2.0889, time (sec): 128070.6604\n",
      "Ep. 9690 done, reward: 6.0, running_reward: 2.0876, time (sec): 128097.0305\n",
      "Ep. 9692 done, reward: 16.0, running_reward: 2.1862, time (sec): 128127.2520\n",
      "Ep. 9694 done, reward: 8.0, running_reward: 2.2425, time (sec): 128159.0208\n",
      "Ep. 9696 done, reward: -2.0, running_reward: 2.1185, time (sec): 128191.5042\n",
      "Ep. 9698 done, reward: 2.0, running_reward: 2.1557, time (sec): 128224.3678\n",
      "Ep. 9700 done, reward: 1.0, running_reward: 2.1723, time (sec): 128252.8194\n",
      "Ep. 9702 done, reward: -12.0, running_reward: 1.9002, time (sec): 128280.5809\n",
      "Ep. 9704 done, reward: 16.0, running_reward: 2.0719, time (sec): 128304.8791\n",
      "Ep. 9706 done, reward: -4.0, running_reward: 2.0600, time (sec): 128333.1577\n",
      "Ep. 9708 done, reward: -6.0, running_reward: 1.9986, time (sec): 128359.6298\n",
      "Ep. 9710 done, reward: -4.0, running_reward: 1.8495, time (sec): 128386.9652\n",
      "Ep. 9712 done, reward: 3.0, running_reward: 1.9516, time (sec): 128413.2234\n",
      "Ep. 9714 done, reward: 3.0, running_reward: 1.8933, time (sec): 128443.6860\n",
      "Ep. 9716 done, reward: 5.0, running_reward: 1.9947, time (sec): 128475.6264\n",
      "Ep. 9718 done, reward: -9.0, running_reward: 1.9046, time (sec): 128505.4774\n",
      "Ep. 9720 done, reward: 11.0, running_reward: 1.9668, time (sec): 128539.5162\n",
      "Ep. 9722 done, reward: 16.0, running_reward: 2.0777, time (sec): 128564.6711\n",
      "Ep. 9724 done, reward: 10.0, running_reward: 2.1760, time (sec): 128592.5150\n",
      "Ep. 9726 done, reward: 7.0, running_reward: 2.3017, time (sec): 128619.2598\n",
      "Ep. 9728 done, reward: 8.0, running_reward: 2.4151, time (sec): 128647.8885\n",
      "Ep. 9730 done, reward: 10.0, running_reward: 2.6254, time (sec): 128671.9863\n",
      "Ep. 9732 done, reward: -5.0, running_reward: 2.5133, time (sec): 128697.1970\n",
      "Ep. 9734 done, reward: 5.0, running_reward: 2.5529, time (sec): 128724.5124\n",
      "Ep. 9736 done, reward: -7.0, running_reward: 2.5212, time (sec): 128751.6348\n",
      "Ep. 9738 done, reward: 1.0, running_reward: 2.4612, time (sec): 128781.7269\n",
      "Ep. 9740 done, reward: -4.0, running_reward: 2.4514, time (sec): 128809.3081\n",
      "Ep. 9742 done, reward: 5.0, running_reward: 2.5714, time (sec): 128835.5179\n",
      "Ep. 9744 done, reward: 1.0, running_reward: 2.5204, time (sec): 128863.5773\n",
      "Ep. 9746 done, reward: -6.0, running_reward: 2.4201, time (sec): 128892.5564\n",
      "Ep. 9748 done, reward: 8.0, running_reward: 2.5807, time (sec): 128914.5295\n",
      "Ep. 9750 done, reward: -9.0, running_reward: 2.5878, time (sec): 128934.5334\n",
      "Ep. 9752 done, reward: 9.0, running_reward: 2.6659, time (sec): 128958.1574\n",
      "Ep. 9754 done, reward: 8.0, running_reward: 2.6730, time (sec): 128985.4388\n",
      "Ep. 9756 done, reward: 7.0, running_reward: 2.6998, time (sec): 129014.0343\n",
      "Ep. 9758 done, reward: -3.0, running_reward: 2.7051, time (sec): 129042.7171\n",
      "Ep. 9760 done, reward: 9.0, running_reward: 2.8106, time (sec): 129066.3039\n",
      "Ep. 9762 done, reward: 4.0, running_reward: 2.8442, time (sec): 129090.4010\n",
      "Ep. 9764 done, reward: -4.0, running_reward: 2.7773, time (sec): 129117.6924\n",
      "Ep. 9766 done, reward: 2.0, running_reward: 2.7816, time (sec): 129144.6016\n",
      "Ep. 9768 done, reward: 11.0, running_reward: 2.9748, time (sec): 129161.5780\n",
      "Ep. 9770 done, reward: 3.0, running_reward: 2.9951, time (sec): 129188.2742\n",
      "Ep. 9772 done, reward: -1.0, running_reward: 2.8958, time (sec): 129217.0615\n",
      "Ep. 9774 done, reward: 2.0, running_reward: 2.8186, time (sec): 129246.8103\n",
      "Ep. 9776 done, reward: 8.0, running_reward: 2.8029, time (sec): 129272.5196\n",
      "Ep. 9778 done, reward: 5.0, running_reward: 2.8268, time (sec): 129297.9990\n",
      "Ep. 9780 done, reward: -5.0, running_reward: 2.7404, time (sec): 129327.2948\n",
      "Ep. 9782 done, reward: 2.0, running_reward: 2.6366, time (sec): 129354.1527\n",
      "Ep. 9784 done, reward: 3.0, running_reward: 2.6042, time (sec): 129383.1911\n",
      "Ep. 9786 done, reward: 7.0, running_reward: 2.6620, time (sec): 129406.8286\n",
      "Ep. 9788 done, reward: 1.0, running_reward: 2.6883, time (sec): 129432.9010\n",
      "Ep. 9790 done, reward: 5.0, running_reward: 2.7640, time (sec): 129458.2569\n",
      "Ep. 9792 done, reward: -9.0, running_reward: 2.6091, time (sec): 129489.2135\n",
      "Ep. 9794 done, reward: 6.0, running_reward: 2.5875, time (sec): 129517.9238\n",
      "Ep. 9796 done, reward: 8.0, running_reward: 2.6259, time (sec): 129545.7875\n",
      "Ep. 9798 done, reward: 4.0, running_reward: 2.6829, time (sec): 129571.1137\n",
      "Ep. 9800 done, reward: 12.0, running_reward: 2.7198, time (sec): 129596.1651\n",
      "Ep. 9802 done, reward: 5.0, running_reward: 2.8444, time (sec): 129623.7138\n",
      "Ep. 9804 done, reward: 3.0, running_reward: 2.8673, time (sec): 129649.6088\n",
      "Ep. 9806 done, reward: 12.0, running_reward: 2.9896, time (sec): 129673.0368\n",
      "Ep. 9808 done, reward: 16.0, running_reward: 3.0605, time (sec): 129695.1204\n",
      "Ep. 9810 done, reward: 15.0, running_reward: 3.2090, time (sec): 129716.6065\n",
      "Ep. 9812 done, reward: 8.0, running_reward: 3.2944, time (sec): 129742.8299\n",
      "Ep. 9814 done, reward: -17.0, running_reward: 2.9499, time (sec): 129767.3408\n",
      "Ep. 9816 done, reward: -5.0, running_reward: 2.7917, time (sec): 129795.6091\n",
      "Ep. 9818 done, reward: -3.0, running_reward: 2.7359, time (sec): 129826.9620\n",
      "Ep. 9820 done, reward: 4.0, running_reward: 2.6818, time (sec): 129855.4246\n",
      "Ep. 9822 done, reward: 8.0, running_reward: 2.6689, time (sec): 129890.3657\n",
      "Ep. 9824 done, reward: 1.0, running_reward: 2.6555, time (sec): 129933.5543\n",
      "Ep. 9826 done, reward: 2.0, running_reward: 2.6919, time (sec): 129964.2749\n",
      "Ep. 9828 done, reward: -14.0, running_reward: 2.5181, time (sec): 130001.4499\n",
      "Ep. 9830 done, reward: -2.0, running_reward: 2.3787, time (sec): 130039.6022\n",
      "Ep. 9832 done, reward: -4.0, running_reward: 2.3805, time (sec): 130070.2318\n",
      "Ep. 9834 done, reward: 3.0, running_reward: 2.4621, time (sec): 130101.4773\n",
      "Ep. 9836 done, reward: 2.0, running_reward: 2.5519, time (sec): 130126.8742\n",
      "Ep. 9838 done, reward: -4.0, running_reward: 2.4215, time (sec): 130157.4797\n",
      "Ep. 9840 done, reward: 5.0, running_reward: 2.4729, time (sec): 130185.2183\n",
      "Ep. 9842 done, reward: -10.0, running_reward: 2.4325, time (sec): 130208.2613\n",
      "Ep. 9844 done, reward: 6.0, running_reward: 2.4837, time (sec): 130236.6315\n",
      "Ep. 9846 done, reward: 1.0, running_reward: 2.4740, time (sec): 130267.4110\n",
      "Ep. 9848 done, reward: 8.0, running_reward: 2.5444, time (sec): 130289.8820\n",
      "Ep. 9850 done, reward: -7.0, running_reward: 2.3445, time (sec): 130316.4338\n",
      "Ep. 9852 done, reward: 4.0, running_reward: 2.4567, time (sec): 130343.5309\n",
      "Ep. 9854 done, reward: 1.0, running_reward: 2.4475, time (sec): 130377.7762\n",
      "Ep. 9856 done, reward: -3.0, running_reward: 2.3589, time (sec): 130412.9500\n",
      "Ep. 9858 done, reward: -5.0, running_reward: 2.2917, time (sec): 130442.5149\n",
      "Ep. 9860 done, reward: 1.0, running_reward: 2.2758, time (sec): 130481.3880\n",
      "Ep. 9862 done, reward: -3.0, running_reward: 2.3194, time (sec): 130503.3054\n",
      "Ep. 9864 done, reward: 13.0, running_reward: 2.4527, time (sec): 130527.1795\n",
      "Ep. 9866 done, reward: 11.0, running_reward: 2.5337, time (sec): 130551.7518\n",
      "Ep. 9868 done, reward: 13.0, running_reward: 2.7024, time (sec): 130573.3826\n",
      "Ep. 9870 done, reward: 11.0, running_reward: 2.8180, time (sec): 130598.2418\n",
      "Ep. 9872 done, reward: 2.0, running_reward: 2.8017, time (sec): 130625.7104\n",
      "Ep. 9874 done, reward: 6.0, running_reward: 2.8258, time (sec): 130652.2123\n",
      "Ep. 9876 done, reward: 3.0, running_reward: 2.9084, time (sec): 130671.8895\n",
      "Ep. 9878 done, reward: -10.0, running_reward: 2.7209, time (sec): 130697.4535\n",
      "Ep. 9880 done, reward: 1.0, running_reward: 2.7262, time (sec): 130722.8408\n",
      "Ep. 9882 done, reward: 5.0, running_reward: 2.6725, time (sec): 130748.5441\n",
      "Ep. 9884 done, reward: -13.0, running_reward: 2.3804, time (sec): 130774.9013\n",
      "Ep. 9886 done, reward: 9.0, running_reward: 2.5418, time (sec): 130798.0869\n",
      "Ep. 9888 done, reward: -6.0, running_reward: 2.5401, time (sec): 130823.2641\n",
      "Ep. 9890 done, reward: 7.0, running_reward: 2.5992, time (sec): 130850.5949\n",
      "Ep. 9892 done, reward: -5.0, running_reward: 2.5371, time (sec): 130876.1636\n",
      "Ep. 9894 done, reward: 2.0, running_reward: 2.6452, time (sec): 130905.3483\n",
      "Ep. 9896 done, reward: 5.0, running_reward: 2.6623, time (sec): 130934.9604\n",
      "Ep. 9898 done, reward: 1.0, running_reward: 2.5104, time (sec): 130973.7010\n",
      "Ep. 9900 done, reward: 1.0, running_reward: 2.5200, time (sec): 131014.7282\n",
      "Ep. 9902 done, reward: -9.0, running_reward: 2.5283, time (sec): 131044.4862\n",
      "Ep. 9904 done, reward: 5.0, running_reward: 2.5181, time (sec): 131081.6264\n",
      "Ep. 9906 done, reward: -2.0, running_reward: 2.4678, time (sec): 131119.8692\n",
      "Ep. 9908 done, reward: 7.0, running_reward: 2.5481, time (sec): 131144.0066\n",
      "Ep. 9910 done, reward: -3.0, running_reward: 2.4971, time (sec): 131171.4077\n",
      "Ep. 9912 done, reward: 1.0, running_reward: 2.4277, time (sec): 131202.8661\n",
      "Ep. 9914 done, reward: -5.0, running_reward: 2.4284, time (sec): 131226.6106\n",
      "Ep. 9916 done, reward: 10.0, running_reward: 2.4207, time (sec): 131251.5635\n",
      "Ep. 9918 done, reward: -1.0, running_reward: 2.4021, time (sec): 131283.3415\n",
      "Ep. 9920 done, reward: 1.0, running_reward: 2.3148, time (sec): 131316.4238\n",
      "Ep. 9922 done, reward: 7.0, running_reward: 2.4080, time (sec): 131338.4833\n",
      "Ep. 9924 done, reward: -2.0, running_reward: 2.4292, time (sec): 131364.6313\n",
      "Ep. 9926 done, reward: 6.0, running_reward: 2.3815, time (sec): 131391.0827\n",
      "Ep. 9928 done, reward: 11.0, running_reward: 2.5728, time (sec): 131414.7678\n",
      "Ep. 9930 done, reward: -7.0, running_reward: 2.3823, time (sec): 131449.9911\n",
      "Ep. 9932 done, reward: 13.0, running_reward: 2.4055, time (sec): 131476.3797\n",
      "Ep. 9934 done, reward: 1.0, running_reward: 2.3181, time (sec): 131507.7736\n",
      "Ep. 9936 done, reward: -9.0, running_reward: 2.2117, time (sec): 131540.1282\n",
      "Ep. 9938 done, reward: -3.0, running_reward: 2.0090, time (sec): 131563.8379\n",
      "Ep. 9940 done, reward: 2.0, running_reward: 2.1375, time (sec): 131588.5537\n",
      "Ep. 9942 done, reward: 9.0, running_reward: 2.3037, time (sec): 131615.1329\n",
      "Ep. 9944 done, reward: -1.0, running_reward: 2.2578, time (sec): 131658.9957\n",
      "Ep. 9946 done, reward: -6.0, running_reward: 2.1925, time (sec): 131694.7343\n",
      "Ep. 9948 done, reward: 3.0, running_reward: 2.1887, time (sec): 131738.5746\n",
      "Ep. 9950 done, reward: -3.0, running_reward: 2.2043, time (sec): 131774.0526\n",
      "Ep. 9952 done, reward: 12.0, running_reward: 2.2903, time (sec): 131812.5964\n",
      "Ep. 9954 done, reward: 6.0, running_reward: 2.2849, time (sec): 131851.4602\n",
      "Ep. 9956 done, reward: 14.0, running_reward: 2.3399, time (sec): 131883.8481\n",
      "Ep. 9958 done, reward: 2.0, running_reward: 2.2539, time (sec): 131924.3892\n",
      "Ep. 9960 done, reward: 5.0, running_reward: 2.3086, time (sec): 131964.6549\n",
      "Ep. 9962 done, reward: 12.0, running_reward: 2.4717, time (sec): 131989.1284\n",
      "Ep. 9964 done, reward: 5.0, running_reward: 2.5022, time (sec): 132021.5898\n",
      "Ep. 9966 done, reward: 3.0, running_reward: 2.4131, time (sec): 132046.7682\n",
      "Ep. 9968 done, reward: 8.0, running_reward: 2.3758, time (sec): 132072.0656\n",
      "Ep. 9970 done, reward: 13.0, running_reward: 2.5278, time (sec): 132096.4505\n",
      "Ep. 9972 done, reward: 4.0, running_reward: 2.4779, time (sec): 132127.5034\n",
      "Ep. 9974 done, reward: 7.0, running_reward: 2.4788, time (sec): 132157.0836\n",
      "Ep. 9976 done, reward: 4.0, running_reward: 2.5586, time (sec): 132184.7077\n",
      "Ep. 9978 done, reward: 13.0, running_reward: 2.6080, time (sec): 132212.9923\n",
      "Ep. 9980 done, reward: 10.0, running_reward: 2.7848, time (sec): 132235.7820\n",
      "Ep. 9982 done, reward: 13.0, running_reward: 2.8792, time (sec): 132263.3532\n",
      "Ep. 9984 done, reward: -10.0, running_reward: 2.8110, time (sec): 132293.6110\n",
      "Ep. 9986 done, reward: -13.0, running_reward: 2.4765, time (sec): 132319.7906\n",
      "Ep. 9988 done, reward: 5.0, running_reward: 2.4277, time (sec): 132352.0173\n",
      "Ep. 9990 done, reward: 6.0, running_reward: 2.4691, time (sec): 132380.6042\n",
      "Ep. 9992 done, reward: -5.0, running_reward: 2.3205, time (sec): 132411.7730\n",
      "Ep. 9994 done, reward: 15.0, running_reward: 2.4441, time (sec): 132442.2311\n",
      "Ep. 9996 done, reward: 8.0, running_reward: 2.3765, time (sec): 132474.2001\n",
      "Ep. 9998 done, reward: 4.0, running_reward: 2.3395, time (sec): 132506.5962\n",
      "Ep. 10000 done, reward: 6.0, running_reward: 2.4222, time (sec): 132536.7359\n",
      "Ep. 10002 done, reward: -12.0, running_reward: 2.3134, time (sec): 132566.8815\n",
      "Ep. 10004 done, reward: 3.0, running_reward: 2.3172, time (sec): 132598.6400\n",
      "Ep. 10006 done, reward: -7.0, running_reward: 2.2902, time (sec): 132620.5225\n",
      "Ep. 10008 done, reward: -3.0, running_reward: 2.2542, time (sec): 132657.4008\n",
      "Ep. 10010 done, reward: 5.0, running_reward: 2.3385, time (sec): 132687.9827\n",
      "Ep. 10012 done, reward: 4.0, running_reward: 2.3617, time (sec): 132717.7961\n",
      "Ep. 10014 done, reward: -6.0, running_reward: 2.3438, time (sec): 132747.6939\n",
      "Ep. 10016 done, reward: 1.0, running_reward: 2.3567, time (sec): 132780.0531\n",
      "Ep. 10018 done, reward: 6.0, running_reward: 2.3995, time (sec): 132813.6490\n",
      "Ep. 10020 done, reward: 5.0, running_reward: 2.3522, time (sec): 132849.7362\n",
      "Ep. 10022 done, reward: 2.0, running_reward: 2.2957, time (sec): 132883.7784\n",
      "Ep. 10024 done, reward: -1.0, running_reward: 2.2796, time (sec): 132913.1222\n",
      "Ep. 10026 done, reward: 2.0, running_reward: 2.2642, time (sec): 132949.9177\n",
      "Ep. 10028 done, reward: 4.0, running_reward: 2.2690, time (sec): 132976.9359\n",
      "Ep. 10030 done, reward: 8.0, running_reward: 2.1950, time (sec): 133005.6321\n",
      "Ep. 10032 done, reward: 4.0, running_reward: 2.3200, time (sec): 133034.4512\n",
      "Ep. 10034 done, reward: 8.0, running_reward: 2.2746, time (sec): 133061.7088\n",
      "Ep. 10036 done, reward: 8.0, running_reward: 2.3192, time (sec): 133092.7602\n",
      "Ep. 10038 done, reward: -2.0, running_reward: 2.2927, time (sec): 133124.5547\n",
      "Ep. 10040 done, reward: -7.0, running_reward: 2.2266, time (sec): 133158.5754\n",
      "Ep. 10042 done, reward: -5.0, running_reward: 2.1818, time (sec): 133194.3699\n",
      "Ep. 10044 done, reward: 4.0, running_reward: 2.2575, time (sec): 133227.7320\n",
      "Ep. 10046 done, reward: 10.0, running_reward: 2.3621, time (sec): 133261.0073\n",
      "Ep. 10048 done, reward: 2.0, running_reward: 2.3450, time (sec): 133296.1018\n",
      "Ep. 10050 done, reward: 16.0, running_reward: 2.5375, time (sec): 133320.0209\n",
      "Ep. 10052 done, reward: -4.0, running_reward: 2.3678, time (sec): 133346.8969\n",
      "Ep. 10054 done, reward: 6.0, running_reward: 2.2817, time (sec): 133371.8740\n",
      "Ep. 10056 done, reward: -3.0, running_reward: 2.3350, time (sec): 133398.2013\n",
      "Ep. 10058 done, reward: 2.0, running_reward: 2.3680, time (sec): 133428.8740\n",
      "Ep. 10060 done, reward: -8.0, running_reward: 2.3596, time (sec): 133456.8963\n",
      "Ep. 10062 done, reward: -3.0, running_reward: 2.3025, time (sec): 133489.5281\n",
      "Ep. 10064 done, reward: 8.0, running_reward: 2.4060, time (sec): 133512.9933\n",
      "Ep. 10066 done, reward: 5.0, running_reward: 2.4576, time (sec): 133538.9255\n",
      "Ep. 10068 done, reward: 1.0, running_reward: 2.4979, time (sec): 133566.5842\n",
      "Ep. 10070 done, reward: -3.0, running_reward: 2.4578, time (sec): 133597.5914\n",
      "Ep. 10072 done, reward: 6.0, running_reward: 2.4392, time (sec): 133623.4108\n",
      "Ep. 10074 done, reward: -5.0, running_reward: 2.3604, time (sec): 133654.6266\n",
      "Ep. 10076 done, reward: 4.0, running_reward: 2.2940, time (sec): 133690.1955\n",
      "Ep. 10078 done, reward: 3.0, running_reward: 2.3477, time (sec): 133721.8647\n",
      "Ep. 10080 done, reward: 7.0, running_reward: 2.2621, time (sec): 133758.1965\n",
      "Ep. 10082 done, reward: -1.0, running_reward: 2.2368, time (sec): 133791.5655\n",
      "Ep. 10084 done, reward: 5.0, running_reward: 2.2026, time (sec): 133819.0007\n",
      "Ep. 10086 done, reward: 6.0, running_reward: 2.2386, time (sec): 133847.5184\n",
      "Ep. 10088 done, reward: 4.0, running_reward: 2.2737, time (sec): 133877.5916\n",
      "Ep. 10090 done, reward: 1.0, running_reward: 2.3176, time (sec): 133904.2648\n",
      "Ep. 10092 done, reward: 3.0, running_reward: 2.4500, time (sec): 133927.8553\n",
      "Ep. 10094 done, reward: 2.0, running_reward: 2.4509, time (sec): 133963.3028\n",
      "Ep. 10096 done, reward: 2.0, running_reward: 2.4123, time (sec): 133993.6954\n",
      "Ep. 10098 done, reward: -5.0, running_reward: 2.2846, time (sec): 134025.3616\n",
      "Ep. 10100 done, reward: 7.0, running_reward: 2.3586, time (sec): 134051.3825\n",
      "Ep. 10102 done, reward: 6.0, running_reward: 2.3816, time (sec): 134077.4670\n",
      "Ep. 10104 done, reward: 6.0, running_reward: 2.4536, time (sec): 134109.4410\n",
      "Ep. 10106 done, reward: 1.0, running_reward: 2.3652, time (sec): 134136.8536\n",
      "Ep. 10108 done, reward: 6.0, running_reward: 2.3881, time (sec): 134167.6832\n",
      "Ep. 10110 done, reward: 5.0, running_reward: 2.4599, time (sec): 134195.1598\n",
      "Ep. 10112 done, reward: 7.0, running_reward: 2.5601, time (sec): 134225.2378\n",
      "Ep. 10114 done, reward: 4.0, running_reward: 2.6284, time (sec): 134254.3733\n",
      "Ep. 10116 done, reward: -6.0, running_reward: 2.6250, time (sec): 134282.0831\n",
      "Ep. 10118 done, reward: 6.0, running_reward: 2.7416, time (sec): 134309.1591\n",
      "Ep. 10120 done, reward: -7.0, running_reward: 2.6072, time (sec): 134338.6397\n",
      "Ep. 10122 done, reward: 10.0, running_reward: 2.6751, time (sec): 134365.1501\n",
      "Ep. 10124 done, reward: 12.0, running_reward: 2.8408, time (sec): 134388.2530\n",
      "Ep. 10126 done, reward: 3.0, running_reward: 2.8341, time (sec): 134416.5652\n",
      "Ep. 10128 done, reward: 6.0, running_reward: 2.9169, time (sec): 134450.2662\n",
      "Ep. 10130 done, reward: -2.0, running_reward: 2.9082, time (sec): 134481.8703\n",
      "Ep. 10132 done, reward: 9.0, running_reward: 2.8809, time (sec): 134510.4022\n",
      "Ep. 10134 done, reward: 9.0, running_reward: 2.8245, time (sec): 134541.7053\n",
      "Ep. 10136 done, reward: -2.0, running_reward: 2.8275, time (sec): 134575.7193\n",
      "Ep. 10138 done, reward: -3.0, running_reward: 2.8006, time (sec): 134607.0218\n",
      "Ep. 10140 done, reward: -6.0, running_reward: 2.8235, time (sec): 134636.3412\n",
      "Ep. 10142 done, reward: 5.0, running_reward: 2.8371, time (sec): 134666.1302\n",
      "Ep. 10144 done, reward: 10.0, running_reward: 2.9004, time (sec): 134692.0564\n",
      "Ep. 10146 done, reward: 8.0, running_reward: 2.9821, time (sec): 134731.6142\n",
      "Ep. 10148 done, reward: 10.0, running_reward: 3.0822, time (sec): 134760.9329\n",
      "Ep. 10150 done, reward: 12.0, running_reward: 3.1804, time (sec): 134798.4735\n",
      "Ep. 10152 done, reward: -3.0, running_reward: 3.2158, time (sec): 134841.7474\n",
      "Ep. 10154 done, reward: -4.0, running_reward: 3.0722, time (sec): 134878.0338\n",
      "Ep. 10156 done, reward: 4.0, running_reward: 3.1501, time (sec): 134910.1472\n",
      "Ep. 10158 done, reward: -8.0, running_reward: 3.1460, time (sec): 134942.1517\n",
      "Ep. 10160 done, reward: -1.0, running_reward: 3.1427, time (sec): 134980.3182\n",
      "Ep. 10162 done, reward: 7.0, running_reward: 3.2294, time (sec): 135011.9966\n",
      "Ep. 10164 done, reward: -13.0, running_reward: 2.9955, time (sec): 135045.1495\n",
      "Ep. 10166 done, reward: 1.0, running_reward: 3.0548, time (sec): 135081.6415\n",
      "Ep. 10168 done, reward: -1.0, running_reward: 2.9147, time (sec): 135121.5073\n",
      "Ep. 10170 done, reward: 7.0, running_reward: 2.9168, time (sec): 135161.3569\n",
      "Ep. 10172 done, reward: -9.0, running_reward: 2.8380, time (sec): 135196.1107\n",
      "Ep. 10174 done, reward: 12.0, running_reward: 2.9412, time (sec): 135226.8780\n",
      "Ep. 10176 done, reward: 10.0, running_reward: 2.9925, time (sec): 135251.3367\n",
      "Ep. 10178 done, reward: 7.0, running_reward: 3.0327, time (sec): 135289.3119\n",
      "Ep. 10180 done, reward: 10.0, running_reward: 3.0921, time (sec): 135321.8801\n",
      "Ep. 10182 done, reward: -5.0, running_reward: 3.0004, time (sec): 135356.7160\n",
      "Ep. 10184 done, reward: 4.0, running_reward: 3.0203, time (sec): 135386.8243\n",
      "Ep. 10186 done, reward: -2.0, running_reward: 2.9897, time (sec): 135416.3802\n",
      "Ep. 10188 done, reward: -1.0, running_reward: 3.0588, time (sec): 135442.6493\n",
      "Ep. 10190 done, reward: -1.0, running_reward: 3.0374, time (sec): 135475.2611\n",
      "Ep. 10192 done, reward: 5.0, running_reward: 3.0072, time (sec): 135513.7542\n",
      "Ep. 10194 done, reward: -3.0, running_reward: 3.0262, time (sec): 135541.8544\n",
      "Ep. 10196 done, reward: 10.0, running_reward: 3.1650, time (sec): 135565.2330\n",
      "Ep. 10198 done, reward: -4.0, running_reward: 3.1016, time (sec): 135599.7028\n",
      "Ep. 10200 done, reward: 2.0, running_reward: 3.1589, time (sec): 135625.4283\n",
      "Ep. 10202 done, reward: 7.0, running_reward: 3.1958, time (sec): 135651.0765\n",
      "Ep. 10204 done, reward: -1.0, running_reward: 3.1618, time (sec): 135677.9021\n",
      "Ep. 10206 done, reward: -4.0, running_reward: 3.1083, time (sec): 135715.3221\n",
      "Ep. 10208 done, reward: 15.0, running_reward: 3.3945, time (sec): 135732.4519\n",
      "Ep. 10210 done, reward: -1.0, running_reward: 3.4060, time (sec): 135762.9594\n",
      "Ep. 10212 done, reward: 16.0, running_reward: 3.5181, time (sec): 135786.5204\n",
      "Ep. 10214 done, reward: 1.0, running_reward: 3.4679, time (sec): 135822.4103\n",
      "Ep. 10216 done, reward: 6.0, running_reward: 3.5678, time (sec): 135846.9785\n",
      "Ep. 10218 done, reward: -5.0, running_reward: 3.4765, time (sec): 135878.5650\n",
      "Ep. 10220 done, reward: 7.0, running_reward: 3.6456, time (sec): 135904.7120\n",
      "Ep. 10222 done, reward: -1.0, running_reward: 3.6819, time (sec): 135943.4447\n",
      "Ep. 10224 done, reward: -1.0, running_reward: 3.6481, time (sec): 135984.2496\n",
      "Ep. 10226 done, reward: 9.0, running_reward: 3.7744, time (sec): 136005.0732\n",
      "Ep. 10228 done, reward: 9.0, running_reward: 3.8289, time (sec): 136033.6553\n",
      "Ep. 10230 done, reward: 14.0, running_reward: 3.8729, time (sec): 136057.9886\n",
      "Ep. 10232 done, reward: 5.0, running_reward: 3.7964, time (sec): 136086.8282\n",
      "Ep. 10234 done, reward: 11.0, running_reward: 3.8902, time (sec): 136118.4145\n",
      "Ep. 10236 done, reward: 15.0, running_reward: 4.0222, time (sec): 136146.6005\n",
      "Ep. 10238 done, reward: 2.0, running_reward: 3.9126, time (sec): 136178.2248\n",
      "Ep. 10240 done, reward: -1.0, running_reward: 3.9238, time (sec): 136209.4782\n",
      "Ep. 10242 done, reward: 8.0, running_reward: 3.9851, time (sec): 136237.7246\n",
      "Ep. 10244 done, reward: 12.0, running_reward: 4.0753, time (sec): 136265.4852\n",
      "Ep. 10246 done, reward: 9.0, running_reward: 4.0545, time (sec): 136300.0930\n",
      "Ep. 10248 done, reward: 10.0, running_reward: 4.1134, time (sec): 136350.6707\n",
      "Ep. 10250 done, reward: 2.0, running_reward: 4.1308, time (sec): 136378.1168\n",
      "Ep. 10252 done, reward: 3.0, running_reward: 4.1083, time (sec): 136418.1729\n",
      "Ep. 10254 done, reward: 5.0, running_reward: 4.1359, time (sec): 136448.8188\n",
      "Ep. 10256 done, reward: 3.0, running_reward: 4.1232, time (sec): 136476.6907\n",
      "Ep. 10258 done, reward: 2.0, running_reward: 4.1700, time (sec): 136502.7586\n",
      "Ep. 10260 done, reward: 7.0, running_reward: 4.1373, time (sec): 136532.4954\n",
      "Ep. 10262 done, reward: 9.0, running_reward: 4.0459, time (sec): 136560.3242\n",
      "Ep. 10264 done, reward: 8.0, running_reward: 4.1048, time (sec): 136585.0657\n",
      "Ep. 10266 done, reward: -7.0, running_reward: 4.0323, time (sec): 136608.1657\n",
      "Ep. 10268 done, reward: -1.0, running_reward: 3.9124, time (sec): 136639.6252\n",
      "Ep. 10270 done, reward: 1.0, running_reward: 3.9534, time (sec): 136666.5187\n",
      "Ep. 10272 done, reward: 11.0, running_reward: 4.0739, time (sec): 136689.5933\n",
      "Ep. 10274 done, reward: -3.0, running_reward: 3.9826, time (sec): 136725.8726\n",
      "Ep. 10276 done, reward: 2.0, running_reward: 3.9431, time (sec): 136755.8477\n",
      "Ep. 10278 done, reward: 6.0, running_reward: 3.9940, time (sec): 136782.9732\n",
      "Ep. 10280 done, reward: 1.0, running_reward: 3.9938, time (sec): 136813.6458\n",
      "Ep. 10282 done, reward: 10.0, running_reward: 4.0539, time (sec): 136842.0107\n",
      "Ep. 10284 done, reward: 7.0, running_reward: 4.1620, time (sec): 136863.0693\n",
      "Ep. 10286 done, reward: -5.0, running_reward: 4.1084, time (sec): 136889.8561\n",
      "Ep. 10288 done, reward: -7.0, running_reward: 4.0359, time (sec): 136921.5584\n",
      "Ep. 10290 done, reward: -1.0, running_reward: 3.9950, time (sec): 136960.2410\n",
      "Ep. 10292 done, reward: 4.0, running_reward: 4.0842, time (sec): 136985.6888\n",
      "Ep. 10294 done, reward: 6.0, running_reward: 4.0531, time (sec): 137016.6862\n",
      "Ep. 10296 done, reward: 14.0, running_reward: 4.1718, time (sec): 137043.5062\n",
      "Ep. 10298 done, reward: 7.0, running_reward: 4.1489, time (sec): 137075.4817\n",
      "Ep. 10300 done, reward: 9.0, running_reward: 4.1761, time (sec): 137102.7036\n",
      "Ep. 10302 done, reward: 1.0, running_reward: 4.2317, time (sec): 137127.9708\n",
      "Ep. 10304 done, reward: 11.0, running_reward: 4.3664, time (sec): 137152.3170\n",
      "Ep. 10306 done, reward: 6.0, running_reward: 4.3890, time (sec): 137185.4562\n",
      "Ep. 10308 done, reward: 14.0, running_reward: 4.3823, time (sec): 137212.5632\n",
      "Ep. 10310 done, reward: 8.0, running_reward: 4.3157, time (sec): 137245.9747\n",
      "Ep. 10312 done, reward: -3.0, running_reward: 4.2097, time (sec): 137278.3074\n",
      "Ep. 10314 done, reward: 14.0, running_reward: 4.2560, time (sec): 137308.7301\n",
      "Ep. 10316 done, reward: -3.0, running_reward: 4.1512, time (sec): 137352.3943\n",
      "Ep. 10318 done, reward: -3.0, running_reward: 4.0980, time (sec): 137386.3334\n",
      "Ep. 10320 done, reward: 5.0, running_reward: 4.1457, time (sec): 137415.7665\n",
      "Ep. 10322 done, reward: -4.0, running_reward: 4.0430, time (sec): 137453.9626\n",
      "Ep. 10324 done, reward: 8.0, running_reward: 4.0128, time (sec): 137484.2118\n",
      "Ep. 10326 done, reward: 8.0, running_reward: 4.0031, time (sec): 137517.6859\n",
      "Ep. 10328 done, reward: 2.0, running_reward: 3.8741, time (sec): 137551.9340\n",
      "Ep. 10330 done, reward: 10.0, running_reward: 3.9960, time (sec): 137574.2464\n",
      "Ep. 10332 done, reward: -6.0, running_reward: 3.8070, time (sec): 137601.3040\n",
      "Ep. 10334 done, reward: -1.0, running_reward: 3.8103, time (sec): 137627.8849\n",
      "Ep. 10336 done, reward: 1.0, running_reward: 3.8633, time (sec): 137662.1535\n",
      "Ep. 10338 done, reward: 3.0, running_reward: 3.7966, time (sec): 137705.8355\n",
      "Ep. 10340 done, reward: 5.0, running_reward: 3.7513, time (sec): 137739.7035\n",
      "Ep. 10342 done, reward: 7.0, running_reward: 3.8456, time (sec): 137770.3629\n",
      "Ep. 10344 done, reward: 5.0, running_reward: 3.8983, time (sec): 137806.2778\n",
      "Ep. 10346 done, reward: -10.0, running_reward: 3.7405, time (sec): 137843.6288\n",
      "Ep. 10348 done, reward: -7.0, running_reward: 3.5268, time (sec): 137880.9640\n",
      "Ep. 10350 done, reward: 4.0, running_reward: 3.5065, time (sec): 137927.4723\n",
      "Ep. 10352 done, reward: 9.0, running_reward: 3.5168, time (sec): 137958.7921\n",
      "Ep. 10354 done, reward: 4.0, running_reward: 3.5957, time (sec): 137988.6651\n",
      "Ep. 10356 done, reward: -2.0, running_reward: 3.4250, time (sec): 138015.7246\n",
      "Ep. 10358 done, reward: 2.0, running_reward: 3.3669, time (sec): 138049.2798\n",
      "Ep. 10360 done, reward: 4.0, running_reward: 3.3696, time (sec): 138077.6904\n",
      "Ep. 10362 done, reward: 2.0, running_reward: 3.2731, time (sec): 138104.8058\n",
      "Ep. 10364 done, reward: 8.0, running_reward: 3.3077, time (sec): 138129.0658\n",
      "Ep. 10366 done, reward: -3.0, running_reward: 3.1426, time (sec): 138163.4927\n",
      "Ep. 10368 done, reward: 9.0, running_reward: 3.1206, time (sec): 138194.9008\n",
      "Ep. 10370 done, reward: 1.0, running_reward: 3.1180, time (sec): 138231.6103\n",
      "Ep. 10372 done, reward: 2.0, running_reward: 3.1551, time (sec): 138266.1632\n",
      "Ep. 10374 done, reward: 11.0, running_reward: 3.2221, time (sec): 138293.0440\n",
      "Ep. 10376 done, reward: 2.0, running_reward: 3.2473, time (sec): 138320.5588\n",
      "Ep. 10378 done, reward: 10.0, running_reward: 3.3322, time (sec): 138347.6948\n",
      "Ep. 10380 done, reward: -1.0, running_reward: 3.3846, time (sec): 138373.2126\n",
      "Ep. 10382 done, reward: -9.0, running_reward: 3.1381, time (sec): 138400.1738\n",
      "Ep. 10384 done, reward: -4.0, running_reward: 3.1248, time (sec): 138424.8960\n",
      "Ep. 10386 done, reward: 4.0, running_reward: 3.1323, time (sec): 138453.6444\n",
      "Ep. 10388 done, reward: -8.0, running_reward: 3.0791, time (sec): 138475.8192\n",
      "Ep. 10390 done, reward: 1.0, running_reward: 3.1268, time (sec): 138501.7834\n",
      "Ep. 10392 done, reward: 1.0, running_reward: 3.2231, time (sec): 138528.0490\n",
      "Ep. 10394 done, reward: 4.0, running_reward: 3.1890, time (sec): 138569.5507\n",
      "Ep. 10396 done, reward: 5.0, running_reward: 3.2152, time (sec): 138599.8804\n",
      "Ep. 10398 done, reward: -5.0, running_reward: 3.1111, time (sec): 138628.6184\n",
      "Ep. 10400 done, reward: 6.0, running_reward: 3.0399, time (sec): 138661.3546\n",
      "Ep. 10402 done, reward: -7.0, running_reward: 2.8005, time (sec): 138686.8255\n",
      "Ep. 10404 done, reward: 9.0, running_reward: 2.8743, time (sec): 138713.2544\n",
      "Ep. 10406 done, reward: -13.0, running_reward: 2.7465, time (sec): 138743.0722\n",
      "Ep. 10408 done, reward: 7.0, running_reward: 2.8312, time (sec): 138776.8032\n",
      "Ep. 10410 done, reward: -6.0, running_reward: 2.6455, time (sec): 138804.3966\n",
      "Ep. 10412 done, reward: 2.0, running_reward: 2.6624, time (sec): 138843.4221\n",
      "Ep. 10414 done, reward: 4.0, running_reward: 2.5999, time (sec): 138884.3331\n",
      "Ep. 10416 done, reward: 8.0, running_reward: 2.6678, time (sec): 138917.6736\n",
      "Ep. 10418 done, reward: 10.0, running_reward: 2.7345, time (sec): 138958.3370\n",
      "Ep. 10420 done, reward: 9.0, running_reward: 2.7899, time (sec): 138993.6350\n",
      "Ep. 10422 done, reward: 1.0, running_reward: 2.7642, time (sec): 139033.4815\n",
      "Ep. 10424 done, reward: 5.0, running_reward: 2.9077, time (sec): 139058.4857\n",
      "Ep. 10426 done, reward: 6.0, running_reward: 2.9296, time (sec): 139091.0182\n",
      "Ep. 10428 done, reward: 7.0, running_reward: 2.9314, time (sec): 139121.7861\n",
      "Ep. 10430 done, reward: 13.0, running_reward: 3.0625, time (sec): 139146.6516\n",
      "Ep. 10432 done, reward: -4.0, running_reward: 2.9417, time (sec): 139181.5436\n",
      "Ep. 10434 done, reward: 9.0, running_reward: 3.0029, time (sec): 139210.5792\n",
      "Ep. 10436 done, reward: -9.0, running_reward: 2.8036, time (sec): 139237.8859\n",
      "Ep. 10438 done, reward: 5.0, running_reward: 2.9265, time (sec): 139260.1204\n",
      "Ep. 10440 done, reward: -2.0, running_reward: 2.8582, time (sec): 139291.9752\n",
      "Ep. 10442 done, reward: 10.0, running_reward: 3.0102, time (sec): 139313.4385\n",
      "Ep. 10444 done, reward: -6.0, running_reward: 2.8507, time (sec): 139343.6795\n",
      "Ep. 10446 done, reward: 3.0, running_reward: 2.9230, time (sec): 139367.5008\n",
      "Ep. 10448 done, reward: 1.0, running_reward: 2.9144, time (sec): 139398.4687\n",
      "Ep. 10450 done, reward: 11.0, running_reward: 3.0357, time (sec): 139423.6803\n",
      "Ep. 10452 done, reward: 3.0, running_reward: 3.0845, time (sec): 139461.5794\n",
      "Ep. 10454 done, reward: 7.0, running_reward: 2.9842, time (sec): 139495.9098\n",
      "Ep. 10456 done, reward: -4.0, running_reward: 2.9145, time (sec): 139532.4322\n",
      "Ep. 10458 done, reward: 1.0, running_reward: 2.8467, time (sec): 139576.9506\n",
      "Ep. 10460 done, reward: -11.0, running_reward: 2.6504, time (sec): 139618.8429\n",
      "Ep. 10462 done, reward: 6.0, running_reward: 2.6972, time (sec): 139654.5415\n",
      "Ep. 10464 done, reward: 3.0, running_reward: 2.7330, time (sec): 139685.5613\n",
      "Ep. 10466 done, reward: -1.0, running_reward: 2.6290, time (sec): 139717.9751\n",
      "Ep. 10468 done, reward: -3.0, running_reward: 2.6061, time (sec): 139757.8252\n",
      "Ep. 10470 done, reward: -9.0, running_reward: 2.4147, time (sec): 139795.6351\n",
      "Ep. 10472 done, reward: -5.0, running_reward: 2.4355, time (sec): 139821.3698\n",
      "Ep. 10474 done, reward: -3.0, running_reward: 2.3273, time (sec): 139852.3783\n",
      "Ep. 10476 done, reward: 11.0, running_reward: 2.3811, time (sec): 139876.3497\n",
      "Ep. 10478 done, reward: 2.0, running_reward: 2.4428, time (sec): 139900.8337\n",
      "Ep. 10480 done, reward: -7.0, running_reward: 2.4133, time (sec): 139927.0232\n",
      "Ep. 10482 done, reward: 16.0, running_reward: 2.3966, time (sec): 139946.5448\n",
      "Ep. 10484 done, reward: 7.0, running_reward: 2.3991, time (sec): 139971.5153\n",
      "Ep. 10486 done, reward: -1.0, running_reward: 2.4205, time (sec): 139995.7558\n",
      "Ep. 10488 done, reward: 8.0, running_reward: 2.3930, time (sec): 140020.6036\n",
      "Ep. 10490 done, reward: -8.0, running_reward: 2.2158, time (sec): 140048.7093\n",
      "Ep. 10492 done, reward: 4.0, running_reward: 2.1919, time (sec): 140081.0707\n",
      "Ep. 10494 done, reward: -10.0, running_reward: 2.1374, time (sec): 140106.3528\n",
      "Ep. 10496 done, reward: 4.0, running_reward: 2.0656, time (sec): 140135.4048\n",
      "Ep. 10498 done, reward: 1.0, running_reward: 2.1533, time (sec): 140163.7430\n",
      "Ep. 10500 done, reward: 3.0, running_reward: 2.2592, time (sec): 140194.4383\n",
      "Ep. 10502 done, reward: 11.0, running_reward: 2.4035, time (sec): 140219.9229\n",
      "Ep. 10504 done, reward: -3.0, running_reward: 2.3157, time (sec): 140258.1636\n",
      "Ep. 10506 done, reward: 6.0, running_reward: 2.3693, time (sec): 140286.4528\n",
      "Ep. 10508 done, reward: 1.0, running_reward: 2.4014, time (sec): 140320.0262\n",
      "Ep. 10510 done, reward: 3.0, running_reward: 2.3044, time (sec): 140349.5187\n",
      "Ep. 10512 done, reward: 13.0, running_reward: 2.4678, time (sec): 140372.6562\n",
      "Ep. 10514 done, reward: 15.0, running_reward: 2.6380, time (sec): 140397.4915\n",
      "Ep. 10516 done, reward: 13.0, running_reward: 2.6957, time (sec): 140427.6667\n",
      "Ep. 10518 done, reward: -4.0, running_reward: 2.5624, time (sec): 140458.7684\n",
      "Ep. 10520 done, reward: 7.0, running_reward: 2.6507, time (sec): 140488.9344\n",
      "Ep. 10522 done, reward: -1.0, running_reward: 2.6375, time (sec): 140522.6364\n",
      "Ep. 10524 done, reward: 14.0, running_reward: 2.7151, time (sec): 140552.8106\n",
      "Ep. 10526 done, reward: -12.0, running_reward: 2.5114, time (sec): 140587.0886\n",
      "Ep. 10528 done, reward: 14.0, running_reward: 2.6311, time (sec): 140613.8574\n",
      "Ep. 10530 done, reward: -1.0, running_reward: 2.4994, time (sec): 140643.7386\n",
      "Ep. 10532 done, reward: -6.0, running_reward: 2.3303, time (sec): 140674.7280\n",
      "Ep. 10534 done, reward: 6.0, running_reward: 2.3043, time (sec): 140701.5173\n",
      "Ep. 10536 done, reward: 10.0, running_reward: 2.3783, time (sec): 140728.0924\n",
      "Ep. 10538 done, reward: -9.0, running_reward: 2.2310, time (sec): 140761.1651\n",
      "Ep. 10540 done, reward: -5.0, running_reward: 2.1762, time (sec): 140789.1928\n",
      "Ep. 10542 done, reward: -5.0, running_reward: 2.2215, time (sec): 140811.1131\n",
      "Ep. 10544 done, reward: 5.0, running_reward: 2.1184, time (sec): 140839.7858\n",
      "Ep. 10546 done, reward: 12.0, running_reward: 2.2458, time (sec): 140866.7884\n",
      "Ep. 10548 done, reward: 1.0, running_reward: 2.1319, time (sec): 140897.0425\n",
      "Ep. 10550 done, reward: -1.0, running_reward: 2.1091, time (sec): 140929.3462\n",
      "Ep. 10552 done, reward: 4.0, running_reward: 2.2062, time (sec): 140955.4166\n",
      "Ep. 10554 done, reward: 1.0, running_reward: 2.2911, time (sec): 140982.2177\n",
      "Ep. 10556 done, reward: 15.0, running_reward: 2.4549, time (sec): 141005.2152\n",
      "Ep. 10558 done, reward: -6.0, running_reward: 2.3262, time (sec): 141034.6822\n",
      "Ep. 10560 done, reward: 6.0, running_reward: 2.3102, time (sec): 141062.3424\n",
      "Ep. 10562 done, reward: 11.0, running_reward: 2.4832, time (sec): 141085.1895\n",
      "Ep. 10564 done, reward: 2.0, running_reward: 2.5824, time (sec): 141106.9575\n",
      "Ep. 10566 done, reward: 9.0, running_reward: 2.6607, time (sec): 141133.8702\n",
      "Ep. 10568 done, reward: 7.0, running_reward: 2.8064, time (sec): 141156.4930\n",
      "Ep. 10570 done, reward: -2.0, running_reward: 2.8098, time (sec): 141182.3349\n",
      "Ep. 10572 done, reward: 13.0, running_reward: 2.8541, time (sec): 141207.9049\n",
      "Ep. 10574 done, reward: 11.0, running_reward: 2.8677, time (sec): 141233.1376\n",
      "Ep. 10576 done, reward: 9.0, running_reward: 3.0096, time (sec): 141255.7609\n",
      "Ep. 10578 done, reward: 8.0, running_reward: 3.0000, time (sec): 141283.1590\n",
      "Ep. 10580 done, reward: -11.0, running_reward: 2.8897, time (sec): 141308.5573\n",
      "Ep. 10582 done, reward: 11.0, running_reward: 2.9521, time (sec): 141333.6971\n",
      "Ep. 10584 done, reward: 12.0, running_reward: 3.0925, time (sec): 141358.5882\n",
      "Ep. 10586 done, reward: 1.0, running_reward: 2.9717, time (sec): 141388.4893\n",
      "Ep. 10588 done, reward: 2.0, running_reward: 3.0613, time (sec): 141411.1534\n",
      "Ep. 10590 done, reward: 13.0, running_reward: 3.0709, time (sec): 141433.9261\n",
      "Ep. 10592 done, reward: -9.0, running_reward: 3.0089, time (sec): 141458.8445\n",
      "Ep. 10594 done, reward: -9.0, running_reward: 2.9284, time (sec): 141483.9989\n",
      "Ep. 10596 done, reward: 4.0, running_reward: 2.8408, time (sec): 141512.7082\n",
      "Ep. 10598 done, reward: -2.0, running_reward: 2.7840, time (sec): 141538.0234\n",
      "Ep. 10600 done, reward: 6.0, running_reward: 2.8381, time (sec): 141561.3548\n",
      "Ep. 10602 done, reward: 4.0, running_reward: 2.9108, time (sec): 141588.9774\n",
      "Ep. 10604 done, reward: -6.0, running_reward: 2.8918, time (sec): 141613.4490\n",
      "Ep. 10606 done, reward: -3.0, running_reward: 2.8637, time (sec): 141641.3043\n",
      "Ep. 10608 done, reward: -1.0, running_reward: 2.7769, time (sec): 141675.7990\n",
      "Ep. 10610 done, reward: 7.0, running_reward: 2.8807, time (sec): 141703.0443\n",
      "Ep. 10612 done, reward: 8.0, running_reward: 2.9925, time (sec): 141738.2027\n",
      "Ep. 10614 done, reward: -2.0, running_reward: 3.0021, time (sec): 141766.9410\n",
      "Ep. 10616 done, reward: 3.0, running_reward: 3.0020, time (sec): 141797.3299\n",
      "Ep. 10618 done, reward: 8.0, running_reward: 3.0421, time (sec): 141822.6292\n",
      "Ep. 10620 done, reward: -6.0, running_reward: 2.8918, time (sec): 141849.8620\n",
      "Ep. 10622 done, reward: 6.0, running_reward: 2.9537, time (sec): 141874.6465\n",
      "Ep. 10624 done, reward: 1.0, running_reward: 2.8653, time (sec): 141901.6994\n",
      "Ep. 10626 done, reward: -3.0, running_reward: 2.8476, time (sec): 141930.5852\n",
      "Ep. 10628 done, reward: 6.0, running_reward: 2.9301, time (sec): 141961.8901\n",
      "Ep. 10630 done, reward: 8.0, running_reward: 3.0013, time (sec): 141993.2704\n",
      "Ep. 10632 done, reward: -5.0, running_reward: 2.9609, time (sec): 142026.8033\n",
      "Ep. 10634 done, reward: 6.0, running_reward: 2.8927, time (sec): 142057.3408\n",
      "Ep. 10636 done, reward: 10.0, running_reward: 2.9648, time (sec): 142087.0421\n",
      "Ep. 10638 done, reward: -2.0, running_reward: 2.9353, time (sec): 142128.3297\n",
      "Ep. 10640 done, reward: 9.0, running_reward: 2.9867, time (sec): 142164.5108\n",
      "Ep. 10642 done, reward: 9.0, running_reward: 3.0470, time (sec): 142194.0576\n",
      "Ep. 10644 done, reward: -5.0, running_reward: 2.9858, time (sec): 142228.4427\n",
      "Ep. 10646 done, reward: -5.0, running_reward: 2.9358, time (sec): 142262.2264\n",
      "Ep. 10648 done, reward: -4.0, running_reward: 2.8275, time (sec): 142297.7273\n",
      "Ep. 10650 done, reward: 13.0, running_reward: 2.8715, time (sec): 142326.0774\n",
      "Ep. 10652 done, reward: 11.0, running_reward: 3.0630, time (sec): 142346.9907\n",
      "Ep. 10654 done, reward: 1.0, running_reward: 3.0318, time (sec): 142382.3183\n",
      "Ep. 10656 done, reward: 4.0, running_reward: 3.0214, time (sec): 142409.9963\n",
      "Ep. 10658 done, reward: -9.0, running_reward: 2.9406, time (sec): 142441.6187\n",
      "Ep. 10660 done, reward: 8.0, running_reward: 2.9521, time (sec): 142474.1490\n",
      "Ep. 10662 done, reward: -3.0, running_reward: 2.9624, time (sec): 142504.7375\n",
      "Ep. 10664 done, reward: 10.0, running_reward: 2.9341, time (sec): 142539.3650\n",
      "Ep. 10666 done, reward: 1.0, running_reward: 2.8561, time (sec): 142570.7215\n",
      "Ep. 10668 done, reward: 4.0, running_reward: 2.7996, time (sec): 142599.0795\n",
      "Ep. 10670 done, reward: -14.0, running_reward: 2.5544, time (sec): 142626.4552\n",
      "Ep. 10672 done, reward: 4.0, running_reward: 2.6426, time (sec): 142652.3192\n",
      "Ep. 10674 done, reward: 9.0, running_reward: 2.6305, time (sec): 142677.4675\n",
      "Ep. 10676 done, reward: -2.0, running_reward: 2.5977, time (sec): 142713.5088\n",
      "Ep. 10678 done, reward: 12.0, running_reward: 2.7254, time (sec): 142737.2074\n",
      "Ep. 10680 done, reward: -1.0, running_reward: 2.7503, time (sec): 142766.6853\n",
      "Ep. 10682 done, reward: -5.0, running_reward: 2.5961, time (sec): 142797.6870\n",
      "Ep. 10684 done, reward: 1.0, running_reward: 2.5049, time (sec): 142827.3195\n",
      "Ep. 10686 done, reward: 12.0, running_reward: 2.6048, time (sec): 142852.7577\n",
      "Ep. 10688 done, reward: 10.0, running_reward: 2.6034, time (sec): 142879.7488\n",
      "Ep. 10690 done, reward: 12.0, running_reward: 2.6221, time (sec): 142903.8041\n",
      "Ep. 10692 done, reward: -1.0, running_reward: 2.6292, time (sec): 142936.6919\n",
      "Ep. 10694 done, reward: 13.0, running_reward: 2.5881, time (sec): 142958.1020\n",
      "Ep. 10696 done, reward: 6.0, running_reward: 2.5867, time (sec): 142989.0059\n",
      "Ep. 10698 done, reward: -3.0, running_reward: 2.4458, time (sec): 143018.0878\n",
      "Ep. 10700 done, reward: 8.0, running_reward: 2.5663, time (sec): 143040.2956\n",
      "Ep. 10702 done, reward: -11.0, running_reward: 2.3656, time (sec): 143068.6234\n",
      "Ep. 10704 done, reward: 14.0, running_reward: 2.4090, time (sec): 143090.4615\n",
      "Ep. 10706 done, reward: -3.0, running_reward: 2.3707, time (sec): 143116.7087\n",
      "Ep. 10708 done, reward: 6.0, running_reward: 2.3736, time (sec): 143143.2555\n",
      "Ep. 10710 done, reward: 13.0, running_reward: 2.4762, time (sec): 143171.1775\n",
      "Ep. 10712 done, reward: -5.0, running_reward: 2.4264, time (sec): 143196.4334\n",
      "Ep. 10714 done, reward: 3.0, running_reward: 2.3487, time (sec): 143222.7608\n",
      "Ep. 10716 done, reward: 8.0, running_reward: 2.4117, time (sec): 143247.0211\n",
      "Ep. 10718 done, reward: -5.0, running_reward: 2.3038, time (sec): 143273.9878\n",
      "Ep. 10720 done, reward: 11.0, running_reward: 2.4075, time (sec): 143303.3349\n",
      "Ep. 10722 done, reward: 15.0, running_reward: 2.4898, time (sec): 143328.9181\n",
      "Ep. 10724 done, reward: -3.0, running_reward: 2.4598, time (sec): 143354.7948\n",
      "Ep. 10726 done, reward: -9.0, running_reward: 2.4297, time (sec): 143378.8194\n",
      "Ep. 10728 done, reward: -1.0, running_reward: 2.3813, time (sec): 143410.6136\n",
      "Ep. 10730 done, reward: -4.0, running_reward: 2.3335, time (sec): 143439.7022\n",
      "Ep. 10732 done, reward: -9.0, running_reward: 2.2070, time (sec): 143469.4870\n",
      "Ep. 10734 done, reward: -4.0, running_reward: 2.0339, time (sec): 143499.2964\n",
      "Ep. 10736 done, reward: -4.0, running_reward: 2.0525, time (sec): 143526.8031\n",
      "Ep. 10738 done, reward: 1.0, running_reward: 2.1107, time (sec): 143553.5257\n",
      "Ep. 10740 done, reward: 4.0, running_reward: 2.1582, time (sec): 143580.7542\n",
      "Ep. 10742 done, reward: -10.0, running_reward: 1.9757, time (sec): 143609.5827\n",
      "Ep. 10744 done, reward: 11.0, running_reward: 2.0167, time (sec): 143634.6043\n",
      "Ep. 10746 done, reward: 9.0, running_reward: 2.0467, time (sec): 143661.6231\n",
      "Ep. 10748 done, reward: 9.0, running_reward: 2.1356, time (sec): 143687.1399\n",
      "Ep. 10750 done, reward: -5.0, running_reward: 2.0728, time (sec): 143713.9525\n",
      "Ep. 10752 done, reward: -3.0, running_reward: 2.1203, time (sec): 143737.6867\n",
      "Ep. 10754 done, reward: 1.0, running_reward: 1.9891, time (sec): 143767.6955\n",
      "Ep. 10756 done, reward: 2.0, running_reward: 2.0785, time (sec): 143793.6933\n",
      "Ep. 10758 done, reward: 6.0, running_reward: 2.1268, time (sec): 143819.2888\n",
      "Ep. 10760 done, reward: 4.0, running_reward: 2.2037, time (sec): 143845.5443\n",
      "Ep. 10762 done, reward: 12.0, running_reward: 2.3194, time (sec): 143871.2695\n",
      "Ep. 10764 done, reward: -1.0, running_reward: 2.2336, time (sec): 143905.3689\n",
      "Ep. 10766 done, reward: 4.0, running_reward: 2.3380, time (sec): 143932.2126\n",
      "Ep. 10768 done, reward: 5.0, running_reward: 2.2920, time (sec): 143959.3624\n",
      "Ep. 10770 done, reward: -1.0, running_reward: 2.2958, time (sec): 143987.1756\n",
      "Ep. 10772 done, reward: -6.0, running_reward: 2.1802, time (sec): 144015.4050\n",
      "Ep. 10774 done, reward: -4.0, running_reward: 2.2354, time (sec): 144039.8139\n",
      "Ep. 10776 done, reward: -8.0, running_reward: 2.1010, time (sec): 144069.4050\n",
      "Ep. 10778 done, reward: 6.0, running_reward: 2.0895, time (sec): 144095.6794\n",
      "Ep. 10780 done, reward: 5.0, running_reward: 2.1573, time (sec): 144120.3220\n",
      "Ep. 10782 done, reward: 6.0, running_reward: 2.1150, time (sec): 144145.9795\n",
      "Ep. 10784 done, reward: 6.0, running_reward: 2.1032, time (sec): 144172.4386\n",
      "Ep. 10786 done, reward: -4.0, running_reward: 1.9620, time (sec): 144210.0683\n",
      "Ep. 10788 done, reward: -1.0, running_reward: 1.9030, time (sec): 144244.2997\n",
      "Ep. 10790 done, reward: -2.0, running_reward: 1.7659, time (sec): 144282.4707\n",
      "Ep. 10792 done, reward: -1.0, running_reward: 1.6713, time (sec): 144325.3774\n",
      "Ep. 10794 done, reward: -3.0, running_reward: 1.7268, time (sec): 144356.1532\n",
      "Ep. 10796 done, reward: 8.0, running_reward: 1.7527, time (sec): 144382.2711\n",
      "Ep. 10798 done, reward: 1.0, running_reward: 1.6387, time (sec): 144421.0651\n",
      "Ep. 10800 done, reward: 12.0, running_reward: 1.7855, time (sec): 144447.0959\n",
      "Ep. 10802 done, reward: 6.0, running_reward: 1.8595, time (sec): 144483.1620\n",
      "Ep. 10804 done, reward: -3.0, running_reward: 1.8816, time (sec): 144521.3693\n",
      "Ep. 10806 done, reward: 3.0, running_reward: 1.8840, time (sec): 144555.6871\n",
      "Ep. 10808 done, reward: 3.0, running_reward: 1.8963, time (sec): 144584.0682\n",
      "Ep. 10810 done, reward: 12.0, running_reward: 2.1271, time (sec): 144602.9134\n",
      "Ep. 10812 done, reward: -2.0, running_reward: 2.1044, time (sec): 144636.0935\n",
      "Ep. 10814 done, reward: -10.0, running_reward: 2.1011, time (sec): 144661.0459\n",
      "Ep. 10816 done, reward: -6.0, running_reward: 2.0785, time (sec): 144687.5141\n",
      "Ep. 10818 done, reward: 10.0, running_reward: 2.1668, time (sec): 144711.7611\n",
      "Ep. 10820 done, reward: 8.0, running_reward: 2.2730, time (sec): 144735.8318\n",
      "Ep. 10822 done, reward: -3.0, running_reward: 2.1384, time (sec): 144761.1075\n",
      "Ep. 10824 done, reward: 6.0, running_reward: 2.2647, time (sec): 144784.5528\n",
      "Ep. 10826 done, reward: -11.0, running_reward: 2.0799, time (sec): 144809.1909\n",
      "Ep. 10828 done, reward: -4.0, running_reward: 2.0480, time (sec): 144840.6333\n",
      "Ep. 10830 done, reward: -7.0, running_reward: 1.8878, time (sec): 144871.4260\n",
      "Ep. 10832 done, reward: -6.0, running_reward: 1.9387, time (sec): 144894.9985\n",
      "Ep. 10834 done, reward: -5.0, running_reward: 1.8798, time (sec): 144921.9217\n",
      "Ep. 10836 done, reward: 5.0, running_reward: 1.8627, time (sec): 144949.6891\n",
      "Ep. 10838 done, reward: -1.0, running_reward: 1.7266, time (sec): 144978.1164\n",
      "Ep. 10840 done, reward: 2.0, running_reward: 1.7617, time (sec): 145004.9937\n",
      "Ep. 10842 done, reward: 6.0, running_reward: 1.8658, time (sec): 145032.0116\n",
      "Ep. 10844 done, reward: -4.0, running_reward: 1.8679, time (sec): 145057.9006\n",
      "Ep. 10846 done, reward: 6.0, running_reward: 1.9105, time (sec): 145090.4388\n",
      "Ep. 10848 done, reward: -5.0, running_reward: 1.8423, time (sec): 145117.8083\n",
      "Ep. 10850 done, reward: -1.0, running_reward: 1.6967, time (sec): 145147.8856\n",
      "Ep. 10852 done, reward: 15.0, running_reward: 1.9020, time (sec): 145169.3875\n",
      "Ep. 10854 done, reward: 9.0, running_reward: 2.0532, time (sec): 145191.2084\n",
      "Ep. 10856 done, reward: -2.0, running_reward: 2.1111, time (sec): 145218.2924\n",
      "Ep. 10858 done, reward: 7.0, running_reward: 2.2579, time (sec): 145241.4110\n",
      "Ep. 10860 done, reward: 5.0, running_reward: 2.1937, time (sec): 145264.6674\n",
      "Ep. 10862 done, reward: 8.0, running_reward: 2.2102, time (sec): 145647.9630\n",
      "Ep. 10864 done, reward: 2.0, running_reward: 2.1466, time (sec): 145680.9955\n",
      "Ep. 10866 done, reward: 1.0, running_reward: 2.1238, time (sec): 146194.7897\n",
      "Ep. 10868 done, reward: 8.0, running_reward: 2.1318, time (sec): 146230.7828\n",
      "Ep. 10870 done, reward: 14.0, running_reward: 2.2195, time (sec): 146271.9584\n",
      "Ep. 10872 done, reward: 10.0, running_reward: 2.4139, time (sec): 146299.8454\n",
      "Ep. 10874 done, reward: -2.0, running_reward: 2.4152, time (sec): 146351.7713\n",
      "Ep. 10876 done, reward: 3.0, running_reward: 2.3872, time (sec): 146385.6444\n",
      "Ep. 10878 done, reward: -10.0, running_reward: 2.2793, time (sec): 146420.5950\n",
      "Ep. 10880 done, reward: -1.0, running_reward: 2.1745, time (sec): 146454.7649\n",
      "Ep. 10882 done, reward: 11.0, running_reward: 2.1818, time (sec): 146487.3548\n",
      "Ep. 10884 done, reward: 2.0, running_reward: 2.1881, time (sec): 146531.5063\n",
      "Ep. 10886 done, reward: 8.0, running_reward: 2.2740, time (sec): 146567.4328\n",
      "Ep. 10888 done, reward: -10.0, running_reward: 2.1684, time (sec): 146599.2962\n",
      "Ep. 10890 done, reward: 4.0, running_reward: 2.1850, time (sec): 146646.1495\n",
      "Ep. 10892 done, reward: 14.0, running_reward: 2.2915, time (sec): 146675.2068\n",
      "Ep. 10894 done, reward: -1.0, running_reward: 2.2953, time (sec): 146703.7594\n",
      "Ep. 10896 done, reward: -7.0, running_reward: 2.2390, time (sec): 146729.9934\n",
      "Ep. 10898 done, reward: 2.0, running_reward: 2.2540, time (sec): 146759.9344\n",
      "Ep. 10900 done, reward: 1.0, running_reward: 2.2093, time (sec): 146792.7025\n",
      "Ep. 10902 done, reward: 5.0, running_reward: 2.2945, time (sec): 146823.6200\n",
      "Ep. 10904 done, reward: 3.0, running_reward: 2.3085, time (sec): 146858.4822\n",
      "Ep. 10906 done, reward: -5.0, running_reward: 2.2522, time (sec): 146902.7597\n",
      "Ep. 10908 done, reward: 7.0, running_reward: 2.2081, time (sec): 146931.5726\n",
      "Ep. 10910 done, reward: 11.0, running_reward: 2.3335, time (sec): 146958.3955\n",
      "Ep. 10912 done, reward: 4.0, running_reward: 2.3469, time (sec): 147005.6146\n",
      "Ep. 10914 done, reward: 6.0, running_reward: 2.4691, time (sec): 147033.9602\n",
      "Ep. 10916 done, reward: 10.0, running_reward: 2.5893, time (sec): 147065.0857\n",
      "Ep. 10918 done, reward: 7.0, running_reward: 2.6572, time (sec): 147097.9585\n",
      "Ep. 10920 done, reward: 9.0, running_reward: 2.8033, time (sec): 147126.2431\n",
      "Ep. 10922 done, reward: 10.0, running_reward: 2.9366, time (sec): 147156.7644\n",
      "Ep. 10924 done, reward: 13.0, running_reward: 2.9487, time (sec): 147187.8879\n",
      "Ep. 10926 done, reward: 7.0, running_reward: 3.0195, time (sec): 147217.0074\n",
      "Ep. 10928 done, reward: 6.0, running_reward: 3.1085, time (sec): 147246.2295\n",
      "Ep. 10930 done, reward: 1.0, running_reward: 3.0269, time (sec): 147290.2095\n",
      "Ep. 10932 done, reward: 4.0, running_reward: 3.0859, time (sec): 147336.6028\n",
      "Ep. 10934 done, reward: -10.0, running_reward: 3.0235, time (sec): 147375.9489\n",
      "Ep. 10936 done, reward: -11.0, running_reward: 2.8137, time (sec): 147407.9119\n",
      "Ep. 10938 done, reward: 7.0, running_reward: 2.8772, time (sec): 147435.9500\n",
      "Ep. 10940 done, reward: 7.0, running_reward: 2.9692, time (sec): 147468.2217\n",
      "Ep. 10942 done, reward: 1.0, running_reward: 2.9795, time (sec): 147496.9054\n",
      "Ep. 10944 done, reward: -1.0, running_reward: 3.0191, time (sec): 147527.7608\n",
      "Ep. 10946 done, reward: 6.0, running_reward: 3.0388, time (sec): 147553.7530\n",
      "Ep. 10948 done, reward: 12.0, running_reward: 3.0488, time (sec): 147587.3164\n",
      "Ep. 10950 done, reward: 11.0, running_reward: 3.1081, time (sec): 147616.7275\n",
      "Ep. 10952 done, reward: -9.0, running_reward: 3.0057, time (sec): 147647.9459\n",
      "Ep. 10954 done, reward: 5.0, running_reward: 3.1246, time (sec): 147672.3695\n",
      "Ep. 10956 done, reward: -3.0, running_reward: 3.0225, time (sec): 147708.0335\n",
      "Ep. 10958 done, reward: 5.0, running_reward: 2.9629, time (sec): 147735.9323\n",
      "Ep. 10960 done, reward: 8.0, running_reward: 3.0433, time (sec): 147765.6650\n",
      "Ep. 10962 done, reward: 1.0, running_reward: 3.0323, time (sec): 147796.6805\n",
      "Ep. 10964 done, reward: -4.0, running_reward: 3.0211, time (sec): 147822.7556\n",
      "Ep. 10966 done, reward: 15.0, running_reward: 3.0021, time (sec): 147843.1355\n",
      "Ep. 10968 done, reward: 10.0, running_reward: 3.0225, time (sec): 147864.8775\n",
      "Ep. 10970 done, reward: 11.0, running_reward: 3.0823, time (sec): 147891.0323\n",
      "Ep. 10972 done, reward: -1.0, running_reward: 2.9515, time (sec): 147921.0709\n",
      "Ep. 10974 done, reward: -11.0, running_reward: 2.7333, time (sec): 147952.6759\n",
      "Ep. 10976 done, reward: -2.0, running_reward: 2.7084, time (sec): 147990.6261\n",
      "Ep. 10978 done, reward: -5.0, running_reward: 2.6540, time (sec): 148016.6422\n",
      "Ep. 10980 done, reward: 9.0, running_reward: 2.6120, time (sec): 148040.2569\n",
      "Ep. 10982 done, reward: 14.0, running_reward: 2.7792, time (sec): 148063.3355\n",
      "Ep. 10984 done, reward: -9.0, running_reward: 2.6438, time (sec): 148089.8541\n",
      "Ep. 10986 done, reward: -5.0, running_reward: 2.4620, time (sec): 148115.0596\n",
      "Ep. 10988 done, reward: 4.0, running_reward: 2.4332, time (sec): 148147.4652\n",
      "Ep. 10990 done, reward: 7.0, running_reward: 2.5043, time (sec): 148175.0057\n",
      "Ep. 10992 done, reward: 5.0, running_reward: 2.6530, time (sec): 148197.8802\n",
      "Ep. 10994 done, reward: 8.0, running_reward: 2.7000, time (sec): 148222.4679\n",
      "Ep. 10996 done, reward: -7.0, running_reward: 2.6356, time (sec): 148260.0058\n",
      "Ep. 10998 done, reward: 4.0, running_reward: 2.5935, time (sec): 148287.9269\n",
      "Ep. 11000 done, reward: 3.0, running_reward: 2.6115, time (sec): 148317.5902\n",
      "Ep. 11002 done, reward: 2.0, running_reward: 2.6290, time (sec): 148348.8769\n",
      "Ep. 11004 done, reward: -1.0, running_reward: 2.7251, time (sec): 148369.6029\n",
      "Ep. 11006 done, reward: 7.0, running_reward: 2.8696, time (sec): 148395.3731\n",
      "Ep. 11008 done, reward: -5.0, running_reward: 2.8516, time (sec): 148421.9788\n",
      "Ep. 11010 done, reward: 9.0, running_reward: 2.9640, time (sec): 148444.3195\n",
      "Ep. 11012 done, reward: -5.0, running_reward: 2.8451, time (sec): 148478.6982\n",
      "Ep. 11014 done, reward: 10.0, running_reward: 3.0073, time (sec): 148501.1944\n",
      "Ep. 11016 done, reward: -3.0, running_reward: 2.8878, time (sec): 148535.6518\n",
      "Ep. 11018 done, reward: -5.0, running_reward: 2.8694, time (sec): 148561.3319\n",
      "Ep. 11020 done, reward: 2.0, running_reward: 2.8719, time (sec): 148591.5144\n",
      "Ep. 11022 done, reward: -5.0, running_reward: 2.7746, time (sec): 148618.1575\n",
      "Ep. 11024 done, reward: 2.0, running_reward: 2.8087, time (sec): 148645.4382\n",
      "Ep. 11026 done, reward: 14.0, running_reward: 2.9819, time (sec): 148666.1006\n",
      "Ep. 11028 done, reward: -1.0, running_reward: 2.9621, time (sec): 148695.0408\n",
      "Ep. 11030 done, reward: -11.0, running_reward: 2.8922, time (sec): 148718.7076\n",
      "Ep. 11032 done, reward: 1.0, running_reward: 2.9931, time (sec): 148748.5966\n",
      "Ep. 11034 done, reward: 6.0, running_reward: 2.8648, time (sec): 148778.4971\n",
      "Ep. 11036 done, reward: 8.0, running_reward: 2.9967, time (sec): 148802.3270\n",
      "Ep. 11038 done, reward: 12.0, running_reward: 3.1759, time (sec): 148830.7138\n",
      "Ep. 11040 done, reward: 7.0, running_reward: 3.1530, time (sec): 148861.2685\n",
      "Ep. 11042 done, reward: 5.0, running_reward: 3.1699, time (sec): 148888.2197\n",
      "Ep. 11044 done, reward: -7.0, running_reward: 3.0963, time (sec): 148913.8762\n",
      "Ep. 11046 done, reward: -9.0, running_reward: 3.0040, time (sec): 148940.2537\n",
      "Ep. 11048 done, reward: -5.0, running_reward: 2.7557, time (sec): 148969.4293\n",
      "Ep. 11050 done, reward: 9.0, running_reward: 2.9393, time (sec): 149001.6341\n",
      "Ep. 11052 done, reward: 5.0, running_reward: 3.0199, time (sec): 149035.2191\n",
      "Ep. 11054 done, reward: 3.0, running_reward: 3.0195, time (sec): 149072.2924\n",
      "Ep. 11056 done, reward: 3.0, running_reward: 2.9400, time (sec): 149100.8808\n",
      "Ep. 11058 done, reward: 13.0, running_reward: 2.9817, time (sec): 149123.4012\n",
      "Ep. 11060 done, reward: 5.0, running_reward: 2.8437, time (sec): 149149.5672\n",
      "Ep. 11062 done, reward: 4.0, running_reward: 2.8865, time (sec): 149175.5450\n",
      "Ep. 11064 done, reward: 5.0, running_reward: 2.9781, time (sec): 149203.2785\n",
      "Ep. 11066 done, reward: 12.0, running_reward: 3.1576, time (sec): 149226.9536\n",
      "Ep. 11068 done, reward: 9.0, running_reward: 3.2145, time (sec): 149267.8663\n",
      "Ep. 11070 done, reward: 7.0, running_reward: 3.1413, time (sec): 149299.7290\n",
      "Ep. 11072 done, reward: -9.0, running_reward: 3.1571, time (sec): 149328.2920\n",
      "Ep. 11074 done, reward: 10.0, running_reward: 3.2240, time (sec): 149356.3166\n",
      "Ep. 11076 done, reward: 5.0, running_reward: 3.2989, time (sec): 149380.4751\n",
      "Ep. 11078 done, reward: 7.0, running_reward: 3.2637, time (sec): 149403.4626\n",
      "Ep. 11080 done, reward: 5.0, running_reward: 3.3081, time (sec): 149431.8249\n",
      "Ep. 11082 done, reward: -3.0, running_reward: 3.2519, time (sec): 149460.5602\n",
      "Ep. 11084 done, reward: 10.0, running_reward: 3.3565, time (sec): 149486.7142\n",
      "Ep. 11086 done, reward: 13.0, running_reward: 3.4593, time (sec): 149525.4427\n",
      "Ep. 11088 done, reward: 5.0, running_reward: 3.5592, time (sec): 149552.3982\n",
      "Ep. 11090 done, reward: 14.0, running_reward: 3.6482, time (sec): 149580.5143\n",
      "Ep. 11092 done, reward: -3.0, running_reward: 3.6842, time (sec): 149606.0902\n",
      "Ep. 11094 done, reward: 3.0, running_reward: 3.7201, time (sec): 149630.2449\n",
      "Ep. 11096 done, reward: 3.0, running_reward: 3.7652, time (sec): 149652.2083\n",
      "Ep. 11098 done, reward: 2.0, running_reward: 3.7993, time (sec): 149678.4380\n",
      "Ep. 11100 done, reward: -3.0, running_reward: 3.7927, time (sec): 149703.4482\n",
      "Ep. 11102 done, reward: 8.0, running_reward: 3.9359, time (sec): 149726.0541\n",
      "Ep. 11104 done, reward: 9.0, running_reward: 4.0861, time (sec): 149747.0561\n",
      "Ep. 11106 done, reward: 10.0, running_reward: 4.1345, time (sec): 149774.4158\n",
      "Ep. 11108 done, reward: 2.0, running_reward: 3.9831, time (sec): 149807.9891\n",
      "Ep. 11110 done, reward: -2.0, running_reward: 3.9928, time (sec): 149839.0672\n",
      "Ep. 11112 done, reward: 4.0, running_reward: 3.9830, time (sec): 149872.6933\n",
      "Ep. 11114 done, reward: 6.0, running_reward: 3.9242, time (sec): 149897.5843\n",
      "Ep. 11116 done, reward: 8.0, running_reward: 3.9360, time (sec): 149925.7905\n",
      "Ep. 11118 done, reward: 4.0, running_reward: 3.9471, time (sec): 149949.2055\n",
      "Ep. 11120 done, reward: 10.0, running_reward: 4.0082, time (sec): 149973.6204\n",
      "Ep. 11122 done, reward: 10.0, running_reward: 4.0878, time (sec): 149997.0306\n",
      "Ep. 11124 done, reward: 2.0, running_reward: 4.0661, time (sec): 150025.8662\n",
      "Ep. 11126 done, reward: 12.0, running_reward: 4.2438, time (sec): 150043.8891\n",
      "Ep. 11128 done, reward: 7.0, running_reward: 4.2986, time (sec): 150069.5662\n",
      "Ep. 11130 done, reward: -1.0, running_reward: 4.1338, time (sec): 150098.0408\n",
      "Ep. 11132 done, reward: 13.0, running_reward: 4.3201, time (sec): 150116.3091\n",
      "Ep. 11134 done, reward: 9.0, running_reward: 4.2449, time (sec): 150138.3299\n",
      "Ep. 11136 done, reward: 9.0, running_reward: 4.3099, time (sec): 150158.6245\n",
      "Ep. 11138 done, reward: 1.0, running_reward: 4.2143, time (sec): 150184.8896\n",
      "Ep. 11140 done, reward: 12.0, running_reward: 4.3395, time (sec): 150205.7270\n",
      "Ep. 11142 done, reward: 1.0, running_reward: 4.2335, time (sec): 150230.7118\n",
      "Ep. 11144 done, reward: 4.0, running_reward: 4.1793, time (sec): 150256.9434\n",
      "Ep. 11146 done, reward: 8.0, running_reward: 4.2653, time (sec): 150282.5908\n",
      "Ep. 11148 done, reward: 13.0, running_reward: 4.4094, time (sec): 150300.5740\n",
      "Ep. 11150 done, reward: -3.0, running_reward: 4.2817, time (sec): 150328.9108\n",
      "Ep. 11152 done, reward: 6.0, running_reward: 4.2664, time (sec): 150358.4483\n",
      "Ep. 11154 done, reward: 2.0, running_reward: 4.2213, time (sec): 150387.2348\n",
      "Ep. 11156 done, reward: -7.0, running_reward: 4.0871, time (sec): 150416.1751\n",
      "Ep. 11158 done, reward: -8.0, running_reward: 3.9852, time (sec): 150439.5434\n",
      "Ep. 11160 done, reward: 4.0, running_reward: 4.0350, time (sec): 150463.0824\n",
      "Ep. 11162 done, reward: 9.0, running_reward: 4.2229, time (sec): 150480.5933\n",
      "Ep. 11164 done, reward: -3.0, running_reward: 4.0198, time (sec): 150505.9188\n",
      "Ep. 11166 done, reward: 4.0, running_reward: 3.9600, time (sec): 150542.7940\n",
      "Ep. 11168 done, reward: 6.0, running_reward: 4.0996, time (sec): 150565.5336\n",
      "Ep. 11170 done, reward: -7.0, running_reward: 3.9381, time (sec): 150596.8817\n",
      "Ep. 11172 done, reward: 3.0, running_reward: 4.0580, time (sec): 150623.5391\n",
      "Ep. 11174 done, reward: 11.0, running_reward: 4.1665, time (sec): 150653.6738\n",
      "Ep. 11176 done, reward: -2.0, running_reward: 4.0041, time (sec): 150690.9161\n",
      "Ep. 11178 done, reward: 8.0, running_reward: 4.0639, time (sec): 150720.4043\n",
      "Ep. 11180 done, reward: 2.0, running_reward: 3.9535, time (sec): 150746.8201\n",
      "Ep. 11182 done, reward: -5.0, running_reward: 3.7951, time (sec): 150776.2752\n",
      "Ep. 11184 done, reward: 10.0, running_reward: 3.9285, time (sec): 150799.5433\n",
      "Ep. 11186 done, reward: -5.0, running_reward: 3.9092, time (sec): 150825.7068\n",
      "Ep. 11188 done, reward: 8.0, running_reward: 3.9708, time (sec): 150853.8286\n",
      "Ep. 11190 done, reward: 4.0, running_reward: 3.9912, time (sec): 150883.9708\n",
      "Ep. 11192 done, reward: 12.0, running_reward: 3.9526, time (sec): 150906.4562\n",
      "Ep. 11194 done, reward: 5.0, running_reward: 3.9536, time (sec): 150940.3434\n",
      "Ep. 11196 done, reward: 8.0, running_reward: 3.9747, time (sec): 150968.3024\n",
      "Ep. 11198 done, reward: 6.0, running_reward: 4.0150, time (sec): 150998.1365\n",
      "Ep. 11200 done, reward: 4.0, running_reward: 4.0741, time (sec): 151026.2723\n",
      "Ep. 11202 done, reward: 6.0, running_reward: 4.1323, time (sec): 151052.0827\n",
      "Ep. 11204 done, reward: 8.0, running_reward: 4.2389, time (sec): 151072.8474\n",
      "Ep. 11206 done, reward: 5.0, running_reward: 4.2244, time (sec): 151099.0979\n",
      "Ep. 11208 done, reward: 7.0, running_reward: 4.2499, time (sec): 151126.2113\n",
      "Ep. 11210 done, reward: 4.0, running_reward: 4.2845, time (sec): 151153.0831\n",
      "Ep. 11212 done, reward: 11.0, running_reward: 4.3489, time (sec): 151178.2542\n",
      "Ep. 11214 done, reward: 13.0, running_reward: 4.3626, time (sec): 151203.5956\n",
      "Ep. 11216 done, reward: 4.0, running_reward: 4.3257, time (sec): 151234.3293\n",
      "Ep. 11218 done, reward: -7.0, running_reward: 4.3280, time (sec): 151256.8619\n",
      "Ep. 11220 done, reward: 14.0, running_reward: 4.4413, time (sec): 151280.3852\n",
      "Ep. 11222 done, reward: 15.0, running_reward: 4.5227, time (sec): 151305.3161\n",
      "Ep. 11224 done, reward: 8.0, running_reward: 4.5919, time (sec): 151332.3101\n",
      "Ep. 11226 done, reward: 7.0, running_reward: 4.6003, time (sec): 151356.9724\n",
      "Ep. 11228 done, reward: 6.0, running_reward: 4.6974, time (sec): 151376.2580\n",
      "Ep. 11230 done, reward: -1.0, running_reward: 4.7226, time (sec): 151402.4149\n",
      "Ep. 11232 done, reward: 3.0, running_reward: 4.6784, time (sec): 151431.9912\n",
      "Ep. 11234 done, reward: 8.0, running_reward: 4.5861, time (sec): 151469.6860\n",
      "Ep. 11236 done, reward: -6.0, running_reward: 4.5636, time (sec): 151500.1796\n",
      "Ep. 11238 done, reward: 9.0, running_reward: 4.6717, time (sec): 151538.8581\n",
      "Ep. 11240 done, reward: -5.0, running_reward: 4.6871, time (sec): 151571.1283\n",
      "Ep. 11242 done, reward: -6.0, running_reward: 4.6229, time (sec): 151599.4566\n",
      "Ep. 11244 done, reward: 10.0, running_reward: 4.6012, time (sec): 151625.5360\n",
      "Ep. 11246 done, reward: 6.0, running_reward: 4.6390, time (sec): 151652.1896\n",
      "Ep. 11248 done, reward: -9.0, running_reward: 4.3676, time (sec): 151677.3223\n",
      "Ep. 11250 done, reward: -5.0, running_reward: 4.3296, time (sec): 151702.6524\n",
      "Ep. 11252 done, reward: 5.0, running_reward: 4.4123, time (sec): 151725.9973\n",
      "Ep. 11254 done, reward: 8.0, running_reward: 4.4837, time (sec): 151749.4056\n",
      "Ep. 11256 done, reward: 8.0, running_reward: 4.5833, time (sec): 151769.8652\n",
      "Ep. 11258 done, reward: 5.0, running_reward: 4.5322, time (sec): 151797.8805\n",
      "Ep. 11260 done, reward: 3.0, running_reward: 4.5611, time (sec): 151823.9191\n",
      "Ep. 11262 done, reward: 4.0, running_reward: 4.5896, time (sec): 151849.4829\n",
      "Ep. 11264 done, reward: -2.0, running_reward: 4.5178, time (sec): 151880.1565\n",
      "Ep. 11266 done, reward: -6.0, running_reward: 4.3877, time (sec): 151909.8346\n",
      "Ep. 11268 done, reward: 9.0, running_reward: 4.3310, time (sec): 151933.6577\n",
      "Ep. 11270 done, reward: 2.0, running_reward: 4.2945, time (sec): 151962.1021\n",
      "Ep. 11272 done, reward: 3.0, running_reward: 4.2094, time (sec): 151989.9339\n",
      "Ep. 11274 done, reward: 12.0, running_reward: 4.1763, time (sec): 152015.7414\n",
      "Ep. 11276 done, reward: 4.0, running_reward: 4.2421, time (sec): 152037.9957\n",
      "Ep. 11278 done, reward: -4.0, running_reward: 4.1375, time (sec): 152068.8645\n",
      "Ep. 11280 done, reward: 6.0, running_reward: 4.0458, time (sec): 152093.5932\n",
      "Ep. 11282 done, reward: 6.0, running_reward: 3.9065, time (sec): 152117.1444\n",
      "Ep. 11284 done, reward: 4.0, running_reward: 3.9777, time (sec): 152136.4426\n",
      "Ep. 11286 done, reward: 8.0, running_reward: 3.9686, time (sec): 152160.2806\n",
      "Ep. 11288 done, reward: 10.0, running_reward: 3.9600, time (sec): 152186.5600\n",
      "Ep. 11290 done, reward: 4.0, running_reward: 4.0004, time (sec): 152214.7718\n",
      "Ep. 11292 done, reward: 8.0, running_reward: 4.0305, time (sec): 152243.5086\n",
      "Ep. 11294 done, reward: 9.0, running_reward: 4.0105, time (sec): 152269.3200\n",
      "Ep. 11296 done, reward: 3.0, running_reward: 3.8716, time (sec): 152292.5413\n",
      "Ep. 11298 done, reward: -3.0, running_reward: 3.8141, time (sec): 152323.8382\n",
      "Ep. 11300 done, reward: 6.0, running_reward: 3.7388, time (sec): 152349.0656\n",
      "Ep. 11302 done, reward: -4.0, running_reward: 3.7531, time (sec): 152373.2825\n",
      "Ep. 11304 done, reward: 9.0, running_reward: 3.8080, time (sec): 152400.2081\n",
      "Ep. 11306 done, reward: -11.0, running_reward: 3.6915, time (sec): 152424.4710\n",
      "Ep. 11308 done, reward: -1.0, running_reward: 3.5685, time (sec): 152452.5238\n",
      "Ep. 11310 done, reward: 9.0, running_reward: 3.6073, time (sec): 152476.0602\n",
      "Ep. 11312 done, reward: 5.0, running_reward: 3.6152, time (sec): 152506.5027\n",
      "Ep. 11314 done, reward: -2.0, running_reward: 3.5430, time (sec): 152534.5712\n",
      "Ep. 11316 done, reward: -2.0, running_reward: 3.4327, time (sec): 152566.7398\n",
      "Ep. 11318 done, reward: 1.0, running_reward: 3.4437, time (sec): 152596.3275\n",
      "Ep. 11320 done, reward: 1.0, running_reward: 3.4446, time (sec): 152629.5811\n",
      "Ep. 11322 done, reward: 6.0, running_reward: 3.5251, time (sec): 152656.2440\n",
      "Ep. 11324 done, reward: 4.0, running_reward: 3.5643, time (sec): 152685.1383\n",
      "Ep. 11326 done, reward: 5.0, running_reward: 3.6226, time (sec): 152712.1015\n",
      "Ep. 11328 done, reward: 8.0, running_reward: 3.6008, time (sec): 152739.4061\n",
      "Ep. 11330 done, reward: 11.0, running_reward: 3.6589, time (sec): 152771.3040\n",
      "Ep. 11332 done, reward: -5.0, running_reward: 3.3876, time (sec): 152798.0923\n",
      "Ep. 11334 done, reward: -1.0, running_reward: 3.3399, time (sec): 152825.7196\n",
      "Ep. 11336 done, reward: 1.0, running_reward: 3.3527, time (sec): 152852.3536\n",
      "Ep. 11338 done, reward: 9.0, running_reward: 3.4552, time (sec): 152879.7909\n",
      "Ep. 11340 done, reward: 5.0, running_reward: 3.5057, time (sec): 152908.2582\n",
      "Ep. 11342 done, reward: -3.0, running_reward: 3.4357, time (sec): 152935.8395\n",
      "Ep. 11344 done, reward: 12.0, running_reward: 3.5071, time (sec): 152963.1784\n",
      "Ep. 11346 done, reward: 6.0, running_reward: 3.4577, time (sec): 152987.5238\n",
      "Ep. 11348 done, reward: -3.0, running_reward: 3.4183, time (sec): 153013.7769\n",
      "Ep. 11350 done, reward: -4.0, running_reward: 3.3598, time (sec): 153042.0074\n",
      "Ep. 11352 done, reward: 2.0, running_reward: 3.3525, time (sec): 153069.3917\n",
      "Ep. 11354 done, reward: 10.0, running_reward: 3.4155, time (sec): 153094.2773\n",
      "Ep. 11356 done, reward: 3.0, running_reward: 3.4072, time (sec): 153120.1788\n",
      "Ep. 11358 done, reward: 3.0, running_reward: 3.3991, time (sec): 153149.3421\n",
      "Ep. 11360 done, reward: 2.0, running_reward: 3.3416, time (sec): 153181.1287\n",
      "Ep. 11362 done, reward: -2.0, running_reward: 3.1660, time (sec): 153207.0094\n",
      "Ep. 11364 done, reward: 10.0, running_reward: 3.2723, time (sec): 153229.6724\n",
      "Ep. 11366 done, reward: 4.0, running_reward: 3.2373, time (sec): 153257.6240\n",
      "Ep. 11368 done, reward: -5.0, running_reward: 3.2417, time (sec): 153286.7030\n",
      "Ep. 11370 done, reward: 3.0, running_reward: 3.3061, time (sec): 153319.4490\n",
      "Ep. 11372 done, reward: 16.0, running_reward: 3.4201, time (sec): 153341.9607\n",
      "Ep. 11374 done, reward: 5.0, running_reward: 3.3922, time (sec): 153372.5199\n",
      "Ep. 11376 done, reward: 4.0, running_reward: 3.4538, time (sec): 153405.7574\n",
      "Ep. 11378 done, reward: 2.0, running_reward: 3.3556, time (sec): 153452.2478\n",
      "Ep. 11380 done, reward: 6.0, running_reward: 3.2993, time (sec): 153486.0134\n",
      "Ep. 11382 done, reward: 5.0, running_reward: 3.4123, time (sec): 153512.1791\n",
      "Ep. 11384 done, reward: 9.0, running_reward: 3.5136, time (sec): 153543.4199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c66e947be204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicyGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mPG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Pong-v0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kevinli/src/deeplearning/CS294/CS294_Solution/assignment4/agents/policy_gradients.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, environment, max_episodes, print_every)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Forward input to network and sample action from the probability.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# In Pong, 2=UP and 3=DOWN. For now, ignore the NO-OP action (i.e. 0).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0maprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maprob\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinli/src/deeplearning/CS294/CS294_Solution/assignment4/agents/policy_gradients.pyc\u001b[0m in \u001b[0;36mpolicy_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m           \u001b[0mhidden\u001b[0m \u001b[0mstate\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PG = PolicyGradient(D=80*80, H=200, learning_rate=0.001)\n",
    "PG.train(environment=\"Pong-v0\", max_episodes=50000, print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Pong running reward: 3.51361724494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1061456d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGHCAYAAABF4dM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10622ba50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results.\n",
    "print(\"Final Pong running reward: {}\".format(PG.running_rewards[-1]))\n",
    "plt.figure()\n",
    "plt.plot(PG.running_rewards)\n",
    "plt.title(\"Running Rewards for Pong\")\n",
    "plt.xlabel(\"Training Episodes\")\n",
    "plt.ylabel(\"Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary of the Pong Game\n",
    "The pong game takes a lot longer to train as the signal is even weaker than the cartpole game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
